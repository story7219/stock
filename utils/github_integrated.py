#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”§ GitHub í†µí•© ì ‘ê·¼ ì‹œìŠ¤í…œ
ëª¨ë“  ë°©ì‹ì„ í†µí•©í•˜ì—¬ í•­ìƒ GitHub ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë„ë¡ ë³´ì¥

ì ‘ê·¼ ë°©ì‹ ìš°ì„ ìˆœìœ„:
1. GitHub API (í† í° ê¸°ë°˜)
2. ì›¹ ê²€ìƒ‰ (DuckDuckGo + ìŠ¤í¬ë˜í•‘)
3. MCP ì„œë²„ (ë°±ì—…)
4. ë¡œì»¬ ìºì‹œ ë° í´ë°± ë°ì´í„°
"""

import os
import json
import requests
import logging
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
from dotenv import load_dotenv
import pickle
from pathlib import Path

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
try:
    from github_accessor import GitHubAccessor
    GITHUB_API_AVAILABLE = True
except ImportError:
    GITHUB_API_AVAILABLE = False

try:
    from github_web_search import GitHubWebSearcher
    WEB_SEARCH_AVAILABLE = True
except ImportError:
    WEB_SEARCH_AVAILABLE = False

# í™˜ê²½ ì„¤ì •
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GitHubIntegratedSystem:
    """GitHub í†µí•© ì ‘ê·¼ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.github_token = os.getenv('GITHUB_API_TOKEN', '')
        self.cache_dir = Path('.github_cache')
        self.cache_dir.mkdir(exist_ok=True)
        
        # ê° ì ‘ê·¼ ë°©ì‹ ì´ˆê¸°í™”
        self.api_accessor = None
        self.web_searcher = None
        self.mcp_available = False
        
        # GitHub API ì ‘ê·¼ì ì´ˆê¸°í™”
        if GITHUB_API_AVAILABLE and self.github_token:
            try:
                self.api_accessor = GitHubAccessor()
                logger.info("âœ… GitHub API ì ‘ê·¼ì ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ GitHub API ì ‘ê·¼ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ì›¹ ê²€ìƒ‰ì ì´ˆê¸°í™”
        if WEB_SEARCH_AVAILABLE:
            try:
                self.web_searcher = GitHubWebSearcher()
                logger.info("âœ… GitHub ì›¹ ê²€ìƒ‰ì ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ GitHub ì›¹ ê²€ìƒ‰ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # MCP ì„œë²„ ìƒíƒœ í™•ì¸
        self.check_mcp_server()
    
    def check_mcp_server(self):
        """MCP ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            # MCP ì„œë²„ ì„¤ì • íŒŒì¼ í™•ì¸
            mcp_config_path = Path('mcp_servers.json')
            if mcp_config_path.exists():
                with open(mcp_config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    if 'mcpServers' in config and 'github' in config['mcpServers']:
                        self.mcp_available = True
                        logger.info("âœ… MCP GitHub ì„œë²„ ì„¤ì • í™•ì¸ë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ MCP ì„œë²„ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def search_repositories(self, query: str, language: str = None, 
                          sort: str = 'stars', order: str = 'desc', 
                          per_page: int = 10) -> List[Dict[str, Any]]:
        """ì €ì¥ì†Œ ê²€ìƒ‰ (í†µí•© ë°©ì‹)"""
        logger.info(f"ğŸ” í†µí•© ì €ì¥ì†Œ ê²€ìƒ‰: {query}")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"repos_{query}_{language}_{sort}_{order}_{per_page}"
        cached_result = self._get_cache(cache_key)
        if cached_result:
            logger.info("ğŸ“‹ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
            return cached_result
        
        results = []
        
        # ë°©ì‹ 1: GitHub API
        if self.api_accessor:
            try:
                api_results = self.api_accessor.search_repositories(
                    query, language, sort, order, per_page
                )
                if api_results and not any(r.get('fallback') for r in api_results):
                    results = api_results
                    logger.info(f"âœ… GitHub API ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
                    self._set_cache(cache_key, results)
                    return results
            except Exception as e:
                logger.warning(f"GitHub API ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # ë°©ì‹ 2: ì›¹ ê²€ìƒ‰
        if self.web_searcher:
            try:
                web_results = self.web_searcher.search_repositories_web(
                    query, language, per_page
                )
                if web_results and not any(r.get('fallback') for r in web_results):
                    results = web_results
                    logger.info(f"âœ… ì›¹ ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
                    self._set_cache(cache_key, results)
                    return results
            except Exception as e:
                logger.warning(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # ë°©ì‹ 3: í´ë°± ë°ì´í„°
        fallback_results = self._get_fallback_repositories(query, language)
        logger.info(f"ğŸ”„ í´ë°± ë°ì´í„° ì‚¬ìš©: {len(fallback_results)}ê°œ ê²°ê³¼")
        return fallback_results
    
    def search_code(self, query: str, repo: str = None, language: str = None, 
                   per_page: int = 10) -> List[Dict[str, Any]]:
        """ì½”ë“œ ê²€ìƒ‰ (í†µí•© ë°©ì‹)"""
        logger.info(f"ğŸ” í†µí•© ì½”ë“œ ê²€ìƒ‰: {query}")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"code_{query}_{repo}_{language}_{per_page}"
        cached_result = self._get_cache(cache_key)
        if cached_result:
            logger.info("ğŸ“‹ ìºì‹œì—ì„œ ì½”ë“œ ê²°ê³¼ ë°˜í™˜")
            return cached_result
        
        results = []
        
        # ë°©ì‹ 1: GitHub API
        if self.api_accessor:
            try:
                api_results = self.api_accessor.search_code(query, repo, language, per_page)
                if api_results:
                    results = api_results
                    logger.info(f"âœ… GitHub API ì½”ë“œ ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
                    self._set_cache(cache_key, results)
                    return results
            except Exception as e:
                logger.warning(f"GitHub API ì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # ë°©ì‹ 2: ì›¹ ê²€ìƒ‰
        if self.web_searcher:
            try:
                web_results = self.web_searcher.search_code_web(query, language)
                if web_results:
                    results = web_results
                    logger.info(f"âœ… ì›¹ ì½”ë“œ ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
                    self._set_cache(cache_key, results)
                    return results
            except Exception as e:
                logger.warning(f"ì›¹ ì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        logger.info("ğŸ”„ ì½”ë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return []
    
    def get_repository_info(self, owner: str, repo: str) -> Dict[str, Any]:
        """ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ (í†µí•© ë°©ì‹)"""
        logger.info(f"ğŸ“‹ í†µí•© ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ: {owner}/{repo}")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"repo_info_{owner}_{repo}"
        cached_result = self._get_cache(cache_key)
        if cached_result:
            logger.info("ğŸ“‹ ìºì‹œì—ì„œ ì €ì¥ì†Œ ì •ë³´ ë°˜í™˜")
            return cached_result
        
        # ë°©ì‹ 1: GitHub API
        if self.api_accessor:
            try:
                api_result = self.api_accessor.get_repository_info(owner, repo)
                if api_result:
                    logger.info("âœ… GitHub API ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ì„±ê³µ")
                    self._set_cache(cache_key, api_result)
                    return api_result
            except Exception as e:
                logger.warning(f"GitHub API ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # ë°©ì‹ 2: ì›¹ ìŠ¤í¬ë˜í•‘
        if self.web_searcher:
            try:
                web_result = self.web_searcher._scrape_repo_info(owner, repo)
                if web_result:
                    logger.info("âœ… ì›¹ ìŠ¤í¬ë˜í•‘ ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ì„±ê³µ")
                    self._set_cache(cache_key, web_result)
                    return web_result
            except Exception as e:
                logger.warning(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ì •ë³´ ë°˜í™˜
        return {
            'name': repo,
            'full_name': f'{owner}/{repo}',
            'html_url': f'https://github.com/{owner}/{repo}',
            'owner': {'login': owner},
            'description': '',
            'stars': 0,
            'forks': 0,
            'language': '',
            'fallback': True
        }
    
    def get_trending_repositories(self, language: str = None, 
                                 period: str = 'daily') -> List[Dict[str, Any]]:
        """íŠ¸ë Œë”© ì €ì¥ì†Œ ì¡°íšŒ"""
        logger.info(f"ğŸ“ˆ íŠ¸ë Œë”© ì €ì¥ì†Œ ì¡°íšŒ: {language} ({period})")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"trending_{language}_{period}"
        cached_result = self._get_cache(cache_key, max_age_hours=6)  # 6ì‹œê°„ ìºì‹œ
        if cached_result:
            logger.info("ğŸ“‹ ìºì‹œì—ì„œ íŠ¸ë Œë”© ê²°ê³¼ ë°˜í™˜")
            return cached_result
        
        # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ íŠ¸ë Œë”© ì¡°íšŒ
        if self.web_searcher:
            try:
                trending_results = self.web_searcher.get_trending_repositories(language, period)
                if trending_results:
                    logger.info(f"âœ… íŠ¸ë Œë”© ì €ì¥ì†Œ ì¡°íšŒ ì„±ê³µ: {len(trending_results)}ê°œ")
                    self._set_cache(cache_key, trending_results)
                    return trending_results
            except Exception as e:
                logger.warning(f"íŠ¸ë Œë”© ì €ì¥ì†Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return []
    
    def _get_cache(self, key: str, max_age_hours: int = 24) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        try:
            cache_file = self.cache_dir / f"{key}.pkl"
            if cache_file.exists():
                # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                file_age = datetime.now() - datetime.fromtimestamp(cache_file.stat().st_mtime)
                if file_age < timedelta(hours=max_age_hours):
                    with open(cache_file, 'rb') as f:
                        return pickle.load(f)
                else:
                    cache_file.unlink()  # ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
        except Exception as e:
            logger.warning(f"ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None
    
    def _set_cache(self, key: str, data: Any):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        try:
            cache_file = self.cache_dir / f"{key}.pkl"
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _get_fallback_repositories(self, query: str, language: str = None) -> List[Dict[str, Any]]:
        """í´ë°± ì €ì¥ì†Œ ë°ì´í„°"""
        # ì£¼ì‹/ê¸ˆìœµ/AI ê´€ë ¨ ì¸ê¸° ì €ì¥ì†Œë“¤
        popular_repos = [
            {
                'name': 'yfinance',
                'full_name': 'ranaroussi/yfinance',
                'description': 'Download market data from Yahoo! Finance API',
                'html_url': 'https://github.com/ranaroussi/yfinance',
                'stars': 12000,
                'forks': 2000,
                'language': 'Python',
                'owner': {'login': 'ranaroussi'},
                'topics': ['finance', 'yahoo-finance', 'stock-data', 'market-data'],
                'fallback': True
            },
            {
                'name': 'zipline',
                'full_name': 'quantopian/zipline',
                'description': 'Zipline, a Pythonic Algorithmic Trading Library',
                'html_url': 'https://github.com/quantopian/zipline',
                'stars': 17000,
                'forks': 4500,
                'language': 'Python',
                'owner': {'login': 'quantopian'},
                'topics': ['algorithmic-trading', 'finance', 'backtesting', 'trading'],
                'fallback': True
            },
            {
                'name': 'backtrader',
                'full_name': 'mementum/backtrader',
                'description': 'Python Backtesting library for trading strategies',
                'html_url': 'https://github.com/mementum/backtrader',
                'stars': 13000,
                'forks': 3500,
                'language': 'Python',
                'owner': {'login': 'mementum'},
                'topics': ['backtesting', 'trading', 'finance', 'strategy'],
                'fallback': True
            },
            {
                'name': 'pandas-datareader',
                'full_name': 'pydata/pandas-datareader',
                'description': 'Up to date remote data access for pandas',
                'html_url': 'https://github.com/pydata/pandas-datareader',
                'stars': 2800,
                'forks': 700,
                'language': 'Python',
                'owner': {'login': 'pydata'},
                'topics': ['pandas', 'data-reader', 'finance', 'data-access'],
                'fallback': True
            },
            {
                'name': 'FinanceDatabase',
                'full_name': 'JerBouma/FinanceDatabase',
                'description': '300,000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies',
                'html_url': 'https://github.com/JerBouma/FinanceDatabase',
                'stars': 3000,
                'forks': 500,
                'language': 'Python',
                'owner': {'login': 'JerBouma'},
                'topics': ['finance', 'database', 'stocks', 'etf', 'cryptocurrency'],
                'fallback': True
            },
            {
                'name': 'ta-lib',
                'full_name': 'mrjbq7/ta-lib',
                'description': 'Python wrapper for TA-Lib (Technical Analysis Library)',
                'html_url': 'https://github.com/mrjbq7/ta-lib',
                'stars': 8000,
                'forks': 1800,
                'language': 'Python',
                'owner': {'login': 'mrjbq7'},
                'topics': ['technical-analysis', 'finance', 'trading', 'indicators'],
                'fallback': True
            },
            {
                'name': 'ultralytics',
                'full_name': 'ultralytics/ultralytics',
                'description': 'NEW - YOLOv8 ğŸš€ in PyTorch > ONNX > OpenVINO > CoreML > TFLite',
                'html_url': 'https://github.com/ultralytics/ultralytics',
                'stars': 25000,
                'forks': 5000,
                'language': 'Python',
                'owner': {'login': 'ultralytics'},
                'topics': ['yolo', 'computer-vision', 'object-detection', 'ai', 'deep-learning'],
                'fallback': True
            },
            {
                'name': 'transformers',
                'full_name': 'huggingface/transformers',
                'description': 'ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX',
                'html_url': 'https://github.com/huggingface/transformers',
                'stars': 120000,
                'forks': 24000,
                'language': 'Python',
                'owner': {'login': 'huggingface'},
                'topics': ['nlp', 'pytorch', 'tensorflow', 'jax', 'transformers', 'ai'],
                'fallback': True
            }
        ]
        
        # ì¿¼ë¦¬ì™€ ê´€ë ¨ì„± ê³„ì‚°
        query_lower = query.lower()
        query_words = query_lower.split()
        
        relevant_repos = []
        for repo in popular_repos:
            relevance_score = 0
            
            # ì´ë¦„ì—ì„œ ë§¤ì¹­
            if any(word in repo['name'].lower() for word in query_words):
                relevance_score += 5
            
            # ì„¤ëª…ì—ì„œ ë§¤ì¹­
            if any(word in repo['description'].lower() for word in query_words):
                relevance_score += 3
            
            # í† í”½ì—ì„œ ë§¤ì¹­
            topics_text = ' '.join(repo['topics']).lower()
            matching_topics = sum(1 for word in query_words if word in topics_text)
            relevance_score += matching_topics * 2
            
            # ì–¸ì–´ í•„í„°
            if language and repo['language'].lower() != language.lower():
                relevance_score = max(0, relevance_score - 2)
            
            if relevance_score > 0:
                repo['relevance_score'] = relevance_score
                relevant_repos.append(repo)
        
        # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
        relevant_repos.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        return relevant_repos[:10]  # ìƒìœ„ 10ê°œ ë°˜í™˜
    
    def test_all_systems(self) -> Dict[str, Any]:
        """ëª¨ë“  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ”§ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        results = {
            'github_api_working': False,
            'web_search_working': False,
            'mcp_server_available': self.mcp_available,
            'cache_working': False,
            'overall_status': 'unknown',
            'test_results': {}
        }
        
        # GitHub API í…ŒìŠ¤íŠ¸
        if self.api_accessor:
            try:
                api_test = self.api_accessor.test_connection()
                results['github_api_working'] = api_test.get('requests_working', False) or api_test.get('pygithub_working', False)
                results['test_results']['api'] = api_test
            except Exception as e:
                logger.warning(f"GitHub API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        if self.web_searcher:
            try:
                web_test = self.web_searcher.test_web_search()
                results['web_search_working'] = web_test.get('web_search_working', False)
                results['test_results']['web'] = web_test
            except Exception as e:
                logger.warning(f"ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ìºì‹œ í…ŒìŠ¤íŠ¸
        try:
            test_data = {'test': 'data', 'timestamp': datetime.now().isoformat()}
            self._set_cache('test_cache', test_data)
            cached_data = self._get_cache('test_cache')
            results['cache_working'] = cached_data is not None
        except Exception as e:
            logger.warning(f"ìºì‹œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if results['github_api_working']:
            results['overall_status'] = 'excellent'
        elif results['web_search_working']:
            results['overall_status'] = 'good'
        elif results['mcp_server_available']:
            results['overall_status'] = 'fair'
        else:
            results['overall_status'] = 'fallback_only'
        
        logger.info(f"âœ… í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {results['overall_status']}")
        return results
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            for cache_file in self.cache_dir.glob('*.pkl'):
                cache_file.unlink()
            logger.info("âœ… ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
github_system = GitHubIntegratedSystem()

# í¸ì˜ í•¨ìˆ˜ë“¤
def search_github_repositories_integrated(query: str, **kwargs) -> List[Dict[str, Any]]:
    """í†µí•© GitHub ì €ì¥ì†Œ ê²€ìƒ‰"""
    return github_system.search_repositories(query, **kwargs)

def search_github_code_integrated(query: str, **kwargs) -> List[Dict[str, Any]]:
    """í†µí•© GitHub ì½”ë“œ ê²€ìƒ‰"""
    return github_system.search_code(query, **kwargs)

def get_github_repo_info_integrated(owner: str, repo: str) -> Dict[str, Any]:
    """í†µí•© GitHub ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ"""
    return github_system.get_repository_info(owner, repo)

def get_github_trending_integrated(language: str = None, period: str = 'daily') -> List[Dict[str, Any]]:
    """í†µí•© GitHub íŠ¸ë Œë”© ì €ì¥ì†Œ"""
    return github_system.get_trending_repositories(language, period)

def test_github_integrated_system() -> Dict[str, Any]:
    """í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    return github_system.test_all_systems()

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ”§ GitHub í†µí•© ì ‘ê·¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    # ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸
    system_test = test_github_integrated_system()
    print(f"ì‹œìŠ¤í…œ ìƒíƒœ: {system_test['overall_status']}")
    print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {json.dumps(system_test, indent=2, ensure_ascii=False)}")
    
    # ì €ì¥ì†Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ“‹ í†µí•© ì €ì¥ì†Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    repos = search_github_repositories_integrated("python stock analysis", per_page=5)
    for repo in repos:
        status = "ğŸ”„ í´ë°±" if repo.get('fallback') else "âœ… ì‹¤ì œ"
        print(f"  {status} {repo['full_name']}: â­{repo.get('stars', 0)} - {repo.get('description', '')[:80]}...")
    
    # íŠ¸ë Œë”© ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“ˆ íŠ¸ë Œë”© ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸")
    trending = get_github_trending_integrated("python")
    for repo in trending[:3]:
        print(f"  ğŸ“ˆ {repo['full_name']}: â­{repo.get('stars', 0)} - {repo.get('description', '')[:80]}...")
    
    print("\nâœ… ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 