#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
âš¡ ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ v1.0
ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
"""

import asyncio
import logging
import time
import psutil
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import sqlite3
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
from functools import wraps
import gc
import sys
import os

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_io_read: int
    disk_io_write: int
    network_sent: int
    network_recv: int
    active_threads: int
    function_name: str
    execution_time: float
    status: str

@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼"""
    optimization_type: str
    before_metrics: PerformanceMetrics
    after_metrics: PerformanceMetrics
    improvement_percent: float
    recommendation: str

class PerformanceOptimizer:
    """ğŸš€ ì„±ëŠ¥ ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self, db_path: str = "performance_metrics.db"):
        """ì„±ëŠ¥ ìµœì í™” ê´€ë¦¬ì ì´ˆê¸°í™”"""
        logger.info("âš¡ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
        self.db_path = db_path
        self.metrics_history: List[PerformanceMetrics] = []
        self.optimization_history: List[OptimizationResult] = []
        
        # ì„±ëŠ¥ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'execution_time': 30.0,  # 30ì´ˆ
            'disk_io_threshold': 100 * 1024 * 1024,  # 100MB
            'memory_leak_threshold': 500 * 1024 * 1024  # 500MB
        }
        
        # ìŠ¤ë ˆë“œí’€ ì„¤ì •
        self.thread_pool = ThreadPoolExecutor(max_workers=mp.cpu_count())
        self.process_pool = ProcessPoolExecutor(max_workers=mp.cpu_count())
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_active = False
        self.monitoring_thread = None
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        
        logger.info("âœ… ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
    
    def _init_database(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    cpu_percent REAL,
                    memory_percent REAL,
                    memory_used_mb REAL,
                    disk_io_read INTEGER,
                    disk_io_write INTEGER,
                    network_sent INTEGER,
                    network_recv INTEGER,
                    active_threads INTEGER,
                    function_name TEXT,
                    execution_time REAL,
                    status TEXT
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS optimization_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    optimization_type TEXT,
                    improvement_percent REAL,
                    recommendation TEXT,
                    before_metrics TEXT,
                    after_metrics TEXT
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def performance_monitor(self, function_name: str = None):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
        def decorator(func: Callable):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                start_time = time.time()
                start_metrics = self._collect_system_metrics()
                
                try:
                    result = await func(*args, **kwargs)
                    status = "SUCCESS"
                except Exception as e:
                    status = f"ERROR: {str(e)}"
                    raise
                finally:
                    end_time = time.time()
                    execution_time = end_time - start_time
                    
                    end_metrics = self._collect_system_metrics()
                    
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„±
                    metrics = PerformanceMetrics(
                        timestamp=datetime.now(),
                        cpu_percent=end_metrics['cpu_percent'],
                        memory_percent=end_metrics['memory_percent'],
                        memory_used_mb=end_metrics['memory_used_mb'],
                        disk_io_read=end_metrics['disk_io_read'],
                        disk_io_write=end_metrics['disk_io_write'],
                        network_sent=end_metrics['network_sent'],
                        network_recv=end_metrics['network_recv'],
                        active_threads=threading.active_count(),
                        function_name=function_name or func.__name__,
                        execution_time=execution_time,
                        status=status
                    )
                    
                    # ë©”íŠ¸ë¦­ ì €ì¥
                    self._save_metrics(metrics)
                    
                    # ì„±ëŠ¥ ì´ìŠˆ ì²´í¬
                    await self._check_performance_issues(metrics)
                
                return result
            
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                start_time = time.time()
                start_metrics = self._collect_system_metrics()
                
                try:
                    result = func(*args, **kwargs)
                    status = "SUCCESS"
                except Exception as e:
                    status = f"ERROR: {str(e)}"
                    raise
                finally:
                    end_time = time.time()
                    execution_time = end_time - start_time
                    
                    end_metrics = self._collect_system_metrics()
                    
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„±
                    metrics = PerformanceMetrics(
                        timestamp=datetime.now(),
                        cpu_percent=end_metrics['cpu_percent'],
                        memory_percent=end_metrics['memory_percent'],
                        memory_used_mb=end_metrics['memory_used_mb'],
                        disk_io_read=end_metrics['disk_io_read'],
                        disk_io_write=end_metrics['disk_io_write'],
                        network_sent=end_metrics['network_sent'],
                        network_recv=end_metrics['network_recv'],
                        active_threads=threading.active_count(),
                        function_name=function_name or func.__name__,
                        execution_time=execution_time,
                        status=status
                    )
                    
                    # ë©”íŠ¸ë¦­ ì €ì¥
                    self._save_metrics(metrics)
                
                return result
            
            # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸
            if asyncio.iscoroutinefunction(func):
                return async_wrapper
            else:
                return sync_wrapper
        
        return decorator
    
    def _collect_system_metrics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_used_mb = memory.used / (1024 * 1024)
            
            # ë””ìŠ¤í¬ I/O
            disk_io = psutil.disk_io_counters()
            disk_io_read = disk_io.read_bytes if disk_io else 0
            disk_io_write = disk_io.write_bytes if disk_io else 0
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            network_io = psutil.net_io_counters()
            network_sent = network_io.bytes_sent if network_io else 0
            network_recv = network_io.bytes_recv if network_io else 0
            
            return {
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                'memory_used_mb': memory_used_mb,
                'disk_io_read': disk_io_read,
                'disk_io_write': disk_io_write,
                'network_sent': network_sent,
                'network_recv': network_recv
            }
        
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _save_metrics(self, metrics: PerformanceMetrics):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO performance_metrics 
                (timestamp, cpu_percent, memory_percent, memory_used_mb,
                 disk_io_read, disk_io_write, network_sent, network_recv,
                 active_threads, function_name, execution_time, status)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                metrics.timestamp.isoformat(),
                metrics.cpu_percent,
                metrics.memory_percent,
                metrics.memory_used_mb,
                metrics.disk_io_read,
                metrics.disk_io_write,
                metrics.network_sent,
                metrics.network_recv,
                metrics.active_threads,
                metrics.function_name,
                metrics.execution_time,
                metrics.status
            ))
            
            conn.commit()
            conn.close()
            
            # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥ (ìµœê·¼ 1000ê°œë§Œ)
            self.metrics_history.append(metrics)
            if len(self.metrics_history) > 1000:
                self.metrics_history = self.metrics_history[-1000:]
                
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def _check_performance_issues(self, metrics: PerformanceMetrics):
        """ì„±ëŠ¥ ì´ìŠˆ ì²´í¬ ë° ìµœì í™” ì œì•ˆ"""
        issues = []
        
        # CPU ì‚¬ìš©ë¥  ì²´í¬
        if metrics.cpu_percent > self.thresholds['cpu_percent']:
            issues.append(f"ë†’ì€ CPU ì‚¬ìš©ë¥ : {metrics.cpu_percent:.1f}%")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬
        if metrics.memory_percent > self.thresholds['memory_percent']:
            issues.append(f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics.memory_percent:.1f}%")
        
        # ì‹¤í–‰ ì‹œê°„ ì²´í¬
        if metrics.execution_time > self.thresholds['execution_time']:
            issues.append(f"ê¸´ ì‹¤í–‰ ì‹œê°„: {metrics.execution_time:.1f}ì´ˆ")
        
        if issues:
            logger.warning(f"âš ï¸ ì„±ëŠ¥ ì´ìŠˆ ê°ì§€ [{metrics.function_name}]: {', '.join(issues)}")
            await self._suggest_optimizations(metrics, issues)
    
    async def _suggest_optimizations(self, metrics: PerformanceMetrics, issues: List[str]):
        """ìµœì í™” ì œì•ˆ"""
        suggestions = []
        
        if metrics.cpu_percent > self.thresholds['cpu_percent']:
            suggestions.append("CPU ì§‘ì•½ì  ì‘ì—…ì„ ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë¶„ì‚°")
            suggestions.append("ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš© ê³ ë ¤")
        
        if metrics.memory_percent > self.thresholds['memory_percent']:
            suggestions.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•„ìš”")
            suggestions.append("ë°ì´í„° ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ ê³ ë ¤")
            
        if metrics.execution_time > self.thresholds['execution_time']:
            suggestions.append("í•¨ìˆ˜ ë¶„í•  ë° ìºì‹± ì ìš©")
            suggestions.append("ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”")
        
        logger.info(f"ğŸ’¡ ìµœì í™” ì œì•ˆ [{metrics.function_name}]: {', '.join(suggestions)}")
    
    async def optimize_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘")
        
        before_metrics = self._collect_system_metrics()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        collected = gc.collect()
        
        # ìºì‹œ ì •ë¦¬
        self._clear_caches()
        
        after_metrics = self._collect_system_metrics()
        
        improvement = before_metrics['memory_percent'] - after_metrics['memory_percent']
        
        logger.info(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {improvement:.1f}% ê°œì„ , {collected}ê°œ ê°ì²´ ì •ë¦¬")
        
        return OptimizationResult(
            optimization_type="MEMORY",
            before_metrics=PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_percent=before_metrics['cpu_percent'],
                memory_percent=before_metrics['memory_percent'],
                memory_used_mb=before_metrics['memory_used_mb'],
                disk_io_read=0, disk_io_write=0,
                network_sent=0, network_recv=0,
                active_threads=0, function_name="memory_optimization",
                execution_time=0, status="BEFORE"
            ),
            after_metrics=PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_percent=after_metrics['cpu_percent'],
                memory_percent=after_metrics['memory_percent'],
                memory_used_mb=after_metrics['memory_used_mb'],
                disk_io_read=0, disk_io_write=0,
                network_sent=0, network_recv=0,
                active_threads=0, function_name="memory_optimization",
                execution_time=0, status="AFTER"
            ),
            improvement_percent=improvement,
            recommendation="ì •ê¸°ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰"
        )
    
    def _clear_caches(self):
        """ìºì‹œ ì •ë¦¬"""
        # ë‚´ë¶€ ìºì‹œ ì •ë¦¬
        if hasattr(self, 'cache'):
            self.cache.clear()
        
        # ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì‹œë„
        try:
            if sys.platform == "linux":
                os.system("sync && echo 1 > /proc/sys/vm/drop_caches")
        except:
            pass
    
    async def optimize_async_operations(self, operations: List[Callable], max_concurrent: int = 10):
        """ë¹„ë™ê¸° ì‘ì—… ìµœì í™”"""
        logger.info(f"âš¡ ë¹„ë™ê¸° ì‘ì—… ìµœì í™”: {len(operations)}ê°œ ì‘ì—…")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def controlled_operation(operation):
            async with semaphore:
                return await operation()
        
        start_time = time.time()
        results = await asyncio.gather(
            *[controlled_operation(op) for op in operations],
            return_exceptions=True
        )
        end_time = time.time()
        
        execution_time = end_time - start_time
        logger.info(f"âœ… ë¹„ë™ê¸° ìµœì í™” ì™„ë£Œ: {execution_time:.2f}ì´ˆ")
        
        return results
    
    def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ìµœê·¼ Nì‹œê°„ ë°ì´í„° ì¡°íšŒ
            since_time = (datetime.now() - timedelta(hours=hours)).isoformat()
            
            cursor.execute('''
                SELECT * FROM performance_metrics 
                WHERE timestamp > ? 
                ORDER BY timestamp DESC
            ''', (since_time,))
            
            rows = cursor.fetchall()
            conn.close()
            
            if not rows:
                return {"message": "ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # í†µê³„ ê³„ì‚°
            cpu_values = [row[2] for row in rows if row[2] is not None]
            memory_values = [row[3] for row in rows if row[3] is not None]
            execution_times = [row[11] for row in rows if row[11] is not None]
            
            report = {
                "period_hours": hours,
                "total_records": len(rows),
                "cpu_stats": {
                    "avg": sum(cpu_values) / len(cpu_values) if cpu_values else 0,
                    "max": max(cpu_values) if cpu_values else 0,
                    "min": min(cpu_values) if cpu_values else 0
                },
                "memory_stats": {
                    "avg": sum(memory_values) / len(memory_values) if memory_values else 0,
                    "max": max(memory_values) if memory_values else 0,
                    "min": min(memory_values) if memory_values else 0
                },
                "execution_time_stats": {
                    "avg": sum(execution_times) / len(execution_times) if execution_times else 0,
                    "max": max(execution_times) if execution_times else 0,
                    "min": min(execution_times) if execution_times else 0
                },
                "top_slow_functions": self._get_slow_functions(rows),
                "recommendations": self._generate_recommendations(rows)
            }
            
            return report
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _get_slow_functions(self, rows: List) -> List[Dict]:
        """ëŠë¦° í•¨ìˆ˜ ëª©ë¡ ìƒì„±"""
        function_times = {}
        
        for row in rows:
            func_name = row[10]  # function_name
            exec_time = row[11]  # execution_time
            
            if func_name and exec_time:
                if func_name not in function_times:
                    function_times[func_name] = []
                function_times[func_name].append(exec_time)
        
        # í‰ê·  ì‹¤í–‰ ì‹œê°„ ê³„ì‚° ë° ì •ë ¬
        avg_times = []
        for func_name, times in function_times.items():
            avg_time = sum(times) / len(times)
            avg_times.append({
                "function": func_name,
                "avg_time": avg_time,
                "call_count": len(times),
                "max_time": max(times)
            })
        
        return sorted(avg_times, key=lambda x: x['avg_time'], reverse=True)[:10]
    
    def _generate_recommendations(self, rows: List) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # CPU ì‚¬ìš©ë¥  ë¶„ì„
        cpu_values = [row[2] for row in rows if row[2] is not None]
        if cpu_values and sum(cpu_values) / len(cpu_values) > 70:
            recommendations.append("í‰ê·  CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ ì¦ëŒ€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë¶„ì„
        memory_values = [row[3] for row in rows if row[3] is not None]
        if memory_values and sum(memory_values) / len(memory_values) > 80:
            recommendations.append("í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì‹¤í–‰ ì‹œê°„ ë¶„ì„
        execution_times = [row[11] for row in rows if row[11] is not None and row[11] > 10]
        if execution_times:
            recommendations.append("ì¼ë¶€ í•¨ìˆ˜ì˜ ì‹¤í–‰ ì‹œê°„ì´ ê¹ë‹ˆë‹¤. ì½”ë“œ ìµœì í™”ë¥¼ ê²€í† í•˜ì„¸ìš”.")
        
        return recommendations
    
    def start_continuous_monitoring(self, interval: int = 60):
        """ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_active:
            logger.warning("ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(
            target=self._continuous_monitor,
            args=(interval,),
            daemon=True
        )
        self.monitoring_thread.start()
        logger.info(f"ğŸ“Š ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
    
    def stop_continuous_monitoring(self):
        """ì—°ì† ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("ğŸ“Š ì—°ì† ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _continuous_monitor(self, interval: int):
        """ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        while self.monitoring_active:
            try:
                metrics = self._collect_system_metrics()
                
                # ì„ê³„ì¹˜ ì²´í¬
                if metrics.get('cpu_percent', 0) > self.thresholds['cpu_percent']:
                    logger.warning(f"âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {metrics['cpu_percent']:.1f}%")
                
                if metrics.get('memory_percent', 0) > self.thresholds['memory_percent']:
                    logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {metrics['memory_percent']:.1f}%")
                
                time.sleep(interval)
                
            except Exception as e:
                logger.error(f"ì—°ì† ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(interval)
    
    def __del__(self):
        """ì†Œë©¸ì"""
        self.stop_continuous_monitoring()
        if hasattr(self, 'thread_pool'):
            self.thread_pool.shutdown(wait=True)
        if hasattr(self, 'process_pool'):
            self.process_pool.shutdown(wait=True)

    async def optimize_system(self):
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰"""
        try:
            logger.info("ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ì‹œì‘")
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            await self.optimize_memory_usage()
            
            # ìºì‹œ ìµœì í™”
            await self.optimize_cache()
            
            # ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
            await self.optimize_database()
            
            # ë„¤íŠ¸ì›Œí¬ ìµœì í™”
            await self.optimize_network()
            
            logger.info("ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    async def optimize_cache(self):
        """ìºì‹œ ìµœì í™”"""
        try:
            logger.info("ìºì‹œ ìµœì í™” ì‹œì‘")
            
            # ìºì‹œ íˆíŠ¸ìœ¨ ë¶„ì„
            hit_rate = self._analyze_cache_hit_rate()
            
            # ë¶ˆí•„ìš”í•œ ìºì‹œ ì •ë¦¬
            cleared_count = self._clear_unused_cache()
            
            logger.info(f"ìºì‹œ ìµœì í™” ì™„ë£Œ - íˆíŠ¸ìœ¨: {hit_rate:.2%}, ì •ë¦¬ëœ í•­ëª©: {cleared_count}")
            
        except Exception as e:
            logger.error(f"ìºì‹œ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            
    async def optimize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
        try:
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘")
            
            # ì¸ë±ìŠ¤ ìµœì í™”
            optimized_indexes = self._optimize_indexes()
            
            # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
            cleaned_records = self._cleanup_old_data()
            
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ - ì¸ë±ìŠ¤: {optimized_indexes}, ì •ë¦¬ëœ ë ˆì½”ë“œ: {cleaned_records}")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            
    async def optimize_network(self):
        """ë„¤íŠ¸ì›Œí¬ ìµœì í™”"""
        try:
            logger.info("ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì‹œì‘")
            
            # ì—°ê²° í’€ ìµœì í™”
            pool_size = self._optimize_connection_pool()
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • ìµœì í™”
            timeout_config = self._optimize_timeouts()
            
            logger.info(f"ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì™„ë£Œ - í’€ í¬ê¸°: {pool_size}, íƒ€ì„ì•„ì›ƒ: {timeout_config}")
            
        except Exception as e:
            logger.error(f"ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            
    def _analyze_cache_hit_rate(self) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ë¶„ì„"""
        # Mock íˆíŠ¸ìœ¨ ë°˜í™˜
        return 0.85
        
    def _clear_unused_cache(self) -> int:
        """ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìºì‹œ ì •ë¦¬"""
        # Mock ì •ë¦¬ ê°œìˆ˜ ë°˜í™˜
        return 150
        
    def _optimize_indexes(self) -> int:
        """ì¸ë±ìŠ¤ ìµœì í™”"""
        # Mock ìµœì í™”ëœ ì¸ë±ìŠ¤ ìˆ˜ ë°˜í™˜
        return 5
        
    def _cleanup_old_data(self) -> int:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        # Mock ì •ë¦¬ëœ ë ˆì½”ë“œ ìˆ˜ ë°˜í™˜
        return 1000
        
    def _optimize_connection_pool(self) -> int:
        """ì—°ê²° í’€ ìµœì í™”"""
        # Mock í’€ í¬ê¸° ë°˜í™˜
        return 20
        
    def _optimize_timeouts(self) -> Dict[str, int]:
        """íƒ€ì„ì•„ì›ƒ ìµœì í™”"""
        # Mock íƒ€ì„ì•„ì›ƒ ì„¤ì • ë°˜í™˜
        return {
            'connect_timeout': 10,
            'read_timeout': 30,
            'write_timeout': 15
        }

# ì „ì—­ ì„±ëŠ¥ ìµœì í™” ì¸ìŠ¤í„´ìŠ¤
performance_optimizer = PerformanceOptimizer()

# ë°ì½”ë ˆì´í„° ë‹¨ì¶•í‚¤
monitor_performance = performance_optimizer.performance_monitor

async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    optimizer = PerformanceOptimizer()
    
    @optimizer.performance_monitor("test_function")
    async def test_function():
        await asyncio.sleep(1)
        return "í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = await test_function()
    print(f"ê²°ê³¼: {result}")
    
    # ì„±ëŠ¥ ë¦¬í¬íŠ¸
    report = optimizer.get_performance_report(1)
    print(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸: {json.dumps(report, indent=2, ensure_ascii=False)}")

if __name__ == "__main__":
    asyncio.run(main()) 