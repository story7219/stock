#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š í†µí•© ë°ì´í„° ë¡œë”
ì™¸ë¶€ API â†’ ë°ì´í„° ì •ì œ â†’ AI ì „ì²˜ë¦¬ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
"""

import asyncio
import logging
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
import json
import os
from pathlib import Path

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from data.external.finance_api import FinanceAPIClient
from data.processed.data_cleaner import DataCleaner, CleanedStockData
from ai_integration.ai_preprocessor import AIDataPreprocessor

logger = logging.getLogger(__name__)

class DataLoader:
    """í†µí•© ë°ì´í„° ë¡œë” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.api_client = FinanceAPIClient()
        self.data_cleaner = DataCleaner()
        self.ai_preprocessor = AIDataPreprocessor()
        
        # ìºì‹œ ì„¤ì •
        self.cache_dir = Path("data/processed/cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_duration = timedelta(hours=1)  # 1ì‹œê°„ ìºì‹œ
        
        # ë°ì´í„° í’ˆì§ˆ ì„¤ì •
        self.min_data_quality = 60.0
        
        # ì‹œì¥ë³„ ê¸°ë³¸ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        self.default_symbols = {
            'KR': [
                '005930',  # ì‚¼ì„±ì „ì
                '000660',  # SKí•˜ì´ë‹‰ìŠ¤
                '035420',  # NAVER
                '207940',  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
                '005380',  # í˜„ëŒ€ì°¨
                '051910',  # LGí™”í•™
                '006400',  # ì‚¼ì„±SDI
                '035720',  # ì¹´ì¹´ì˜¤
                '068270',  # ì…€íŠ¸ë¦¬ì˜¨
                '028260',  # ì‚¼ì„±ë¬¼ì‚°
            ],
            'US': [
                'AAPL',    # Apple
                'MSFT',    # Microsoft
                'GOOGL',   # Alphabet
                'AMZN',    # Amazon
                'TSLA',    # Tesla
                'META',    # Meta
                'NVDA',    # NVIDIA
                'NFLX',    # Netflix
                'DIS',     # Disney
                'PYPL',    # PayPal
            ]
        }
    
    async def load_market_data(self, market: str = 'KR', symbols: Optional[List[str]] = None, 
                              use_cache: bool = True) -> List[CleanedStockData]:
        """ì‹œì¥ ë°ì´í„° ë¡œë“œ (ì „ì²´ íŒŒì´í”„ë¼ì¸)"""
        try:
            logger.info(f"{market} ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹œì‘")
            
            # 1ë‹¨ê³„: ì‹¬ë³¼ ëª©ë¡ ê²°ì •
            if symbols is None:
                symbols = self.default_symbols.get(market, [])
            
            # 2ë‹¨ê³„: ìºì‹œ í™•ì¸
            if use_cache:
                cached_data = self._load_from_cache(market, symbols)
                if cached_data:
                    logger.info(f"ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ: {len(cached_data)} ì¢…ëª©")
                    return cached_data
            
            # 3ë‹¨ê³„: ì™¸ë¶€ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            raw_data = await self._fetch_raw_data(market, symbols)
            
            # 4ë‹¨ê³„: ë°ì´í„° ì •ì œ
            cleaned_data = self._clean_data(raw_data)
            
            # 5ë‹¨ê³„: í’ˆì§ˆ í•„í„°ë§
            filtered_data = self._filter_by_quality(cleaned_data)
            
            # 6ë‹¨ê³„: ìºì‹œ ì €ì¥
            if use_cache:
                self._save_to_cache(market, symbols, filtered_data)
            
            logger.info(f"{market} ì‹œì¥ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(filtered_data)} ì¢…ëª©")
            return filtered_data
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({market}): {e}")
            raise
    
    async def load_stock_data(self, symbol: str, market: str = 'KR') -> Optional[CleanedStockData]:
        """ê°œë³„ ì¢…ëª© ë°ì´í„° ë¡œë“œ"""
        try:
            # ì™¸ë¶€ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            async with self.api_client as client:
                raw_data = await client.get_stock_data(symbol, market)
            
            if not raw_data:
                return None
            
            # ë°ì´í„° ì •ì œ
            cleaned_data = self.data_cleaner.clean_stock_data(raw_data)
            
            # í’ˆì§ˆ ê²€ì¦
            if cleaned_data and cleaned_data.data_quality >= self.min_data_quality:
                return cleaned_data
            else:
                logger.warning(f"í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬: {symbol} (í’ˆì§ˆ: {cleaned_data.data_quality if cleaned_data else 0})")
                return None
                
        except Exception as e:
            logger.error(f"ì¢…ëª© ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({symbol}): {e}")
            return None
    
    async def load_sector_data(self, sector: str, market: str = 'KR', limit: int = 50) -> List[CleanedStockData]:
        """ì„¹í„°ë³„ ë°ì´í„° ë¡œë“œ"""
        try:
            logger.info(f"{market} ì‹œì¥ {sector} ì„¹í„° ë°ì´í„° ë¡œë“œ ì‹œì‘")
            
            # ì™¸ë¶€ APIì—ì„œ ì„¹í„° ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            async with self.api_client as client:
                if market == 'KR':
                    sector_symbols = await client.get_sector_stocks_kr(sector, limit)
                else:
                    sector_symbols = await client.get_sector_stocks_us(sector, limit)
            
            if not sector_symbols:
                logger.warning(f"ì„¹í„° ì¢…ëª© ëª©ë¡ì´ ë¹„ì–´ìˆìŒ: {sector}")
                return []
            
            # ê° ì¢…ëª©ì˜ ë°ì´í„° ë¡œë“œ
            sector_data = []
            for symbol in sector_symbols:
                stock_data = await self.load_stock_data(symbol, market)
                if stock_data:
                    sector_data.append(stock_data)
            
            logger.info(f"{sector} ì„¹í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(sector_data)} ì¢…ëª©")
            return sector_data
            
        except Exception as e:
            logger.error(f"ì„¹í„° ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({sector}): {e}")
            return []
    
    def prepare_for_ai_analysis(self, stocks: List[CleanedStockData], 
                               analysis_type: str = 'investment') -> Dict[str, Any]:
        """AI ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # AI ì „ì²˜ë¦¬ê¸°ë¥¼ í†µí•´ ë°ì´í„° ë³€í™˜
            ai_ready_data = self.ai_preprocessor.prepare_for_analysis(
                stocks, analysis_type
            )
            
            logger.info(f"AI ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(stocks)} ì¢…ëª©")
            return ai_ready_data
            
        except Exception as e:
            logger.error(f"AI ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise
    
    async def _fetch_raw_data(self, market: str, symbols: List[str]) -> List[Dict[str, Any]]:
        """ì™¸ë¶€ APIì—ì„œ ì›ì‹œ ë°ì´í„° ìˆ˜ì§‘"""
        raw_data = []
        
        async with self.api_client as client:
            # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
            tasks = []
            for symbol in symbols:
                task = client.get_stock_data(symbol, market)
                tasks.append(task)
            
            # ëª¨ë“  íƒœìŠ¤í¬ ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì²˜ë¦¬
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜ ({symbols[i]}): {result}")
                elif result:
                    raw_data.append(result)
        
        logger.info(f"ì›ì‹œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(raw_data)}/{len(symbols)} ì¢…ëª©")
        return raw_data
    
    def _clean_data(self, raw_data: List[Dict[str, Any]]) -> List[CleanedStockData]:
        """ë°ì´í„° ì •ì œ"""
        return self.data_cleaner.clean_batch_data(raw_data)
    
    def _filter_by_quality(self, stocks: List[CleanedStockData]) -> List[CleanedStockData]:
        """í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§"""
        return self.data_cleaner.filter_by_quality(stocks, self.min_data_quality)
    
    def _get_cache_key(self, market: str, symbols: List[str]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        symbols_str = "_".join(sorted(symbols))
        return f"{market}_{hash(symbols_str)}"
    
    def _get_cache_filename(self, cache_key: str) -> str:
        """ìºì‹œ íŒŒì¼ëª… ìƒì„±"""
        return f"cache_{cache_key}.json"
    
    def _is_cache_valid(self, cache_file: Path) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        if not cache_file.exists():
            return False
        
        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
        mtime = datetime.fromtimestamp(cache_file.stat().st_mtime)
        return datetime.now() - mtime < self.cache_duration
    
    def _load_from_cache(self, market: str, symbols: List[str]) -> Optional[List[CleanedStockData]]:
        """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            cache_key = self._get_cache_key(market, symbols)
            cache_file = self.cache_dir / self._get_cache_filename(cache_key)
            
            if not self._is_cache_valid(cache_file):
                return None
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # CleanedStockData ê°ì²´ë¡œ ë³€í™˜
            stocks = []
            for stock_data in cache_data.get('stocks', []):
                stock = CleanedStockData(**stock_data)
                stocks.append(stock)
            
            return stocks
            
        except Exception as e:
            logger.debug(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _save_to_cache(self, market: str, symbols: List[str], stocks: List[CleanedStockData]):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        try:
            cache_key = self._get_cache_key(market, symbols)
            cache_file = self.cache_dir / self._get_cache_filename(cache_key)
            
            cache_data = {
                "market": market,
                "symbols": symbols,
                "cached_at": datetime.now().isoformat(),
                "stocks": [stock.to_dict() for stock in stocks]
            }
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_file}")
            
        except Exception as e:
            logger.error(f"ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def clear_cache(self, market: str = None):
        """ìºì‹œ ì‚­ì œ"""
        try:
            cache_files = list(self.cache_dir.glob("cache_*.json"))
            
            deleted_count = 0
            for cache_file in cache_files:
                if market is None:
                    # ëª¨ë“  ìºì‹œ ì‚­ì œ
                    cache_file.unlink()
                    deleted_count += 1
                else:
                    # íŠ¹ì • ì‹œì¥ ìºì‹œë§Œ ì‚­ì œ
                    if cache_file.name.startswith(f"cache_{market}_"):
                        cache_file.unlink()
                        deleted_count += 1
            
            logger.info(f"ìºì‹œ ì‚­ì œ ì™„ë£Œ: {deleted_count} íŒŒì¼")
            
        except Exception as e:
            logger.error(f"ìºì‹œ ì‚­ì œ ì˜¤ë¥˜: {e}")
    
    def get_data_statistics(self, stocks: List[CleanedStockData]) -> Dict[str, Any]:
        """ë°ì´í„° í†µê³„ ì •ë³´"""
        if not stocks:
            return {}
        
        # ê¸°ë³¸ í†µê³„
        stats = self.data_cleaner.get_quality_statistics(stocks)
        
        # ì¶”ê°€ í†µê³„
        markets = {}
        sectors = {}
        
        for stock in stocks:
            # ì‹œì¥ë³„ ë¶„í¬
            market = stock.market
            markets[market] = markets.get(market, 0) + 1
            
            # ì„¹í„°ë³„ ë¶„í¬
            if stock.sector:
                sector = stock.sector
                sectors[sector] = sectors.get(sector, 0) + 1
        
        stats.update({
            "ì‹œì¥ë³„_ë¶„í¬": markets,
            "ì„¹í„°ë³„_ë¶„í¬": sectors,
            "í‰ê· _ì‹œê°€ì´ì•¡": round(np.mean([s.market_cap for s in stocks if s.market_cap]), 2),
            "í‰ê· _ì£¼ê°€": round(np.mean([s.price for s in stocks if s.price]), 2)
        })
        
        return stats
    
    async def get_market_overview(self, market: str = 'KR') -> Dict[str, Any]:
        """ì‹œì¥ ê°œìš” ì •ë³´"""
        try:
            # ì£¼ìš” ì¢…ëª© ë°ì´í„° ë¡œë“œ
            stocks = await self.load_market_data(market)
            
            if not stocks:
                return {"error": f"{market} ì‹œì¥ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            # ì‹œì¥ í†µê³„ ê³„ì‚°
            overview = {
                "ì‹œì¥": market,
                "ë¶„ì„_ì‹œê°„": datetime.now().isoformat(),
                "ì´_ì¢…ëª©ìˆ˜": len(stocks),
                "ë°ì´í„°_í†µê³„": self.get_data_statistics(stocks)
            }
            
            # ìƒìœ„ ì¢…ëª© (ì‹œê°€ì´ì•¡ ê¸°ì¤€)
            top_stocks = sorted(stocks, key=lambda x: x.market_cap or 0, reverse=True)[:10]
            overview["ìƒìœ„_ì¢…ëª©"] = [
                {
                    "ì¢…ëª©ì½”ë“œ": stock.symbol,
                    "ì¢…ëª©ëª…": stock.name,
                    "ì‹œê°€ì´ì•¡": stock.market_cap,
                    "ì£¼ê°€": stock.price,
                    "ì„¹í„°": stock.sector
                }
                for stock in top_stocks
            ]
            
            return overview
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ê°œìš” ìƒì„± ì˜¤ë¥˜ ({market}): {e}")
            return {"error": str(e)}

# í¸ì˜ í•¨ìˆ˜ë“¤
async def load_korean_stocks(symbols: List[str] = None) -> List[CleanedStockData]:
    """í•œêµ­ ì£¼ì‹ ë°ì´í„° ë¡œë“œ"""
    loader = DataLoader()
    return await loader.load_market_data('KR', symbols)

async def load_us_stocks(symbols: List[str] = None) -> List[CleanedStockData]:
    """ë¯¸êµ­ ì£¼ì‹ ë°ì´í„° ë¡œë“œ"""
    loader = DataLoader()
    return await loader.load_market_data('US', symbols)

async def load_stock_for_analysis(symbol: str, market: str = 'KR') -> Optional[Dict[str, Any]]:
    """AI ë¶„ì„ìš© ê°œë³„ ì¢…ëª© ë°ì´í„° ë¡œë“œ"""
    loader = DataLoader()
    stock_data = await loader.load_stock_data(symbol, market)
    
    if stock_data:
        return loader.prepare_for_ai_analysis([stock_data])
    return None 