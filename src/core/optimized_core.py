#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ ìµœì í™”ëœ íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ í•µì‹¬ ëª¨ë“ˆ v3.0
================================================================
- ë¹„ë™ê¸° ê³ ì† ë³‘ë ¬ì²˜ë¦¬
- ë©€í‹°ë ˆë²¨ ìºì‹± ì‹œìŠ¤í…œ 
- ì»¤ë„¥ì…˜ í’€ë§ ìµœì í™”
- ë©”ëª¨ë¦¬ ìµœì í™”
- ì•ˆì •ì„± ë° ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
"""

import asyncio
import logging
import time
import gc
import weakref
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Callable, TypeVar, Generic
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from contextlib import asynccontextmanager
import aiohttp
import aiodns
from functools import wraps, lru_cache
import psutil
import threading
from collections import defaultdict, deque
import json
import pickle
import sqlite3
import redis
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

T = TypeVar('T')

@dataclass
class SystemConfig:
    """ì‹œìŠ¤í…œ ì„¤ì • í†µí•©"""
    # ì„±ëŠ¥ ì„¤ì •
    max_workers: int = 16
    max_concurrent_requests: int = 100
    connection_pool_size: int = 50
    memory_limit_mb: int = 4096
    cache_ttl_seconds: int = 3600
    
    # ë¹„ë™ê¸° ì„¤ì •
    async_timeout: float = 30.0
    retry_attempts: int = 3
    retry_delay: float = 1.0
    
    # ìºì‹± ì„¤ì •
    cache_levels: int = 3
    l1_cache_size: int = 1000
    l2_cache_size: int = 5000
    l3_cache_size: int = 10000
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    db_pool_size: int = 20
    db_timeout: float = 10.0
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    gc_threshold: int = 700
    memory_check_interval: int = 300
    
    # API ì„¤ì •
    gemini_api_key: str = ""
    rate_limit_per_minute: int = 60

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_times = {}
        self.memory_usage = deque(maxlen=100)
        self.cpu_usage = deque(maxlen=100)
        self._lock = threading.Lock()
    
    def start_timer(self, operation: str) -> str:
        """íƒ€ì´ë¨¸ ì‹œì‘"""
        timer_id = f"{operation}_{int(time.time() * 1000)}"
        self.start_times[timer_id] = time.perf_counter()
        return timer_id
    
    def end_timer(self, timer_id: str) -> float:
        """íƒ€ì´ë¨¸ ì¢…ë£Œ ë° ì¸¡ì •ê°’ ë°˜í™˜"""
        if timer_id in self.start_times:
            duration = time.perf_counter() - self.start_times.pop(timer_id)
            operation = timer_id.split('_')[0]
            with self._lock:
                self.metrics[operation].append(duration)
            return duration
        return 0.0
    
    def record_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        with self._lock:
            self.memory_usage.append(memory_mb)
    
    def record_cpu_usage(self):
        """CPU ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        cpu_percent = psutil.cpu_percent()
        with self._lock:
            self.cpu_usage.append(cpu_percent)
    
    def get_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        with self._lock:
            stats = {}
            for operation, durations in self.metrics.items():
                if durations:
                    stats[operation] = {
                        'count': len(durations),
                        'avg': sum(durations) / len(durations),
                        'min': min(durations),
                        'max': max(durations),
                        'total': sum(durations)
                    }
            
            if self.memory_usage:
                stats['memory'] = {
                    'current_mb': list(self.memory_usage)[-1],
                    'avg_mb': sum(self.memory_usage) / len(self.memory_usage),
                    'max_mb': max(self.memory_usage)
                }
            
            if self.cpu_usage:
                stats['cpu'] = {
                    'current_percent': list(self.cpu_usage)[-1],
                    'avg_percent': sum(self.cpu_usage) / len(self.cpu_usage),
                    'max_percent': max(self.cpu_usage)
                }
            
            return stats

class MultiLevelCache:
    """ë©€í‹°ë ˆë²¨ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        
        # L1: ë©”ëª¨ë¦¬ ìºì‹œ (ê°€ì¥ ë¹ ë¦„)
        self.l1_cache = {}
        self.l1_access_times = {}
        self.l1_lock = threading.RLock()
        
        # L2: Redis ìºì‹œ (ì¤‘ê°„ ì†ë„)
        try:
            self.redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
            self.redis_available = True
        except:
            self.redis_client = None
            self.redis_available = False
            logger.warning("Redis ì—°ê²° ì‹¤íŒ¨, L2 ìºì‹œ ë¹„í™œì„±í™”")
        
        # L3: SQLite ìºì‹œ (ì˜êµ¬ ì €ì¥)
        self.db_path = Path("data/cache.db")
        self.db_path.parent.mkdir(exist_ok=True)
        self._init_sqlite_cache()
        
        # ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì‘ì—…
        self._start_cleanup_task()
    
    def _init_sqlite_cache(self):
        """SQLite ìºì‹œ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(str(self.db_path))
        conn.execute('''
            CREATE TABLE IF NOT EXISTS cache (
                key TEXT PRIMARY KEY,
                value TEXT,
                expires_at TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        conn.close()
    
    def _start_cleanup_task(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì‘ì—… ì‹œì‘"""
        def cleanup_worker():
            while True:
                try:
                    self._cleanup_expired()
                    time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì •ë¦¬
                except Exception as e:
                    logger.error(f"ìºì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        
        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
        cleanup_thread.start()
    
    async def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ (L1 -> L2 -> L3 ìˆœì„œ)"""
        # L1 ìºì‹œ í™•ì¸
        with self.l1_lock:
            if key in self.l1_cache:
                self.l1_access_times[key] = time.time()
                return self.l1_cache[key]
        
        # L2 ìºì‹œ í™•ì¸ (Redis)
        if self.redis_available:
            try:
                value = self.redis_client.get(key)
                if value:
                    data = json.loads(value)
                    # L1 ìºì‹œì— ìŠ¹ê²©
                    await self._promote_to_l1(key, data)
                    return data
            except Exception as e:
                logger.warning(f"Redis ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        
        # L3 ìºì‹œ í™•ì¸ (SQLite)
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.execute(
                'SELECT value FROM cache WHERE key = ? AND expires_at > ?',
                (key, datetime.now())
            )
            row = cursor.fetchone()
            conn.close()
            
            if row:
                data = json.loads(row[0])
                # ìƒìœ„ ìºì‹œì— ìŠ¹ê²©
                await self._promote_to_l2(key, data)
                await self._promote_to_l1(key, data)
                return data
        except Exception as e:
            logger.warning(f"SQLite ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """ìºì‹œì— ê°’ ì €ì¥ (ëª¨ë“  ë ˆë²¨ì— ì €ì¥)"""
        ttl = ttl or self.config.cache_ttl_seconds
        expires_at = datetime.now() + timedelta(seconds=ttl)
        
        # L1 ìºì‹œ ì €ì¥
        await self._promote_to_l1(key, value)
        
        # L2 ìºì‹œ ì €ì¥ (Redis)
        await self._promote_to_l2(key, value, ttl)
        
        # L3 ìºì‹œ ì €ì¥ (SQLite)
        try:
            conn = sqlite3.connect(str(self.db_path))
            conn.execute(
                'INSERT OR REPLACE INTO cache (key, value, expires_at) VALUES (?, ?, ?)',
                (key, json.dumps(value, default=str), expires_at)
            )
            conn.commit()
            conn.close()
        except Exception as e:
            logger.warning(f"SQLite ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    async def _promote_to_l1(self, key: str, value: Any) -> None:
        """L1 ìºì‹œë¡œ ìŠ¹ê²©"""
        with self.l1_lock:
            # L1 ìºì‹œ í¬ê¸° ì œí•œ
            if len(self.l1_cache) >= self.config.l1_cache_size:
                # LRU ë°©ì‹ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = min(self.l1_access_times.keys(), 
                               key=lambda k: self.l1_access_times[k])
                del self.l1_cache[oldest_key]
                del self.l1_access_times[oldest_key]
            
            self.l1_cache[key] = value
            self.l1_access_times[key] = time.time()
    
    async def _promote_to_l2(self, key: str, value: Any, ttl: int = None) -> None:
        """L2 ìºì‹œë¡œ ìŠ¹ê²©"""
        if not self.redis_available:
            return
        
        try:
            ttl = ttl or self.config.cache_ttl_seconds
            self.redis_client.setex(key, ttl, json.dumps(value, default=str))
        except Exception as e:
            logger.warning(f"Redis ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _cleanup_expired(self) -> None:
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        # L1 ìºì‹œëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ TTL ì—†ìŒ
        
        # L3 ìºì‹œ ì •ë¦¬
        try:
            conn = sqlite3.connect(str(self.db_path))
            conn.execute('DELETE FROM cache WHERE expires_at < ?', (datetime.now(),))
            conn.commit()
            conn.close()
        except Exception as e:
            logger.warning(f"ìºì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")

class OptimizedConnectionPool:
    """ìµœì í™”ëœ ì»¤ë„¥ì…˜ í’€"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        self.session_pool = {}
        self.pool_lock = threading.RLock()
        self.connector_args = {
            'limit': config.connection_pool_size,
            'limit_per_host': config.connection_pool_size // 4,
            'ttl_dns_cache': 300,
            'use_dns_cache': True,
            'keepalive_timeout': 30,
            'enable_cleanup_closed': True
        }
    
    @asynccontextmanager
    async def get_session(self, session_key: str = "default"):
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        session = await self._get_or_create_session(session_key)
        try:
            yield session
        finally:
            # ì„¸ì…˜ì€ í’€ì—ì„œ ê´€ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë‹«ì§€ ì•ŠìŒ
            pass
    
    async def _get_or_create_session(self, session_key: str) -> aiohttp.ClientSession:
        """ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        with self.pool_lock:
            if session_key not in self.session_pool:
                connector = aiohttp.TCPConnector(**self.connector_args)
                timeout = aiohttp.ClientTimeout(total=self.config.async_timeout)
                session = aiohttp.ClientSession(
                    connector=connector,
                    timeout=timeout,
                    headers={'User-Agent': 'Investment-AI-System/3.0'}
                )
                self.session_pool[session_key] = session
            
            return self.session_pool[session_key]
    
    async def close_all(self):
        """ëª¨ë“  ì„¸ì…˜ ì¢…ë£Œ"""
        with self.pool_lock:
            for session in self.session_pool.values():
                if not session.closed:
                    await session.close()
            self.session_pool.clear()

class AsyncTaskManager:
    """ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ì"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        self.semaphore = asyncio.Semaphore(config.max_concurrent_requests)
        self.thread_pool = ThreadPoolExecutor(max_workers=config.max_workers)
        self.process_pool = ProcessPoolExecutor(max_workers=min(4, config.max_workers))
        self.active_tasks = set()
        self.task_results = {}
        
    async def run_with_semaphore(self, coro):
        """ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•œ ë™ì‹œ ì‹¤í–‰ ì œí•œ"""
        async with self.semaphore:
            return await coro
    
    async def run_in_thread(self, func: Callable, *args, **kwargs):
        """ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, func, *args, **kwargs)
    
    async def run_in_process(self, func: Callable, *args, **kwargs):
        """í”„ë¡œì„¸ìŠ¤ í’€ì—ì„œ ì‹¤í–‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.process_pool, func, *args, **kwargs)
    
    async def gather_with_limit(self, *coros, return_exceptions=True):
        """ì œí•œëœ ë™ì‹œ ì‹¤í–‰ìœ¼ë¡œ gather"""
        semaphore_coros = [self.run_with_semaphore(coro) for coro in coros]
        return await asyncio.gather(*semaphore_coros, return_exceptions=return_exceptions)
    
    def create_task(self, coro, name: str = None) -> asyncio.Task:
        """ì‘ì—… ìƒì„± ë° ì¶”ì """
        task = asyncio.create_task(coro, name=name)
        self.active_tasks.add(task)
        task.add_done_callback(self.active_tasks.discard)
        return task
    
    async def cancel_all_tasks(self):
        """ëª¨ë“  í™œì„± ì‘ì—… ì·¨ì†Œ"""
        for task in list(self.active_tasks):
            task.cancel()
        
        if self.active_tasks:
            await asyncio.gather(*self.active_tasks, return_exceptions=True)
    
    def shutdown(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.thread_pool.shutdown(wait=True)
        self.process_pool.shutdown(wait=True)

class MemoryOptimizer:
    """ë©”ëª¨ë¦¬ ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self, config: SystemConfig):
        self.config = config
        self.weak_refs = weakref.WeakValueDictionary()
        self.memory_threshold = config.memory_limit_mb
        self.gc_threshold = config.gc_threshold
        self.last_gc_time = time.time()
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_memory_monitor()
    
    def _start_memory_monitor(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        def monitor_worker():
            while True:
                try:
                    self._check_memory_usage()
                    time.sleep(self.config.memory_check_interval)
                except Exception as e:
                    logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
        
        monitor_thread = threading.Thread(target=monitor_worker, daemon=True)
        monitor_thread.start()
    
    def _check_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ë° ìµœì í™”"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        if memory_mb > self.memory_threshold * 0.8:  # 80% ì„ê³„ì¹˜
            logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {memory_mb:.1f}MB")
            self.force_gc()
    
    def force_gc(self):
        """ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜"""
        current_time = time.time()
        if current_time - self.last_gc_time > 60:  # 1ë¶„ì— í•œ ë²ˆë§Œ
            collected = gc.collect()
            self.last_gc_time = current_time
            logger.info(f"ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì™„ë£Œ: {collected}ê°œ ê°ì²´ ì •ë¦¬")
    
    def register_weak_ref(self, key: str, obj: Any):
        """ì•½í•œ ì°¸ì¡° ë“±ë¡"""
        self.weak_refs[key] = obj
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ í†µê³„ ë°˜í™˜"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent(),
            'weak_refs_count': len(self.weak_refs),
            'gc_counts': gc.get_count()
        }

class OptimizedCore:
    """ìµœì í™”ëœ í•µì‹¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Optional[SystemConfig] = None):
        self.config = config or SystemConfig()
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.performance_monitor = PerformanceMonitor()
        self.cache = MultiLevelCache(self.config)
        self.connection_pool = OptimizedConnectionPool(self.config)
        self.task_manager = AsyncTaskManager(self.config)
        self.memory_optimizer = MemoryOptimizer(self.config)
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.startup_time = datetime.now()
        
        logger.info("ğŸš€ ìµœì í™”ëœ ì½”ì–´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if self.is_initialized:
            return
        
        timer_id = self.performance_monitor.start_timer("system_init")
        
        try:
            # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‘ì—…ë“¤
            init_tasks = [
                self._warm_up_cache(),
                self._test_connections(),
                self._optimize_memory()
            ]
            
            await self.task_manager.gather_with_limit(*init_tasks)
            
            self.is_initialized = True
            duration = self.performance_monitor.end_timer(timer_id)
            logger.info(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({duration:.2f}ì´ˆ)")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _warm_up_cache(self):
        """ìºì‹œ ì›Œë°ì—…"""
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
        await self.cache.set("system_status", "initialized")
    
    async def _test_connections(self):
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        async with self.connection_pool.get_session() as session:
            # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
            pass
    
    async def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        self.memory_optimizer.force_gc()
    
    async def execute_with_retry(self, 
                                coro: Callable, 
                                *args, 
                                max_retries: int = None,
                                delay: float = None,
                                **kwargs) -> Any:
        """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ì‹¤í–‰"""
        max_retries = max_retries or self.config.retry_attempts
        delay = delay or self.config.retry_delay
        
        last_exception = None
        
        for attempt in range(max_retries + 1):
            try:
                if asyncio.iscoroutinefunction(coro):
                    return await coro(*args, **kwargs)
                else:
                    return await self.task_manager.run_in_thread(coro, *args, **kwargs)
                    
            except Exception as e:
                last_exception = e
                if attempt < max_retries:
                    await asyncio.sleep(delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{max_retries}: {e}")
                else:
                    logger.error(f"ìµœì¢… ì‹¤íŒ¨ ({max_retries + 1}íšŒ ì‹œë„): {e}")
        
        raise last_exception
    
    def performance_decorator(self, operation_name: str):
        """ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                timer_id = self.performance_monitor.start_timer(operation_name)
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    self.performance_monitor.end_timer(timer_id)
            
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                timer_id = self.performance_monitor.start_timer(operation_name)
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    self.performance_monitor.end_timer(timer_id)
            
            return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
        
        return decorator
    
    async def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            'initialized': self.is_initialized,
            'uptime_seconds': (datetime.now() - self.startup_time).total_seconds(),
            'performance': self.performance_monitor.get_stats(),
            'memory': self.memory_optimizer.get_memory_stats(),
            'active_tasks': len(self.task_manager.active_tasks),
            'cache_stats': {
                'l1_size': len(self.cache.l1_cache),
                'redis_available': self.cache.redis_available
            }
        }
    
    async def shutdown(self):
        """ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹œì‘...")
        
        try:
            # í™œì„± ì‘ì—… ì·¨ì†Œ
            await self.task_manager.cancel_all_tasks()
            
            # ì»¤ë„¥ì…˜ í’€ ì¢…ë£Œ
            await self.connection_pool.close_all()
            
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            self.task_manager.shutdown()
            
            logger.info("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_core_instance = None

def get_core() -> OptimizedCore:
    """ì „ì—­ ì½”ì–´ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _core_instance
    if _core_instance is None:
        _core_instance = OptimizedCore()
    return _core_instance

async def initialize_core(config: Optional[SystemConfig] = None) -> OptimizedCore:
    """ì½”ì–´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global _core_instance
    if _core_instance is None:
        _core_instance = OptimizedCore(config)
    
    await _core_instance.initialize()
    return _core_instance 