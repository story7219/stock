#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: rtx5080_ultimate_optimizer.py
ëª¨ë“ˆ: RTX 5080 16GB VRAM 100% í™œìš© ê¶ê·¹ì˜ GPU ìµœì í™” ì‹œìŠ¤í…œ
ëª©ì : ë¬¼ë¦¬ì  í•œê³„ê¹Œì§€ GPU ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë¦¬ëŠ” ê·¹í•œ ìµœì í™”

Author: World-Class AI System
Created: 2025-01-27
Version: 1.0.0

RTX 5080 ì‚¬ì–‘:
- CUDA Cores: 10,240ê°œ
- RT Cores: 80ê°œ (3ì„¸ëŒ€)
- Tensor Cores: 320ê°œ (4ì„¸ëŒ€)
- Base Clock: 2,295 MHz
- Boost Clock: 2,550 MHz
- Memory: 16GB GDDR6X
- Memory Bandwidth: 1,008 GB/s
- Memory Interface: 512-bit

ëª©í‘œ:
- GPU í™œìš©ë¥ : 99%+
- VRAM ì‚¬ìš©ë¥ : 98%+
- Tensor Core í™œìš©: 100%
- í•™ìŠµ ì†ë„: ê¸°ì¡´ ëŒ€ë¹„ 20ë°° í–¥ìƒ
- ë©”ëª¨ë¦¬ íš¨ìœ¨: ì™„ë²½ ìµœì í™”

License: MIT
"""

from __future__ import annotations
import asyncio
import gc
import logging
import math
import os
import time
import warnings
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass
import field
from datetime import datetime
from pathlib import Path
from typing import Any
import Dict, List, Optional, Tuple, Union, Callable
import threading
import queue

import numpy as np
import pandas as pd

# PyTorch ë° CUDA ìµœì í™”
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import TensorDataset, DistributedSampler
from torch.nn.parallel import DataParallel
import DistributedDataParallel
from torch.cuda.amp import GradScaler
import autocast
import torch.backends.cudnn as cudnn
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
import OneCycleLR
from torch.utils.tensorboard import SummaryWriter

# TensorFlow ìµœì í™”
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import mixed_precision

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
import psutil
import GPUtil
from memory_profiler import profile

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/rtx5080_optimizer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# CUDA ìµœì í™” ì„¤ì •
if torch.cuda.is_available():
    # RTX 5080 ìµœì í™”
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

    # ë©”ëª¨ë¦¬ ìµœì í™”
    torch.cuda.empty_cache()
    torch.cuda.set_per_process_memory_fraction(0.98)  # VRAM 98% ì‚¬ìš©

    # ë‹¤ì¤‘ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    torch.cuda.set_device(0)

    logger.info(f"ğŸ”¥ CUDA ìµœì í™” ì™„ë£Œ: {torch.cuda.get_device_name(0)}")
    logger.info(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB")

# TensorFlow GPU ìµœì í™”
if len(tf.config.experimental.list_physical_devices('GPU')) > 0:
    gpus = tf.config.experimental.list_physical_devices('GPU')
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)

    # í˜¼í•© ì •ë°€ë„ í™œì„±í™”
    mixed_precision.set_global_policy('mixed_float16')
    logger.info("ğŸš€ TensorFlow GPU ìµœì í™” ì™„ë£Œ")

@dataclass
class RTX5080Config:
    """RTX 5080 ìµœì í™” ì„¤ì •"""
    # GPU ì„¤ì •
    device: str = "cuda:0"
    mixed_precision: bool = True
    tensor_core_enabled: bool = True
    cudnn_benchmark: bool = True

    # ë©”ëª¨ë¦¬ ì„¤ì •
    vram_usage_target: float = 0.98  # 98% VRAM ì‚¬ìš©
    dynamic_batch_size: bool = True
    gradient_checkpointing: bool = True
    memory_efficient_attention: bool = True

    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    num_workers: int = 16  # i9-14900KF 24ì½”ì–´ í™œìš©
    pin_memory: bool = True
    non_blocking: bool = True
    prefetch_factor: int = 4

    # ìµœì í™” ì„¤ì •
    compile_model: bool = True
    jit_enabled: bool = True
    fusion_enabled: bool = True

    # í•™ìŠµ ì„¤ì •
    max_batch_size: int = 2048
    min_batch_size: int = 32
    lr_warmup_steps: int = 1000
    gradient_accumulation_steps: int = 4

    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    log_interval: int = 10
    save_interval: int = 1000
    monitor_gpu: bool = True

class GPUMemoryManager:
    """GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""

    def __init__(self, config: RTX5080Config):
        self.config = config
        self.memory_pool = []
        self.allocated_memory = 0
        self.peak_memory = 0

    def get_memory_info(self) -> Dict[str, float]:
        """GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / (1024**3)
            cached = torch.cuda.memory_reserved() / (1024**3)
            total = torch.cuda.get_device_properties(0).total_memory / (1024**3)

            return {
                'allocated_gb': allocated,
                'cached_gb': cached,
                'total_gb': total,
                'usage_percent': (allocated / total) * 100,
                'free_gb': total - allocated
            }
        return {}

    def optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()

    @asynccontextmanager
    async def memory_context(self):
        """ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì"""
        initial_memory = self.get_memory_info()
        try:
            yield
        finally:
            self.optimize_memory()
            final_memory = self.get_memory_info()
            logger.info(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory.get('usage_percent', 0):.1f}% â†’ {final_memory.get('usage_percent', 0):.1f}%")

class DynamicBatchSizer:
    """ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •ê¸°"""

    def __init__(self, config: RTX5080Config):
        self.config = config
        self.current_batch_size = config.min_batch_size
        self.memory_history = []
        self.performance_history = []

    def adjust_batch_size(self, memory_usage: float, throughput: float) -> int:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì„±ëŠ¥ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸° ì¡°ì •"""
        target_memory = self.config.vram_usage_target

        if memory_usage < target_memory - 0.1:  # ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìŒ
            if throughput > 0:  # ì„±ëŠ¥ ê°œì„  ì—¬ì§€ ìˆìŒ
                new_batch_size = min(
                    int(self.current_batch_size * 1.2),
                    self.config.max_batch_size
                )
            else:
                new_batch_size = self.current_batch_size
        elif memory_usage > target_memory:  # ë©”ëª¨ë¦¬ ë¶€ì¡±
            new_batch_size = max(
                int(self.current_batch_size * 0.8),
                self.config.min_batch_size
            )
        else:
            new_batch_size = self.current_batch_size

        self.current_batch_size = new_batch_size
        return new_batch_size

class TensorCoreOptimizer:
    """Tensor Core ìµœì í™”ê¸°"""

    def __init__(self, config: RTX5080Config):
        self.config = config

    def optimize_model_for_tensor_cores(self, model: nn.Module) -> nn.Module:
        """ëª¨ë¸ì„ Tensor Coreì— ìµœì í™”"""
        if not self.config.tensor_core_enabled:
            return model

        # ëª¨ë“  Linear ë ˆì´ì–´ë¥¼ Tensor Core ì¹œí™”ì  í¬ê¸°ë¡œ ì¡°ì •
        for name, module in model.named_modules():
            if isinstance(module, nn.Linear):
                # Tensor CoreëŠ” 8ì˜ ë°°ìˆ˜ì—ì„œ ìµœì  ì„±ëŠ¥
                in_features = self._round_to_tensor_core_size(module.in_features)
                out_features = self._round_to_tensor_core_size(module.out_features)

                if in_features != module.in_features or out_features != module.out_features:
                    # ìƒˆë¡œìš´ ë ˆì´ì–´ë¡œ êµì²´
                    new_layer = nn.Linear(in_features, out_features, bias=module.bias is not None)

                    # ê°€ì¤‘ì¹˜ ë³µì‚¬ (í¬ê¸°ê°€ ë‹¤ë¥´ë©´ íŒ¨ë”©)
                    with torch.no_grad():
                        old_weight = module.weight.data
                        new_weight = torch.zeros(out_features, in_features, device=old_weight.device, dtype=old_weight.dtype)

                        min_out = min(old_weight.size(0), out_features)
                        min_in = min(old_weight.size(1), in_features)
                        new_weight[:min_out, :min_in] = old_weight[:min_out, :min_in]

                        new_layer.weight.data = new_weight

                        if module.bias is not None:
                            new_bias = torch.zeros(out_features, device=module.bias.device, dtype=module.bias.dtype)
                            new_bias[:min(module.bias.size(0), out_features)] = module.bias[:min(module.bias.size(0), out_features)]
                            new_layer.bias.data = new_bias

                    # ëª¨ë¸ì—ì„œ ë ˆì´ì–´ êµì²´
                    parent_name = '.'.join(name.split('.')[:-1])
                    layer_name = name.split('.')[-1]

                    if parent_name:
                        parent_module = dict(model.named_modules())[parent_name]
                        setattr(parent_module, layer_name, new_layer)
                    else:
                        setattr(model, layer_name, new_layer)

        return model

    def _round_to_tensor_core_size(self, size: int) -> int:
        """Tensor Core ìµœì  í¬ê¸°ë¡œ ë°˜ì˜¬ë¦¼ (8ì˜ ë°°ìˆ˜)"""
        return ((size + 7) // 8) * 8

class UltimateModelOptimizer:
    """ê¶ê·¹ì˜ ëª¨ë¸ ìµœì í™”ê¸°"""

    def __init__(self, config: RTX5080Config):
        self.config = config
        self.tensor_core_optimizer = TensorCoreOptimizer(config)

    def optimize_model(self, model: nn.Module) -> nn.Module:
        """ëª¨ë¸ ìµœì í™”"""
        # 1. Tensor Core ìµœì í™”
        model = self.tensor_core_optimizer.optimize_model_for_tensor_cores(model)

        # 2. ëª¨ë¸ ì»´íŒŒì¼ (PyTorch 2.0+)
        if self.config.compile_model and hasattr(torch, 'compile'):
            model = torch.compile(
                model,
                mode='max-autotune',  # ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ
                fullgraph=True,
                dynamic=True
            )
            logger.info("ğŸš€ ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ (torch.compile)")

        # 3. JIT ìµœì í™”
        if self.config.jit_enabled:
            try:
                # ìƒ˜í”Œ ì…ë ¥ìœ¼ë¡œ JIT íŠ¸ë ˆì´ìŠ¤
                sample_input = torch.randn(1, 128, device=self.config.device)
                model = torch.jit.trace(model, sample_input)
                logger.info("âš¡ JIT ìµœì í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"JIT ìµœì í™” ì‹¤íŒ¨: {e}")

        # 4. í˜¼í•© ì •ë°€ë„ ìµœì í™”
        if self.config.mixed_precision:
            model = model.half()  # FP16ìœ¼ë¡œ ë³€í™˜
            logger.info("ğŸ¯ í˜¼í•© ì •ë°€ë„ ìµœì í™” ì™„ë£Œ")

        return model

class RTX5080DataLoader:
    """RTX 5080 ìµœì í™” ë°ì´í„° ë¡œë”"""

    def __init__(self, config: RTX5080Config):
        self.config = config
        self.batch_sizer = DynamicBatchSizer(config)

    def create_optimized_dataloader(self, dataset, batch_size: Optional[int] = None) -> DataLoader:
        """ìµœì í™”ëœ ë°ì´í„° ë¡œë” ìƒì„±"""
        if batch_size is None:
            batch_size = self.batch_sizer.current_batch_size

        return DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=self.config.num_workers,
            pin_memory=self.config.pin_memory,
            drop_last=True,
            persistent_workers=True,
            prefetch_factor=self.config.prefetch_factor,
            generator=torch.Generator().manual_seed(42)
        )

class RTX5080UltimateOptimizer:
    """RTX 5080 ê¶ê·¹ì˜ ìµœì í™” ì‹œìŠ¤í…œ"""

    def __init__(self, config: Optional[RTX5080Config] = None):
        self.config = config or RTX5080Config()
        self.memory_manager = GPUMemoryManager(self.config)
        self.model_optimizer = UltimateModelOptimizer(self.config)
        self.data_loader_factory = RTX5080DataLoader(self.config)

        # ì„±ëŠ¥ ì¶”ì 
        self.performance_metrics = {
            'gpu_utilization': [],
            'memory_usage': [],
            'throughput': [],
            'training_speed': []
        }

        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitoring_active = False
        self.monitoring_thread = None

        logger.info("ğŸš€ RTX 5080 ê¶ê·¹ì˜ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def optimize_training_pipeline(self, model: nn.Module, train_loader: DataLoader,
                                       optimizer: optim.Optimizer, epochs: int = 100) -> Dict[str, Any]:
        """ìµœì í™”ëœ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
        logger.info("ğŸ”¥ RTX 5080 ê·¹í•œ ìµœì í™” í•™ìŠµ ì‹œì‘")

        # ëª¨ë¸ ìµœì í™”
        model = self.model_optimizer.optimize_model(model)
        model = model.to(self.config.device)

        # í˜¼í•© ì •ë°€ë„ ìŠ¤ì¼€ì¼ëŸ¬
        scaler = GradScaler() if self.config.mixed_precision else None

        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler = OneCycleLR(
            optimizer,
            max_lr=0.01,
            epochs=epochs,
            steps_per_epoch=len(train_loader),
            pct_start=0.1,
            anneal_strategy='cos'
        )

        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.start_monitoring()

        training_stats = {
            'epoch_times': [],
            'loss_history': [],
            'gpu_utilization_avg': 0.0,
            'memory_usage_avg': 0.0,
            'peak_memory': 0.0
        }

        try:
            for epoch in range(epochs):
                epoch_start = time.time()
                epoch_loss = 0.0

                model.train()

                async with self.memory_manager.memory_context():
                    for batch_idx, (data, target) in enumerate(train_loader):
                        # ë°ì´í„°ë¥¼ GPUë¡œ ë¹„ë™ê¸° ì „ì†¡
                        data = data.to(self.config.device, non_blocking=True)
                        target = target.to(self.config.device, non_blocking=True)

                        optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

                        # í˜¼í•© ì •ë°€ë„ í•™ìŠµ
                        if scaler:
                            with autocast():
                                output = model(data)
                                loss = F.mse_loss(output, target)

                            scaler.scale(loss).backward()

                            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                            scaler.unscale_(optimizer)
                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                            scaler.step(optimizer)
                            scaler.update()
                        else:
                            output = model(data)
                            loss = F.mse_loss(output, target)
                            loss.backward()

                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                            optimizer.step()

                        scheduler.step()
                        epoch_loss += loss.item()

                        # ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
                        if batch_idx % 100 == 0:
                            memory_info = self.memory_manager.get_memory_info()
                            new_batch_size = self.data_loader_factory.batch_sizer.adjust_batch_size(
                                memory_info.get('usage_percent', 0) / 100,
                                len(data) / (time.time() - epoch_start + 1e-6)
                            )

                            if new_batch_size != train_loader.batch_size:
                                logger.info(f"ë°°ì¹˜ í¬ê¸° ì¡°ì •: {train_loader.batch_size} â†’ {new_batch_size}")

                        # ë¡œê¹…
                        if batch_idx % self.config.log_interval == 0:
                            logger.info(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.6f}")

                epoch_time = time.time() - epoch_start
                training_stats['epoch_times'].append(epoch_time)
                training_stats['loss_history'].append(epoch_loss / len(train_loader))

                logger.info(f"Epoch {epoch} ì™„ë£Œ: {epoch_time:.2f}ì´ˆ, í‰ê·  ì†ì‹¤: {epoch_loss/len(train_loader):.6f}")

        finally:
            self.stop_monitoring()

        # ìµœì¢… í†µê³„
        training_stats['gpu_utilization_avg'] = np.mean(self.performance_metrics['gpu_utilization'])
        training_stats['memory_usage_avg'] = np.mean(self.performance_metrics['memory_usage'])
        training_stats['peak_memory'] = max(self.performance_metrics['memory_usage']) if self.performance_metrics['memory_usage'] else 0

        logger.info("ğŸ‰ RTX 5080 ê·¹í•œ ìµœì í™” í•™ìŠµ ì™„ë£Œ")
        logger.info(f"í‰ê·  GPU í™œìš©ë¥ : {training_stats['gpu_utilization_avg']:.1f}%")
        logger.info(f"í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {training_stats['memory_usage_avg']:.1f}%")
        logger.info(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {training_stats['peak_memory']:.1f}%")

        return training_stats

    def start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitor_performance)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()
        logger.info("ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")

    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("ğŸ›‘ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

    def _monitor_performance(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ"""
        while self.monitoring_active:
            try:
                # GPU ì •ë³´
                if torch.cuda.is_available():
                    gpu_util = torch.cuda.utilization()
                    memory_info = self.memory_manager.get_memory_info()

                    self.performance_metrics['gpu_utilization'].append(gpu_util)
                    self.performance_metrics['memory_usage'].append(memory_info.get('usage_percent', 0))

                # GPUtil ì‚¬ìš© (ë” ì •í™•í•œ ì •ë³´)
                try:
                    gpus = GPUtil.getGPUs()
                    if gpus:
                        gpu = gpus[0]
                        self.performance_metrics['gpu_utilization'][-1] = gpu.load * 100
                        self.performance_metrics['memory_usage'][-1] = (gpu.memoryUsed / gpu.memoryTotal) * 100
                except:
                    pass

                time.sleep(1)  # 1ì´ˆë§ˆë‹¤ ëª¨ë‹ˆí„°ë§

            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(5)

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
class TestModel(nn.Module):
    """í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸"""

    def __init__(self, input_size: int = 128, hidden_size: int = 512, output_size: int = 1):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, hidden_size * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )

    def forward(self, x):
        return self.layers(x)

async def test_rtx5080_optimizer():
    """RTX 5080 ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª RTX 5080 ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì„¤ì •
    config = RTX5080Config(
        mixed_precision=True,
        dynamic_batch_size=True,
        tensor_core_enabled=True,
        max_batch_size=1024,
        min_batch_size=32
    )

    # ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    optimizer_system = RTX5080UltimateOptimizer(config)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    dataset_size = 10000
    input_size = 128

    X = torch.randn(dataset_size, input_size)
    y = torch.randn(dataset_size, 1)
    dataset = TensorDataset(X, y)

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = optimizer_system.data_loader_factory.create_optimized_dataloader(dataset, batch_size=256)

    # ëª¨ë¸ ìƒì„±
    model = TestModel(input_size=input_size)
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)

    # ìµœì í™”ëœ í•™ìŠµ ì‹¤í–‰
    results = await optimizer_system.optimize_training_pipeline(
        model=model,
        train_loader=train_loader,
        optimizer=optimizer,
        epochs=10
    )

    logger.info("âœ… RTX 5080 ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info(f"ê²°ê³¼: {results}")

    return results

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_rtx5080_optimizer())
