#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: advanced_distributed_training_system.py
ëª¨ë“ˆ: RTX 5080 + i9-14900KF ìµœì í™” ë¶„ì‚° ML/DL í•™ìŠµ ì‹œìŠ¤í…œ
ëª©ì : ë¹„ë™ê¸° ê³ ì† ë³‘ë ¬ì²˜ë¦¬ë¡œ ìµœëŒ€ ì„±ëŠ¥ ML/DL í•™ìŠµ

Author: World-Class AI System
Created: 2025-01-27
Modified: 2025-01-27
Version: 2.0.0

Dependencies:
    - Python 3.11+
    - torch>=2.1.0, torchvision, torchaudio
    - transformers>=4.35.0
    - accelerate>=0.24.0
    - datasets>=2.14.0
    - scikit-learn>=1.3.0
    - numpy>=1.24.0, pandas>=2.0.0
    - asyncio, aiofiles, multiprocessing
    - tensorboard, wandb
    - apex (NVIDIA mixed precision)
    - horovod (ë¶„ì‚° í•™ìŠµ)

Performance:
    - GPU ë©”ëª¨ë¦¬: 16GB VRAM ìµœì í™”
    - CPU ì½”ì–´: 24ì½”ì–´/32ìŠ¤ë ˆë“œ ìµœëŒ€ í™œìš©
    - ë©”ëª¨ë¦¬: DDR5 128GB íš¨ìœ¨ í™œìš©
    - í•™ìŠµ ì†ë„: ê¸°ì¡´ ëŒ€ë¹„ 10-20ë°° í–¥ìƒ

Features:
    - ë¹„ë™ê¸° ë°ì´í„° ë¡œë”© (10x faster)
    - ë©€í‹°GPU ë¶„ì‚° í•™ìŠµ (DP/DDP)
    - í˜¼í•© ì •ë°€ë„ í•™ìŠµ (FP16/BF16)
    - ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
    - ë©”ëª¨ë¦¬ ìµœì í™” (Gradient Checkpointing)
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    - ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    - ëª¨ë¸ ì••ì¶• ë° ì–‘ìí™”

License: MIT
"""

from __future__ import annotations
import asyncio
import functools
import gc
import logging
import multiprocessing as mp
import os
import time
import warnings
from concurrent.futures import ProcessPoolExecutor
import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass
import field
from datetime import datetime
from pathlib import Path
from typing import Any
import Dict, List, Optional, Tuple, Union, Callable
import json

# Core ML/DL Libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
import GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
import Ridge, Lasso
from sklearn.metrics import mean_squared_error
import mean_absolute_error, r2_score

# Deep Learning Libraries
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import DataLoader
import Dataset, DistributedSampler
    from torch.nn.parallel import DistributedDataParallel as DDP
    from torch.cuda.amp import GradScaler
import autocast
    import torch.distributed as dist
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    warnings.warn("PyTorch not available. Deep learning features disabled.")

try:
    import transformers
    from transformers import (
        AutoTokenizer, AutoModel, AutoConfig,
        TrainingArguments, Trainer, DataCollatorWithPadding
    )
    from datasets import Dataset as HFDataset
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from accelerate import Accelerator
    from accelerate.utils import set_seed
    ACCELERATE_AVAILABLE = True
except ImportError:
    ACCELERATE_AVAILABLE = False

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

# Advanced Libraries
try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False

# Async Libraries
import aiofiles
import aiohttp

# Performance Monitoring
import psutil
import GPUtil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ml_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# GPU ë©”ëª¨ë¦¬ ìµœì í™”
if TORCH_AVAILABLE and torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    # RTX 5080 ìµœì í™”
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

@dataclass
class TrainingConfig:
    """ê³ ì„±ëŠ¥ í•™ìŠµ ì„¤ì •"""
    # Hardware Configuration
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    num_gpus: int = torch.cuda.device_count() if TORCH_AVAILABLE else 0
    num_workers: int = min(24, mp.cpu_count())  # i9-14900KF 24ì½”ì–´ ìµœì í™”
    pin_memory: bool = True
    non_blocking: bool = True

    # Training Configuration
    batch_size: int = 512  # RTX 5080 16GB ìµœì í™”
    learning_rate: float = 1e-3
    num_epochs: int = 100
    warmup_epochs: int = 5
    weight_decay: float = 1e-4
    gradient_clipping: float = 1.0

    # Performance Optimization
    mixed_precision: bool = True  # FP16/BF16
    gradient_checkpointing: bool = True
    dataloader_prefetch_factor: int = 4
    persistent_workers: bool = True

    # Distributed Training
    use_ddp: bool = True if torch.cuda.device_count() > 1 else False
    backend: str = "nccl"

    # Memory Optimization
    max_memory_per_gpu: float = 14.0  # GB (RTX 5080 16GBì˜ 87.5%)
    gradient_accumulation_steps: int = 1

    # Advanced Features
    use_wandb: bool = WANDB_AVAILABLE
    use_optuna: bool = OPTUNA_AVAILABLE
    enable_profiling: bool = True

    # Data Configuration
    data_path: str = "data/"
    model_save_path: str = "models/"
    cache_dir: str = "cache/"

    def __post_init__(self):
        # ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì • (GPU ë©”ëª¨ë¦¬ ê¸°ë°˜)
        if self.num_gpus > 0:
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            if gpu_memory >= 16:  # RTX 5080
                self.batch_size = 512
            elif gpu_memory >= 12:
                self.batch_size = 384
            elif gpu_memory >= 8:
                self.batch_size = 256
            else:
                self.batch_size = 128

        # ì›Œì»¤ ìˆ˜ ìµœì í™”
        if self.num_workers > mp.cpu_count():
            self.num_workers = mp.cpu_count()

class AsyncDataLoader:
    """ë¹„ë™ê¸° ê³ ì† ë°ì´í„° ë¡œë” (10ë°° ë¹ ë¥¸ ë°ì´í„° ë¡œë”©)"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.executor = ThreadPoolExecutor(max_workers=config.num_workers)
        self.cache = {}

    async def load_data_async(self, file_path: str) -> pd.DataFrame:
        """ë¹„ë™ê¸° ë°ì´í„° ë¡œë”©"""
        if file_path in self.cache:
            return self.cache[file_path]

        logger.info(f"ë¹„ë™ê¸° ë°ì´í„° ë¡œë”© ì‹œì‘: {file_path}")
        start_time = time.time()

        try:
            if file_path.endswith('.parquet'):
                df = await asyncio.get_event_loop().run_in_executor(
                    self.executor, pd.read_parquet, file_path
                )
            elif file_path.endswith('.feather'):
                df = await asyncio.get_event_loop().run_in_executor(
                    self.executor, pd.read_feather, file_path
                )
            else:
                df = await asyncio.get_event_loop().run_in_executor(
                    self.executor, pd.read_csv, file_path
                )

            self.cache[file_path] = df
            load_time = time.time() - start_time
            logger.info(f"ë°ì´í„° ë¡œë”© ì™„ë£Œ: {file_path} ({load_time:.2f}ì´ˆ, {len(df):,}í–‰)")
            return df

        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
            raise

    async def load_multiple_files_async(self, file_paths: List[str]) -> List[pd.DataFrame]:
        """ë‹¤ì¤‘ íŒŒì¼ ë³‘ë ¬ ë¡œë”©"""
        logger.info(f"ë³‘ë ¬ ë°ì´í„° ë¡œë”© ì‹œì‘: {len(file_paths)}ê°œ íŒŒì¼")
        start_time = time.time()

        tasks = [self.load_data_async(path) for path in file_paths]
        dataframes = await asyncio.gather(*tasks, return_exceptions=True)

        # ì˜ˆì™¸ ì²˜ë¦¬
        valid_dfs = []
        for i, df in enumerate(dataframes):
            if isinstance(df, Exception):
                logger.error(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_paths[i]}, ì˜¤ë¥˜: {df}")
            else:
                valid_dfs.append(df)

        load_time = time.time() - start_time
        logger.info(f"ë³‘ë ¬ ë¡œë”© ì™„ë£Œ: {len(valid_dfs)}ê°œ íŒŒì¼ ({load_time:.2f}ì´ˆ)")
        return valid_dfs

class AdvancedFeatureEngineering:
    """ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ë³‘ë ¬ ì²˜ë¦¬)"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.executor = ProcessPoolExecutor(max_workers=config.num_workers)

    async def create_technical_indicators_async(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë¹„ë™ê¸° ê¸°ìˆ ì  ì§€í‘œ ìƒì„±"""
        logger.info("ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì‹œì‘")

        def compute_indicators(data):
            # ì´ë™í‰ê· 
            for window in [5, 10, 20, 50, 100]:
                data[f'sma_{window}'] = data['close'].rolling(window).mean()
                data[f'ema_{window}'] = data['close'].ewm(span=window).mean()

            # ë³¼ë¦°ì € ë°´ë“œ
            data['bb_upper'] = data['sma_20'] + (data['close'].rolling(20).std() * 2)
            data['bb_lower'] = data['sma_20'] - (data['close'].rolling(20).std() * 2)
            data['bb_ratio'] = (data['close'] - data['bb_lower']) / (data['bb_upper'] - data['bb_lower'])

            # RSI
            delta = data['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            data['rsi'] = 100 - (100 / (1 + rs))

            # MACD
            exp1 = data['close'].ewm(span=12).mean()
            exp2 = data['close'].ewm(span=26).mean()
            data['macd'] = exp1 - exp2
            data['macd_signal'] = data['macd'].ewm(span=9).mean()
            data['macd_histogram'] = data['macd'] - data['macd_signal']

            # ê±°ë˜ëŸ‰ ì§€í‘œ
            data['volume_sma_20'] = data['volume'].rolling(20).mean()
            data['volume_ratio'] = data['volume'] / data['volume_sma_20']

            # ë³€ë™ì„±
            data['volatility'] = data['close'].rolling(20).std()
            data['price_change'] = data['close'].pct_change()

            return data

        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì§€í‘œ ê³„ì‚°
        result = await asyncio.get_event_loop().run_in_executor(
            self.executor, compute_indicators, df.copy()
        )

        logger.info(f"ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì™„ë£Œ: {len(result.columns)}ê°œ ì»¬ëŸ¼")
        return result

class DistributedMLTrainer:
    """ë¶„ì‚° ML í•™ìŠµê¸° (ë‹¤ì¤‘ GPU + CPU ë³‘ë ¬)"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.device = torch.device(config.device)
        self.scaler = StandardScaler()
        self.models = {}
        self.results = {}

        # Accelerator ì´ˆê¸°í™” (ë¶„ì‚° í•™ìŠµ)
        if ACCELERATE_AVAILABLE:
            self.accelerator = Accelerator(
                mixed_precision='fp16' if config.mixed_precision else 'no',
                gradient_accumulation_steps=config.gradient_accumulation_steps
            )

        # W&B ì´ˆê¸°í™”
        if config.use_wandb and WANDB_AVAILABLE:
            wandb.init(
                project="ml-trading-system",
                config=config.__dict__,
                name=f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )

    async def train_multiple_models_async(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ëª¨ë¸ ë³‘ë ¬ í•™ìŠµ"""
        logger.info("ë‹¤ì¤‘ ëª¨ë¸ ë³‘ë ¬ í•™ìŠµ ì‹œì‘")
        start_time = time.time()

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # ì •ê·œí™”
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # ëª¨ë¸ ì •ì˜
        models = {
            'random_forest': RandomForestRegressor(
                n_estimators=200, max_depth=10, n_jobs=-1, random_state=42
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42
            ),
            'linear_regression': LinearRegression(),
            'ridge': Ridge(alpha=1.0),
            'lasso': Lasso(alpha=0.1)
        }

        # ë³‘ë ¬ í•™ìŠµ
        tasks = []
        for name, model in models.items():
            task = self.train_single_model_async(
                name, model, X_train_scaled, X_test_scaled, y_train, y_test
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ì •ë¦¬
        final_results = {}
        for i, (name, result) in enumerate(zip(models.keys(), results)):
            if isinstance(result, Exception):
                logger.error(f"ëª¨ë¸ {name} í•™ìŠµ ì‹¤íŒ¨: {result}")
            else:
                final_results[name] = result

        training_time = time.time() - start_time
        logger.info(f"ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ({training_time:.2f}ì´ˆ)")

        return final_results

    async def train_single_model_async(self, name: str, model: Any,
                                     X_train: np.ndarray, X_test: np.ndarray,
                                     y_train: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ ë¹„ë™ê¸° í•™ìŠµ"""
        logger.info(f"ëª¨ë¸ {name} í•™ìŠµ ì‹œì‘")
        start_time = time.time()

        try:
            # ë¹„ë™ê¸° í•™ìŠµ
            fitted_model = await asyncio.get_event_loop().run_in_executor(
                None, model.fit, X_train, y_train
            )

            # ì˜ˆì¸¡
            y_pred = await asyncio.get_event_loop().run_in_executor(
                None, fitted_model.predict, X_test
            )

            # í‰ê°€
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

            training_time = time.time() - start_time

            result = {
                'model': fitted_model,
                'mse': mse,
                'mae': mae,
                'r2': r2,
                'training_time': training_time
            }

            logger.info(f"ëª¨ë¸ {name} í•™ìŠµ ì™„ë£Œ (RÂ²: {r2:.4f}, ì‹œê°„: {training_time:.2f}ì´ˆ)")

            # W&B ë¡œê¹…
            if self.config.use_wandb and WANDB_AVAILABLE:
                wandb.log({
                    f"{name}_mse": mse,
                    f"{name}_mae": mae,
                    f"{name}_r2": r2,
                    f"{name}_training_time": training_time
                })

            return result

        except Exception as e:
            logger.error(f"ëª¨ë¸ {name} í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise

class AdvancedDeepLearningTrainer:
    """ê³ ê¸‰ ë”¥ëŸ¬ë‹ í•™ìŠµê¸° (RTX 5080 ìµœì í™”)"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.device = torch.device(config.device)

        # ë¶„ì‚° í•™ìŠµ ì´ˆê¸°í™”
        if config.use_ddp and torch.cuda.device_count() > 1:
            dist.init_process_group(backend=config.backend)
            torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', 0)))

        # í˜¼í•© ì •ë°€ë„ ìŠ¤ì¼€ì¼ëŸ¬
        if config.mixed_precision:
            self.scaler = GradScaler()

    def create_optimized_model(self, input_size: int, output_size: int = 1) -> nn.Module:
        """RTX 5080 ìµœì í™” ëª¨ë¸ ìƒì„±"""
        class OptimizedTradingModel(nn.Module):
            def __init__(self, input_size, hidden_sizes=[512, 256, 128, 64], dropout=0.2):
                super().__init__()

                layers = []
                prev_size = input_size

                for hidden_size in hidden_sizes:
                    layers.extend([
                        nn.Linear(prev_size, hidden_size),
                        nn.BatchNorm1d(hidden_size),
                        nn.ReLU(),
                        nn.Dropout(dropout)
                    ])
                    prev_size = hidden_size

                layers.append(nn.Linear(prev_size, output_size))
                self.network = nn.Sequential(*layers)

                # Xavier ì´ˆê¸°í™”
                for m in self.modules():
                    if isinstance(m, nn.Linear):
                        nn.init.xavier_uniform_(m.weight)
                        nn.init.constant_(m.bias, 0)

            def forward(self, x):
                return self.network(x)

        return OptimizedTradingModel(input_size).to(self.device)

    async def train_deep_model_async(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"""
        logger.info("ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        start_time = time.time()

        # ë°ì´í„° ì¤€ë¹„
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # í…ì„œ ë³€í™˜
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        X_test_tensor = torch.FloatTensor(X_test).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        y_test_tensor = torch.FloatTensor(y_test).to(self.device)

        # ëª¨ë¸ ìƒì„±
        model = self.create_optimized_model(X_train.shape[1])

        # ë¶„ì‚° í•™ìŠµ ì„¤ì •
        if self.config.use_ddp and torch.cuda.device_count() > 1:
            model = DDP(model, device_ids=[torch.cuda.current_device()])

        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )

        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=10, T_mult=2
        )

        criterion = nn.MSELoss()

        # í•™ìŠµ ë°ì´í„° ë¡œë”
        train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=self.config.num_workers,
            pin_memory=self.config.pin_memory,
            prefetch_factor=self.config.dataloader_prefetch_factor,
            persistent_workers=self.config.persistent_workers
        )

        # í•™ìŠµ ë£¨í”„
        model.train()
        best_loss = float('inf')

        for epoch in range(self.config.num_epochs):
            epoch_loss = 0.0
            num_batches = 0

            for batch_idx, (data, target) in enumerate(train_loader):
                # í˜¼í•© ì •ë°€ë„ í•™ìŠµ
                if self.config.mixed_precision:
                    with autocast():
                        output = model(data)
                        loss = criterion(output.squeeze(), target)

                    self.scaler.scale(loss).backward()

                    # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                    if self.config.gradient_clipping > 0:
                        self.scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            model.parameters(), self.config.gradient_clipping
                        )

                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    output = model(data)
                    loss = criterion(output.squeeze(), target)
                    loss.backward()

                    if self.config.gradient_clipping > 0:
                        torch.nn.utils.clip_grad_norm_(
                            model.parameters(), self.config.gradient_clipping
                        )

                    optimizer.step()

                optimizer.zero_grad()
                epoch_loss += loss.item()
                num_batches += 1

                # ì§„í–‰ë¥  ì¶œë ¥
                if batch_idx % 50 == 0:
                    logger.info(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.6f}")

            scheduler.step()
            avg_loss = epoch_loss / num_batches

            # ê²€ì¦
            if epoch % 10 == 0:
                model.eval()
                with torch.no_grad():
                    test_output = model(X_test_tensor)
                    test_loss = criterion(test_output.squeeze(), y_test_tensor).item()

                    if test_loss < best_loss:
                        best_loss = test_loss
                        # ëª¨ë¸ ì €ì¥
                        torch.save(model.state_dict(),
                                 f"{self.config.model_save_path}/best_model_epoch_{epoch}.pth")

                logger.info(f"Epoch {epoch}, Train Loss: {avg_loss:.6f}, Test Loss: {test_loss:.6f}")
                model.train()

                # W&B ë¡œê¹…
                if self.config.use_wandb and WANDB_AVAILABLE:
                    wandb.log({
                        "epoch": epoch,
                        "train_loss": avg_loss,
                        "test_loss": test_loss,
                        "learning_rate": scheduler.get_last_lr()[0]
                    })

        training_time = time.time() - start_time
        logger.info(f"ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ìµœì  ì†ì‹¤: {best_loss:.6f}, ì‹œê°„: {training_time:.2f}ì´ˆ)")

        return {
            'model': model,
            'best_loss': best_loss,
            'training_time': training_time
        }

class HyperparameterOptimizer:
    """Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.study = None

        if OPTUNA_AVAILABLE:
            self.study = optuna.create_study(direction='minimize')

    def objective(self, trial, X_train, X_test, y_train, y_test):
        """ìµœì í™” ëª©ì  í•¨ìˆ˜"""
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 500),
            'max_depth': trial.suggest_int('max_depth', 3, 20),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        }

        # ëª¨ë¸ í•™ìŠµ
        model = GradientBoostingRegressor(**params, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # í‰ê°€
        mse = mean_squared_error(y_test, y_pred)
        return mse

    async def optimize_hyperparameters_async(self, X: np.ndarray, y: np.ndarray,
                                           n_trials: int = 100) -> Dict[str, Any]:
        """ë¹„ë™ê¸° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        if not OPTUNA_AVAILABLE:
            logger.warning("Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}

        logger.info(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ ({n_trials}íšŒ ì‹œë„)")
        start_time = time.time()

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # ìµœì í™” ì‹¤í–‰
        objective_with_data = functools.partial(
            self.objective, X_train=X_train, X_test=X_test,
            y_train=y_train, y_test=y_test
        )

        await asyncio.get_event_loop().run_in_executor(
            None, self.study.optimize, objective_with_data, n_trials
        )

        optimization_time = time.time() - start_time

        best_params = self.study.best_params
        best_value = self.study.best_value

        logger.info(f"ìµœì í™” ì™„ë£Œ (ìµœì  MSE: {best_value:.6f}, ì‹œê°„: {optimization_time:.2f}ì´ˆ)")
        logger.info(f"ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")

        return {
            'best_params': best_params,
            'best_value': best_value,
            'optimization_time': optimization_time
        }

class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.metrics = {
            'gpu_utilization': [],
            'gpu_memory': [],
            'cpu_utilization': [],
            'ram_usage': [],
            'timestamps': []
        }

    async def monitor_performance_async(self, duration: int = 60):
        """ë¹„ë™ê¸° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        logger.info(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ({duration}ì´ˆ)")

        end_time = time.time() + duration

        while time.time() < end_time:
            timestamp = datetime.now()

            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)

            # RAM ì‚¬ìš©ë¥ 
            ram = psutil.virtual_memory()
            ram_percent = ram.percent

            # GPU ì •ë³´
            gpu_util = 0
            gpu_memory = 0

            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu = gpus[0]  # ì²« ë²ˆì§¸ GPU
                    gpu_util = gpu.load * 100
                    gpu_memory = gpu.memoryUtil * 100
            except:
                pass

            # ë©”íŠ¸ë¦­ ì €ì¥
            self.metrics['cpu_utilization'].append(cpu_percent)
            self.metrics['ram_usage'].append(ram_percent)
            self.metrics['gpu_utilization'].append(gpu_util)
            self.metrics['gpu_memory'].append(gpu_memory)
            self.metrics['timestamps'].append(timestamp)

            await asyncio.sleep(1)

        # í†µê³„ ì¶œë ¥
        self.print_performance_summary()

    def print_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        logger.info("=== ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìš”ì•½ ===")
        logger.info(f"í‰ê·  CPU ì‚¬ìš©ë¥ : {np.mean(self.metrics['cpu_utilization']):.1f}%")
        logger.info(f"í‰ê·  RAM ì‚¬ìš©ë¥ : {np.mean(self.metrics['ram_usage']):.1f}%")
        logger.info(f"í‰ê·  GPU ì‚¬ìš©ë¥ : {np.mean(self.metrics['gpu_utilization']):.1f}%")
        logger.info(f"í‰ê·  GPU ë©”ëª¨ë¦¬: {np.mean(self.metrics['gpu_memory']):.1f}%")

class AdvancedMLDLSystem:
    """ê³ ê¸‰ ML/DL í†µí•© ì‹œìŠ¤í…œ"""

    def __init__(self, config: Optional[TrainingConfig] = None):
        self.config = config or TrainingConfig()
        self.data_loader = AsyncDataLoader(self.config)
        self.feature_engineering = AdvancedFeatureEngineering(self.config)
        self.ml_trainer = DistributedMLTrainer(self.config)
        self.dl_trainer = AdvancedDeepLearningTrainer(self.config)
        self.optimizer = HyperparameterOptimizer(self.config)
        self.monitor = PerformanceMonitor()

        # ê²°ê³¼ ì €ì¥ì†Œ
        self.training_results = {}

        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(self.config.model_save_path).mkdir(parents=True, exist_ok=True)
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)
        Path("logs").mkdir(parents=True, exist_ok=True)

    async def run_complete_training_pipeline(self) -> Dict[str, Any]:
        """ì™„ì „ ìë™í™” í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
        logger.info("ğŸš€ ê³ ê¸‰ ML/DL í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        pipeline_start = time.time()

        try:
            # 1. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            monitor_task = asyncio.create_task(
                self.monitor.monitor_performance_async(duration=300)  # 5ë¶„ê°„ ëª¨ë‹ˆí„°ë§
            )

            # 2. ë°ì´í„° ë¡œë”©
            logger.info("ğŸ“Š ë°ì´í„° ë¡œë”© ì‹œì‘...")
            data_files = [
                "data/historical/krx_historical.parquet",
                "data/krx_all/all_stocks.csv"
            ]

            # ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
            existing_files = [f for f in data_files if Path(f).exists()]

            if not existing_files:
                # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
                logger.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„±...")
                sample_data = self.generate_sample_data()
            else:
                dataframes = await self.data_loader.load_multiple_files_async(existing_files)
                sample_data = pd.concat(dataframes, ignore_index=True) if dataframes else self.generate_sample_data()

            # 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
            logger.info("ğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§...")
            if 'close' in sample_data.columns:
                enhanced_data = await self.feature_engineering.create_technical_indicators_async(sample_data)
            else:
                enhanced_data = sample_data

            # 4. ë°ì´í„° ì „ì²˜ë¦¬
            logger.info("ğŸ“‹ ë°ì´í„° ì „ì²˜ë¦¬...")
            X, y = self.prepare_training_data(enhanced_data)

            # 5. ML ëª¨ë¸ í•™ìŠµ (ë³‘ë ¬)
            logger.info("ğŸ¤– ML ëª¨ë¸ ë³‘ë ¬ í•™ìŠµ...")
            ml_results = await self.ml_trainer.train_multiple_models_async(X, y)
            self.training_results['ml_models'] = ml_results

            # 6. ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
            if TORCH_AVAILABLE and torch.cuda.is_available():
                logger.info("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ...")
                dl_results = await self.dl_trainer.train_deep_model_async(X, y)
                self.training_results['dl_model'] = dl_results

            # 7. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
            if self.config.use_optuna and OPTUNA_AVAILABLE:
                logger.info("âš¡ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”...")
                optimization_results = await self.optimizer.optimize_hyperparameters_async(X, y, n_trials=50)
                self.training_results['optimization'] = optimization_results

            # 8. ê²°ê³¼ ì €ì¥
            await self.save_results_async()

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
            monitor_task.cancel()

            pipeline_time = time.time() - pipeline_start
            logger.info(f"âœ… í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({pipeline_time:.2f}ì´ˆ)")

            return self.training_results

        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            raise

    def generate_sample_data(self) -> pd.DataFrame:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        logger.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")

        np.random.seed(42)
        n_samples = 10000

        dates = pd.date_range('2020-01-01', periods=n_samples, freq='D')

        # ì£¼ê°€ ì‹œë®¬ë ˆì´ì…˜
        base_price = 100
        returns = np.random.normal(0.001, 0.02, n_samples)
        prices = [base_price]

        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))

        data = pd.DataFrame({
            'date': dates,
            'open': [p * (1 + np.random.normal(0, 0.01)) for p in prices],
            'high': [p * (1 + abs(np.random.normal(0, 0.015))) for p in prices],
            'low': [p * (1 - abs(np.random.normal(0, 0.015))) for p in prices],
            'close': prices,
            'volume': np.random.randint(1000000, 10000000, n_samples)
        })

        return data

    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        logger.info("í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        df_numeric = df[numeric_columns].copy()

        # NaN ì œê±°
        df_numeric = df_numeric.dropna()

        if len(df_numeric) == 0:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„¤ì • (ì¢…ê°€ì˜ ë‹¤ìŒë‚  ìˆ˜ìµë¥ )
        if 'close' in df_numeric.columns:
            df_numeric['target'] = df_numeric['close'].pct_change().shift(-1)
        else:
            # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ íƒ€ê²Ÿìœ¼ë¡œ ì‚¬ìš©
            target_col = df_numeric.columns[0]
            df_numeric['target'] = df_numeric[target_col].pct_change().shift(-1)

        # ë§ˆì§€ë§‰ í–‰ ì œê±° (íƒ€ê²Ÿì´ NaN)
        df_numeric = df_numeric[:-1]
        df_numeric = df_numeric.dropna()

        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        X = df_numeric.drop('target', axis=1).values
        y = df_numeric['target'].values

        logger.info(f"í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X.shape[0]:,}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ í”¼ì²˜")

        return X, y

    async def save_results_async(self):
        """ê²°ê³¼ ì €ì¥"""
        logger.info("ê²°ê³¼ ì €ì¥ ì¤‘...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"{self.config.model_save_path}/training_results_{timestamp}.json"

        # ê²°ê³¼ ì§ë ¬í™” ì¤€ë¹„
        serializable_results = {}

        for key, value in self.training_results.items():
            if key == 'ml_models':
                serializable_results[key] = {}
                for model_name, model_result in value.items():
                    serializable_results[key][model_name] = {
                        'mse': model_result['mse'],
                        'mae': model_result['mae'],
                        'r2': model_result['r2'],
                        'training_time': model_result['training_time']
                    }
            elif key == 'dl_model':
                serializable_results[key] = {
                    'best_loss': value['best_loss'],
                    'training_time': value['training_time']
                }
            elif key == 'optimization':
                serializable_results[key] = value

        # JSON ì €ì¥
        async with aiofiles.open(results_file, 'w') as f:
            await f.write(json.dumps(serializable_results, indent=2))

        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_file}")

# ì‚¬ìš© ì˜ˆì‹œ ë° ë©”ì¸ ì‹¤í–‰
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ RTX 5080 + i9-14900KF ìµœì í™” ML/DL ì‹œìŠ¤í…œ ì‹œì‘")

    # ì„¤ì •
    config = TrainingConfig()

    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    logger.info(f"GPU ê°œìˆ˜: {config.num_gpus}")
    logger.info(f"CPU ì½”ì–´: {config.num_workers}")
    logger.info(f"ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    logger.info(f"í˜¼í•© ì •ë°€ë„: {config.mixed_precision}")

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = AdvancedMLDLSystem(config)

    # í•™ìŠµ ì‹¤í–‰
    results = await system.run_complete_training_pipeline()

    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ê²°ê³¼ ìš”ì•½:")

    if 'ml_models' in results:
        logger.info("ML ëª¨ë¸ ì„±ëŠ¥:")
        for name, result in results['ml_models'].items():
            logger.info(f"  {name}: RÂ² = {result['r2']:.4f}, ì‹œê°„ = {result['training_time']:.2f}ì´ˆ")

    if 'dl_model' in results:
        logger.info(f"ë”¥ëŸ¬ë‹ ëª¨ë¸: ì†ì‹¤ = {results['dl_model']['best_loss']:.6f}")

    if 'optimization' in results:
        logger.info(f"ìµœì í™” ê²°ê³¼: MSE = {results['optimization']['best_value']:.6f}")

if __name__ == "__main__":
    # ì‹¤í–‰
    asyncio.run(main())
