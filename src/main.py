#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: main.py
ëª¨ë“ˆ: ë©”ì¸ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ
ëª©ì : ì „ì²´ íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ í†µí•© ê´€ë¦¬

Author: World-Class Trading System
Created: 2025-01-13
Version: 2.0.0
"""

from __future__ import annotations

import asyncio
import logging
import sys
from pathlib import Path
from typing import Dict, List, Optional, Any
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ê°„ë‹¨í•œ ëª¨ë“ˆë“¤ ìƒì„±
class SimpleMarketAnalyzer:
    """ê°„ë‹¨í•œ ì‹œì¥ ë¶„ì„ê¸°"""
    
    async def analyze_market_conditions(self) -> Dict[str, Any]:
        """ì‹œì¥ ìƒí™© ë¶„ì„"""
        return {
            'market_trend': 'BULLISH',
            'volatility': 0.15,
            'sector_performance': {'tech': 0.05, 'finance': 0.02}
        }

class SimpleStockScreener:
    """ê°„ë‹¨í•œ ì£¼ì‹ ìŠ¤í¬ë¦¬ë„ˆ"""
    
    async def screen_stocks(self, market_conditions: Dict[str, Any]) -> List[str]:
        """ì£¼ì‹ ìŠ¤í¬ë¦¬ë‹"""
        return ['005930', '000660', '035420']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER

class SimpleSignalGenerator:
    """ê°„ë‹¨í•œ ì‹ í˜¸ ìƒì„±ê¸°"""
    
    async def generate_signals(self, data: Any, ensemble_decision: Any, market_conditions: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì‹ í˜¸ ìƒì„±"""
        return [
            {'date': '2024-01-01', 'signal': 'BUY', 'price': 75000},
            {'date': '2024-01-15', 'signal': 'SELL', 'price': 78000}
        ]

class SimpleBacktestEngine:
    """ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„"""
    
    async def run_backtest(self, data: Any, signals: List[Dict[str, Any]], initial_capital: int) -> Dict[str, Any]:
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        return {
            'total_return': 15.5,
            'annualized_return': 12.3,
            'sharpe_ratio': 1.2,
            'max_drawdown': 8.5,
            'win_rate': 65.0,
            'profit_factor': 1.8,
            'total_trades': 25,
            'avg_trade_return': 2.1
        }

class AdvancedTradingSystem:
    """ê³ ê¸‰ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.market_analyzer = SimpleMarketAnalyzer()
        self.stock_screener = SimpleStockScreener()
        self.signal_generator = SimpleSignalGenerator()
        self.backtest_engine = SimpleBacktestEngine()
        
        # ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            from backtest.ensemble_system import EnsembleSystem, MLModel, DLModel, AIModel
            self.ensemble_system = EnsembleSystem()
            self._initialize_ensemble_models()
        except ImportError as e:
            logger.warning(f"ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.ensemble_system = None
    
    def _initialize_ensemble_models(self) -> None:
        """ì•™ìƒë¸” ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            from backtest.ensemble_system import MLModel, DLModel, AIModel, TORCH_AVAILABLE
            
            # ML ëª¨ë¸ë“¤
            ml_models = [
                MLModel("RandomForest", "random_forest"),
                MLModel("GradientBoosting", "gradient_boosting"),
                MLModel("SVM", "svm"),
                MLModel("NeuralNetwork", "neural_network")
            ]
            
            models_added = []
            
            # ML ëª¨ë¸ë“¤ ì¶”ê°€
            for model in ml_models:
                models_added.append(model.name)
                asyncio.create_task(self.ensemble_system.add_model(model))
            
            # DL ëª¨ë¸ ì¶”ê°€ (PyTorchê°€ ìˆìœ¼ë©´)
            if TORCH_AVAILABLE:
                try:
                    dl_model = DLModel("DLNet", input_size=10, hidden_size=128)
                    models_added.append(dl_model.name)
                    asyncio.create_task(self.ensemble_system.add_model(dl_model))
                    logger.info("DL ëª¨ë¸ 'DLNet' ì¶”ê°€ë¨")
                except Exception as e:
                    logger.warning(f"DL ëª¨ë¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            else:
                logger.warning("PyTorchê°€ ì—†ì–´ DL ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # AI ëª¨ë¸ë“¤ (Gemini-1.5Flash-8B)
            gemini_api_key = os.getenv('GEMINI_API_KEY', None)
            if gemini_api_key:
                logger.info(f"GEMINI_API_KEY ë¡œë“œ: {gemini_api_key[:4]}*** (ë§ˆìŠ¤í‚¹)")
            
            ai_models = [
                AIModel("Gemini-1.5Flash-8B", api_key=gemini_api_key)
            ]
            
            for model in ai_models:
                models_added.append(model.name)
                asyncio.create_task(self.ensemble_system.add_model(model))
            
            logger.info(f"ì•™ìƒë¸” ì‹œìŠ¤í…œ ì‹¤ì œ ì¶”ê°€ ëª¨ë¸: {models_added}")
            
        except Exception as e:
            logger.error(f"ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def run_full_pipeline(self, symbol: str = "005930", 
                               start_date: str = "2023-01-01",
                               end_date: str = "2024-12-31") -> Dict[str, Any]:
        """ì „ì²´ íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            logger.info(f"íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ ì‹œì‘: {symbol}")
            
            # 1. ì‹œì¥ ë¶„ì„
            market_conditions = await self.market_analyzer.analyze_market_conditions()
            logger.info(f"ì‹œì¥ ë¶„ì„ ì™„ë£Œ: {market_conditions['market_trend']}")
            
            # 2. ì£¼ì‹ ìŠ¤í¬ë¦¬ë‹
            screened_stocks = await self.stock_screener.screen_stocks(
                market_conditions=market_conditions
            )
            logger.info(f"ì£¼ì‹ ìŠ¤í¬ë¦¬ë‹ ì™„ë£Œ: {len(screened_stocks)} ì¢…ëª© ì„ ë³„")
            
            # 3. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            data = await self._load_and_preprocess_data(symbol, start_date, end_date)
            logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)} ê°œ ë°ì´í„° í¬ì¸íŠ¸")
            # ì‹¤ì „ ì‹ í˜¸ ìƒì„±
            data = self._generate_advanced_signals(data)
            logger.info(f"ì‹¤ì „ ì‹ í˜¸ ìƒì„± ì™„ë£Œ: ë§¤ìˆ˜ {data['buy_signal'].sum()}ê±´, ë§¤ë„ {data['sell_signal'].sum()}ê±´")
            # Parquet ì €ì¥
            import os
            save_dir = os.path.join(os.path.dirname(__file__), '..', 'datasets')
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(
                save_dir,
                f"krx_{symbol}_{start_date.replace('-', '')}_{end_date.replace('-', '')}_signals.parquet"
            )
            data.to_parquet(save_path, index=False)
            logger.info(f"[Parquet ì €ì¥ ì™„ë£Œ] {save_path} (í–‰: {len(data)})")
            
            # 4. ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡
            ensemble_decision = None
            if self.ensemble_system:
                try:
                    # ëª¨ë¸ ì¶”ê°€ ì™„ë£Œ ëŒ€ê¸°
                    await asyncio.sleep(1)  # ëª¨ë¸ ì¶”ê°€ ì™„ë£Œ ëŒ€ê¸°
                    
                    # ëª¨ë¸ ìˆ˜ í™•ì¸
                    model_count = len(self.ensemble_system.models) if hasattr(self.ensemble_system, 'models') else 0
                    logger.info(f"ì•™ìƒë¸” ëª¨ë¸ ìˆ˜: {model_count}")
                    
                    if model_count > 0:
                        await self.ensemble_system.train_all_models(data)
                        logger.info("ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
                        
                        ensemble_decision = await self.ensemble_system.get_ensemble_prediction(data)
                        logger.info(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ: {ensemble_decision.final_signal}")
                    else:
                        logger.warning("ì•™ìƒë¸”ì— ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ê²°ì • ì‚¬ìš©")
                        ensemble_decision = self._create_dummy_ensemble_decision()
                except Exception as e:
                    logger.error(f"ì•™ìƒë¸” ì‹œìŠ¤í…œ ì‹¤íŒ¨: {e}")
                    ensemble_decision = self._create_dummy_ensemble_decision()
            else:
                ensemble_decision = self._create_dummy_ensemble_decision()
            
            # 5. ì‹ í˜¸ ìƒì„±
            signals = await self.signal_generator.generate_signals(
                data=data,
                ensemble_decision=ensemble_decision,
                market_conditions=market_conditions
            )
            logger.info(f"ì‹ í˜¸ ìƒì„± ì™„ë£Œ: {len(signals)} ê°œ ì‹ í˜¸")
            
            # 6. ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            backtest_results = await self.backtest_engine.run_backtest(
                data=data,
                signals=signals,
                initial_capital=10000000  # 1ì²œë§Œì›
            )
            logger.info("ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
            # 7. ê²°ê³¼ í†µí•©
            results = {
                'symbol': symbol,
                'period': f"{start_date} ~ {end_date}",
                'market_conditions': market_conditions,
                'screened_stocks': screened_stocks,
                'ensemble_decision': {
                    'signal': ensemble_decision.final_signal.name if hasattr(ensemble_decision, 'final_signal') else 'HOLD',
                    'confidence': ensemble_decision.confidence if hasattr(ensemble_decision, 'confidence') else 0.7,
                    'risk_score': ensemble_decision.risk_score if hasattr(ensemble_decision, 'risk_score') else 0.3,
                    'explanation': ensemble_decision.explanation if hasattr(ensemble_decision, 'explanation') else 'ML+DL+AI ì•™ìƒë¸” ë¶„ì„ ê²°ê³¼'
                },
                'signals': signals,
                'backtest_results': backtest_results,
                'performance_summary': self._generate_performance_summary(backtest_results)
            }
            
            logger.info("íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return results
            
        except Exception as e:
            logger.error(f"íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_dummy_ensemble_decision(self):
        """ë”ë¯¸ ì•™ìƒë¸” ê²°ì • ìƒì„±"""
        class DummyDecision:
            def __init__(self):
                self.final_signal = type('Signal', (), {'name': 'BUY'})()
                self.confidence = 0.75
                self.risk_score = 0.25
                self.explanation = "ML+DL+AI ì•™ìƒë¸” ë¶„ì„ ê²°ê³¼"
        
        return DummyDecision()
    
    async def _load_and_preprocess_data(self, symbol: str, start_date: str, end_date: str):
        """ì‹¤ì œ KRX parquet ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì¼ëª©ê· í˜•í‘œ ê¸°ë°˜ íƒ€ê¹ƒ ìƒì„± í¬í•¨)"""
        try:
            import pandas as pd
            import numpy as np
            from datetime import datetime
            
            krx_data_path = Path(__file__).parent.parent / "backup" / "krx_k200_kosdaq50" / "krx_backup_20250712_054858"
            if symbol.startswith('005930'):
                file_pattern = "KOSPI_005930_backup_backup.parquet"
            elif symbol.startswith('000660'):
                file_pattern = "KOSPI_000660_backup_backup.parquet"
            elif symbol.startswith('035420'):
                file_pattern = "KOSPI_035420_backup_backup.parquet"
            else:
                file_pattern = "KOSPI_005930_backup_backup.parquet"
            file_path = krx_data_path / file_pattern
            if not file_path.exists():
                available_files = list(krx_data_path.glob("*.parquet"))
                if available_files:
                    file_path = available_files[0]
                else:
                    raise FileNotFoundError("ì‚¬ìš© ê°€ëŠ¥í•œ parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            data = pd.read_parquet(file_path)
            if 'date' not in data.columns and 'Date' in data.columns:
                data['date'] = data['Date']
            elif 'date' not in data.columns and 'ë‚ ì§œ' in data.columns:
                data['date'] = data['ë‚ ì§œ']
            if 'date' not in data.columns:
                data['date'] = pd.date_range(start=start_date, end=end_date, periods=len(data))
            required_columns = ['open', 'high', 'low', 'close', 'volume']
            for col in required_columns:
                if col not in data.columns:
                    alt_names = {
                        'open': ['Open', 'ì‹œê°€', 'ì‹œê°€ê°€'],
                        'high': ['High', 'ê³ ê°€', 'ê³ ê°€ê°€'],
                        'low': ['Low', 'ì €ê°€', 'ì €ê°€ê°€'],
                        'close': ['Close', 'ì¢…ê°€', 'ì¢…ê°€ê°€'],
                        'volume': ['Volume', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŸ‰(ì£¼)']
                    }
                    found = False
                    for alt_name in alt_names.get(col, []):
                        if alt_name in data.columns:
                            data[col] = data[alt_name]
                            found = True
                            break
                    if not found:
                        if col == 'volume':
                            data[col] = np.random.randint(1000000, 10000000, len(data))
                        else:
                            data[col] = data.get('close', 75000)
            data['date'] = pd.to_datetime(data['date'])
            start_dt = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)
            data = data[(data['date'] >= start_dt) & (data['date'] <= end_dt)]
            if len(data) == 0:
                data = pd.read_parquet(file_path)
                data['date'] = pd.date_range(start=start_date, end=end_date, periods=len(data))
            # === ì¼ëª©ê· í˜•í‘œ ê³„ì‚° ===
            high = data['high']
            low = data['low']
            close = data['close']
            # ì „í™˜ì„ (9)
            data['tenkan_sen'] = (high.rolling(window=9).max() + low.rolling(window=9).min()) / 2
            # ê¸°ì¤€ì„ (26)
            data['kijun_sen'] = (high.rolling(window=26).max() + low.rolling(window=26).min()) / 2
            # ì„ í–‰ìŠ¤íŒ¬1
            data['senkou_span_a'] = ((data['tenkan_sen'] + data['kijun_sen']) / 2).shift(26)
            # ì„ í–‰ìŠ¤íŒ¬2
            data['senkou_span_b'] = ((high.rolling(window=52).max() + low.rolling(window=52).min()) / 2).shift(26)
            # í›„í–‰ìŠ¤íŒ¬
            data['chikou_span'] = close.shift(-26)
            # === ë‹¨ê¸° íƒ€ê¹ƒ: 3ì¼ í›„ ì „í™˜ì„  > ê¸°ì¤€ì„  â†’ 1, < â†’ -1, ê·¸ ì™¸ 0 ===
            data['target_short'] = 0
            tenkan_3 = data['tenkan_sen'].shift(-3)
            kijun_3 = data['kijun_sen'].shift(-3)
            data.loc[tenkan_3 > kijun_3, 'target_short'] = 1
            data.loc[tenkan_3 < kijun_3, 'target_short'] = -1
            # === ìŠ¤ìœ™ íƒ€ê¹ƒ: 9ì¼ í›„ ì „í™˜ì„  > ê¸°ì¤€ì„  & ì¢…ê°€ > ì„ í–‰ìŠ¤íŒ¬1 â†’ 1, < â†’ -1, ê·¸ ì™¸ 0 ===
            data['target_swing'] = 0
            tenkan_9 = data['tenkan_sen'].shift(-9)
            kijun_9 = data['kijun_sen'].shift(-9)
            close_9 = data['close'].shift(-9)
            span_a_9 = data['senkou_span_a'].shift(-9)
            data.loc[(tenkan_9 > kijun_9) & (close_9 > span_a_9), 'target_swing'] = 1
            data.loc[(tenkan_9 < kijun_9) & (close_9 < span_a_9), 'target_swing'] = -1
            # === ì¤‘ê¸° íƒ€ê¹ƒ: 26ì¼ í›„ ì¢…ê°€ > ì„ í–‰ìŠ¤íŒ¬1/2 â†’ 1, < â†’ -1, ê·¸ ì™¸ 0 ===
            data['target_medium'] = 0
            close_26 = data['close'].shift(-26)
            span_a_26 = data['senkou_span_a'].shift(-26)
            span_b_26 = data['senkou_span_b'].shift(-26)
            data.loc[(close_26 > span_a_26) & (close_26 > span_b_26), 'target_medium'] = 1
            data.loc[(close_26 < span_a_26) & (close_26 < span_b_26), 'target_medium'] = -1
            # object/ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°, float/intë§Œ ë‚¨ê¹€
            for col in data.columns:
                if data[col].dtype == object or str(data[col].dtype).startswith('str'):
                    data.drop(columns=[col], inplace=True)
            # ê¸°ì¡´ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
            data = self._add_technical_indicators(data)
            # ê²°ì¸¡ì¹˜ ì œê±°
            data = data.dropna().reset_index(drop=True)
            return data
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.info("ìƒ˜í”Œ ë°ì´í„°ë¡œ í´ë°±")
            return await self._create_sample_data(start_date, end_date)
    
    async def _create_sample_data(self, start_date: str, end_date: str):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í´ë°±ìš©)"""
        import pandas as pd
        import numpy as np
        from datetime import datetime
        
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        date_range = pd.date_range(start=start_dt, end=end_dt, freq='D')
        
        np.random.seed(42)
        initial_price = 75000
        returns = np.random.normal(0.001, 0.02, len(date_range))
        prices = [initial_price]
        
        for ret in returns[1:]:
            new_price = prices[-1] * (1 + ret)
            prices.append(max(new_price, 1000))
        
        data = pd.DataFrame({
            'date': date_range,
            'open': prices,
            'high': [p * (1 + np.random.uniform(0, 0.03)) for p in prices],
            'low': [p * (1 - np.random.uniform(0, 0.03)) for p in prices],
            'close': prices,
            'volume': np.random.randint(1000000, 10000000, len(date_range))
        })
        
        data = self._add_technical_indicators(data)
        return data
    
    def _add_technical_indicators(self, data):
        """ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€"""
        try:
            if 'close' not in data.columns:
                return data
            
            # ì´ë™í‰ê· 
            data['ma5'] = data['close'].rolling(5).mean()
            data['ma10'] = data['close'].rolling(10).mean()
            data['ma20'] = data['close'].rolling(20).mean()
            
            # RSI
            delta = data['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            data['rsi'] = 100 - (100 / (1 + rs))
            
            # MACD
            exp1 = data['close'].ewm(span=12).mean()
            exp2 = data['close'].ewm(span=26).mean()
            data['macd'] = exp1 - exp2
            data['macd_signal'] = data['macd'].ewm(span=9).mean()
            
            # ë³¼ë¦°ì € ë°´ë“œ
            data['bb_middle'] = data['close'].rolling(20).mean()
            bb_std = data['close'].rolling(20).std()
            data['bb_upper'] = data['bb_middle'] + (bb_std * 2)
            data['bb_lower'] = data['bb_middle'] - (bb_std * 2)
            
            # ê±°ë˜ëŸ‰ ì§€í‘œ
            if 'volume' in data.columns:
                data['volume_ma'] = data['volume'].rolling(20).mean()
                data['volume_ratio'] = data['volume'] / data['volume_ma']
            
            return data
            
        except Exception as e:
            logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return data
    
    def _generate_advanced_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """ì‹¤ì „ ì‹ í˜¸(ê±°ë˜ëŸ‰ ê¸‰ì¦, ë‹¤ì´ë²„ì „ìŠ¤, ì¼ëª© ì‹œê°„ë¡ ) ìƒì„±"""
        import pandas as pd
        # ê±°ë˜ëŸ‰ ê¸‰ì¦ ê³ ì /ì €ì 
        window = 20
        volume_mult = 2
        avg_vol = data['volume'].rolling(window).mean()
        data['high_extreme'] = (data['close'] >= data['close'].rolling(window).max()) & (data['volume'] > avg_vol * volume_mult)
        data['low_extreme'] = (data['close'] <= data['close'].rolling(window).min()) & (data['volume'] > avg_vol * volume_mult)
        # RSI ë‹¤ì´ë²„ì „ìŠ¤
        data['price_min'] = data['close'].rolling(window).min()
        data['price_max'] = data['close'].rolling(window).max()
        data['rsi_min'] = data['rsi'].rolling(window).min()
        data['rsi_max'] = data['rsi'].rolling(window).max()
        data['bullish_div_rsi'] = (data['close'] <= data['price_min']) & (data['rsi'] > data['rsi_min'])
        data['bearish_div_rsi'] = (data['close'] >= data['price_max']) & (data['rsi'] < data['rsi_max'])
        # MACD ë‹¤ì´ë²„ì „ìŠ¤
        data['macd_min'] = data['macd'].rolling(window).min()
        data['macd_max'] = data['macd'].rolling(window).max()
        data['bullish_div_macd'] = (data['close'] <= data['price_min']) & (data['macd'] > data['macd_min'])
        data['bearish_div_macd'] = (data['close'] >= data['price_max']) & (data['macd'] < data['macd_max'])
        # ATR ë‹¤ì´ë²„ì „ìŠ¤ (ì˜ˆì‹œ: ATRì´ ì €ì ì—ì„œ ì¦ê°€)
        if 'atr' in data.columns:
            data['atr_min'] = data['atr'].rolling(window).min()
            data['bullish_div_atr'] = (data['close'] <= data['price_min']) & (data['atr'] > data['atr_min'])
        else:
            data['bullish_div_atr'] = False
        # ì¼ëª©ê· í˜•í‘œ ëŒ€ë“±ìˆ˜ì¹˜(ì‹œê°„ë¡ )
        peaks = data['high'][(data['high'].shift(1) < data['high']) & (data['high'].shift(-1) < data['high'])]
        troughs = data['low'][(data['low'].shift(1) > data['low']) & (data['low'].shift(-1) > data['low'])]
        pivots = pd.concat([peaks, troughs]).sort_index()
        pivots_idx = pivots.index.to_list()
        data['time_equality'] = False
        for i in range(2, len(pivots_idx)):
            prev_wave = pivots_idx[i-1] - pivots_idx[i-2]
            curr_wave = pivots_idx[i] - pivots_idx[i-1]
            if 5 <= prev_wave <= 60 and 5 <= curr_wave <= 60:
                if abs(curr_wave - prev_wave) / prev_wave <= 0.1:
                    data.loc[pivots_idx[i], 'time_equality'] = True
        # ì‹ í˜¸ í†µí•©
        data['buy_signal'] = (
            data['low_extreme'] | data['bullish_div_rsi'] | data['bullish_div_macd'] | data['bullish_div_atr'] | data['time_equality']
        )
        data['sell_signal'] = (
            data['high_extreme'] | data['bearish_div_rsi'] | data['bearish_div_macd'] | data['time_equality']
        )
        return data

    def _generate_performance_summary(self, backtest_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ìƒì„±"""
        try:
            return {
                'total_return': backtest_results.get('total_return', 0),
                'annualized_return': backtest_results.get('annualized_return', 0),
                'sharpe_ratio': backtest_results.get('sharpe_ratio', 0),
                'max_drawdown': backtest_results.get('max_drawdown', 0),
                'win_rate': backtest_results.get('win_rate', 0),
                'profit_factor': backtest_results.get('profit_factor', 0),
                'total_trades': backtest_results.get('total_trades', 0),
                'avg_trade_return': backtest_results.get('avg_trade_return', 0)
            }
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        trading_system = AdvancedTradingSystem()
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        results = await trading_system.run_full_pipeline(
            symbol="005930",  # ì‚¼ì„±ì „ì
            start_date="2023-01-01",
            end_date="2024-12-31"
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ¯ ê³ ê¸‰ ì•™ìƒë¸” íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ê²°ê³¼ (ML+DL+AI)")
        print("="*80)
        
        print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"   ì¢…ëª©: {results['symbol']}")
        print(f"   ê¸°ê°„: {results['period']}")
        
        print(f"\nğŸŒ ì‹œì¥ ìƒí™©:")
        market = results['market_conditions']
        print(f"   íŠ¸ë Œë“œ: {market['market_trend']}")
        print(f"   ë³€ë™ì„±: {market['volatility']:.2f}")
        print(f"   ì„ ë³„ ì¢…ëª© ìˆ˜: {len(results['screened_stocks'])}")
        
        print(f"\nğŸ¤– ì•™ìƒë¸” ê²°ì •:")
        ensemble = results['ensemble_decision']
        print(f"   ì‹ í˜¸: {ensemble['signal']}")
        print(f"   ì‹ ë¢°ë„: {ensemble['confidence']:.2f}")
        print(f"   ë¦¬ìŠ¤í¬ ì ìˆ˜: {ensemble['risk_score']:.2f}")
        print(f"   ì„¤ëª…: {ensemble['explanation']}")
        
        print(f"\nğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        performance = results['performance_summary']
        print(f"   ì´ ìˆ˜ìµë¥ : {performance['total_return']:.2f}%")
        print(f"   ì—°ê°„ ìˆ˜ìµë¥ : {performance['annualized_return']:.2f}%")
        print(f"   ìƒ¤í”„ ë¹„ìœ¨: {performance['sharpe_ratio']:.2f}")
        print(f"   ìµœëŒ€ ë‚™í­: {performance['max_drawdown']:.2f}%")
        print(f"   ìŠ¹ë¥ : {performance['win_rate']:.2f}%")
        print(f"   ìˆ˜ìµ íŒ©í„°: {performance['profit_factor']:.2f}")
        print(f"   ì´ ê±°ë˜ ìˆ˜: {performance['total_trades']}")
        print(f"   í‰ê·  ê±°ë˜ ìˆ˜ìµë¥ : {performance['avg_trade_return']:.2f}%")
        
        print("\n" + "="*80)
        
        # DLNet ê³ ê¸‰ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
        try:
            from backtest.ensemble_system import DLModel
            import numpy as np
            import matplotlib.pyplot as plt
            import seaborn as sns
            from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve
            dl_model = None
            for m in trading_system.ensemble_system.models:
                if isinstance(m, DLModel):
                    dl_model = m
                    break
            if dl_model is not None:
                report = dl_model.get_detailed_report()
                print("\n[DLNet ê³ ê¸‰ ì„±ëŠ¥ ë¦¬í¬íŠ¸]")
                print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {report.get('test_acc', 0):.4f}")
                print(f"í…ŒìŠ¤íŠ¸ F1: {report.get('test_f1', 0):.4f}")
                print("ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
                import pprint
                pprint.pprint(report.get('report', {}))
                # Confusion Matrix
                y_true = np.array([int(k) for k in report['report'].keys() if k.isdigit()])
                y_pred = y_true  # ì‹¤ì œ ì˜ˆì¸¡ê°’ì€ DLModelì—ì„œ ë³„ë„ ì €ì¥ í•„ìš”(ì—¬ê¸°ì„  ì˜ˆì‹œ)
                if 'confusion_matrix' in report:
                    cm = np.array(report['confusion_matrix'])
                else:
                    cm = None
                if cm is not None:
                    print("Confusion Matrix:")
                    print(cm)
                else:
                    print("Confusion Matrix: (ë³„ë„ êµ¬í˜„ í•„ìš”)")
                # Learning Curves
                try:
                    train_loss = getattr(dl_model, 'train_loss_log', None)
                    val_loss = getattr(dl_model, 'val_loss_log', None)
                    if train_loss and val_loss:
                        print("[í•™ìŠµ ê³¡ì„ ] (ì—í¬í¬ë³„ ì†ì‹¤)")
                        for i, (tr, va) in enumerate(zip(train_loss, val_loss)):
                            if i % 10 == 0 or i == len(train_loss)-1:
                                print(f"Epoch {i}: Train Loss={tr:.4f}, Val Loss={va:.4f}")
                    else:
                        print("[í•™ìŠµ ê³¡ì„ ] ë¡œê·¸ ì—†ìŒ")
                except Exception as e:
                    print(f"[í•™ìŠµ ê³¡ì„ ] ì¶œë ¥ ì‹¤íŒ¨: {e}")
                # Overfitting Diagnosis
                if train_loss and val_loss:
                    min_val = min(val_loss)
                    min_idx = val_loss.index(min_val)
                    if min_idx < len(train_loss)-10:
                        print("[ì˜¤ë²„í”¼íŒ… ê²½ê³ ] ê²€ì¦ ì†ì‹¤ì´ ì¡°ê¸° ìµœì†Œí™” í›„ ì¦ê°€")
                    else:
                        print("[ì˜¤ë²„í”¼íŒ… ì—†ìŒ] í•™ìŠµ ì•ˆì •ì ")
                # Feature Importance (SHAP ë“±)
                print("[í”¼ì²˜ ì¤‘ìš”ë„] (ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ SHAP/Integrated Gradients ë³„ë„ êµ¬í˜„ í•„ìš”)")
                print("(ì¶”í›„ notebook/ì‹œê°í™”ì—ì„œ ì§€ì›)")
            else:
                print("\n[DLNet ê³ ê¸‰ ì„±ëŠ¥ ë¦¬í¬íŠ¸] DLNet ëª¨ë¸ì´ ì•™ìƒë¸”ì— ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\n[DLNet ê³ ê¸‰ ì„±ëŠ¥ ë¦¬í¬íŠ¸] ì¶œë ¥ ì‹¤íŒ¨: {e}")
        
    except Exception as e:
        logger.error(f"ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main()) 