#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ë³‘ë ¬ì²˜ë¦¬ í•µì‹¬ ëª¨ë“ˆ
- ë©€í‹°ë ˆë²¨ ìºì‹± ì‹œìŠ¤í…œ
- ì»¤ë„¥ì…˜ í’€ë§
- ë©”ëª¨ë¦¬ ìµœì í™”
- ì•ˆì •ì„± ìš°ì„  ì„¤ê³„
"""

import asyncio
import aiohttp
import logging
import time
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import threading
import weakref
import gc
from functools import wraps
import json
import hashlib

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬ ë°ì´í„° í´ë˜ìŠ¤"""
    data: Any
    timestamp: datetime
    ttl: int = 300  # 5ë¶„ ê¸°ë³¸ TTL
    access_count: int = 0
    
    def is_valid(self) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        return (datetime.now() - self.timestamp).seconds < self.ttl
    
    def touch(self):
        """ìºì‹œ ì ‘ê·¼ ì‹œ í˜¸ì¶œ"""
        self.access_count += 1

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    total_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    total_time: float = 0.0
    avg_response_time: float = 0.0
    error_count: int = 0
    
    @property
    def cache_hit_rate(self) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        total = self.cache_hits + self.cache_misses
        return (self.cache_hits / total * 100) if total > 0 else 0.0

class MultiLevelCache:
    """ğŸ”¥ ë©€í‹°ë ˆë²¨ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self._cache: Dict[str, CacheEntry] = {}
        self._lock = threading.RLock()
        self._metrics = PerformanceMetrics()
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì•½í•œ ì°¸ì¡°
        self._weak_refs = weakref.WeakValueDictionary()
        
        logger.info(f"âœ… ë©€í‹°ë ˆë²¨ ìºì‹œ ì´ˆê¸°í™” (ìµœëŒ€ í¬ê¸°: {max_size})")
    
    def _generate_key(self, *args, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{args}_{sorted(kwargs.items())}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self._lock:
            if key in self._cache:
                entry = self._cache[key]
                if entry.is_valid():
                    entry.touch()
                    self._metrics.cache_hits += 1
                    logger.debug(f"ğŸ¯ ìºì‹œ íˆíŠ¸: {key[:8]}...")
                    return entry.data
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì œê±°
                    del self._cache[key]
            
            self._metrics.cache_misses += 1
            logger.debug(f"âŒ ìºì‹œ ë¯¸ìŠ¤: {key[:8]}...")
            return None
    
    def set(self, key: str, data: Any, ttl: int = 300):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self._lock:
            # ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
            if len(self._cache) >= self.max_size:
                self._evict_lru()
            
            self._cache[key] = CacheEntry(
                data=data,
                timestamp=datetime.now(),
                ttl=ttl
            )
            logger.debug(f"ğŸ’¾ ìºì‹œ ì €ì¥: {key[:8]}... (TTL: {ttl}s)")
    
    def _evict_lru(self):
        """LRU ë°©ì‹ìœ¼ë¡œ ìºì‹œ ì œê±°"""
        if not self._cache:
            return
        
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì°¾ê¸°
        oldest_key = min(
            self._cache.keys(),
            key=lambda k: (self._cache[k].timestamp, self._cache[k].access_count)
        )
        
        del self._cache[oldest_key]
        logger.debug(f"ğŸ—‘ï¸ LRU ìºì‹œ ì œê±°: {oldest_key[:8]}...")
    
    def clear_expired(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        with self._lock:
            expired_keys = [
                key for key, entry in self._cache.items()
                if not entry.is_valid()
            ]
            
            for key in expired_keys:
                del self._cache[key]
            
            if expired_keys:
                logger.info(f"ğŸ§¹ ë§Œë£Œëœ ìºì‹œ {len(expired_keys)}ê°œ ì •ë¦¬")
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        with self._lock:
            return {
                "cache_size": len(self._cache),
                "max_size": self.max_size,
                "hit_rate": self._metrics.cache_hit_rate,
                "total_hits": self._metrics.cache_hits,
                "total_misses": self._metrics.cache_misses
            }

class ConnectionPool:
    """ğŸ”— ê³ ì„±ëŠ¥ ì»¤ë„¥ì…˜ í’€"""
    
    def __init__(self, max_connections: int = 100, timeout: int = 30):
        self.max_connections = max_connections
        self.timeout = timeout
        self._session: Optional[aiohttp.ClientSession] = None
        self._connector: Optional[aiohttp.TCPConnector] = None
        self._lock = asyncio.Lock()
        
        logger.info(f"âœ… ì»¤ë„¥ì…˜ í’€ ì´ˆê¸°í™” (ìµœëŒ€ ì—°ê²°: {max_connections})")
    
    async def get_session(self) -> aiohttp.ClientSession:
        """ì„¸ì…˜ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
        if self._session is None or self._session.closed:
            async with self._lock:
                if self._session is None or self._session.closed:
                    await self._create_session()
        
        return self._session
    
    async def _create_session(self):
        """ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„±"""
        # ê¸°ì¡´ ì„¸ì…˜ ì •ë¦¬
        if self._session and not self._session.closed:
            await self._session.close()
        
        # TCP ì»¤ë„¥í„° ì„¤ì •
        self._connector = aiohttp.TCPConnector(
            limit=self.max_connections,
            limit_per_host=20,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        # ì„¸ì…˜ ìƒì„±
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        self._session = aiohttp.ClientSession(
            connector=self._connector,
            timeout=timeout,
            headers={
                'User-Agent': 'US-Stock-Analyzer/1.0',
                'Accept': 'application/json',
                'Connection': 'keep-alive'
            }
        )
        
        logger.info("ğŸ”— ìƒˆë¡œìš´ HTTP ì„¸ì…˜ ìƒì„± ì™„ë£Œ")
    
    async def close(self):
        """ì»¤ë„¥ì…˜ í’€ ì •ë¦¬"""
        if self._session and not self._session.closed:
            await self._session.close()
            logger.info("ğŸ”— ì»¤ë„¥ì…˜ í’€ ì •ë¦¬ ì™„ë£Œ")

class AsyncTaskManager:
    """âš¡ ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ì"""
    
    def __init__(self, max_concurrent: int = 50, batch_size: int = 10):
        self.max_concurrent = max_concurrent
        self.batch_size = batch_size
        self._semaphore = asyncio.Semaphore(max_concurrent)
        self._active_tasks = set()
        
        logger.info(f"âœ… ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ì ì´ˆê¸°í™” (ë™ì‹œ ì‘ì—…: {max_concurrent}, ë°°ì¹˜ í¬ê¸°: {batch_size})")
    
    async def run_batch(self, tasks: List[Callable], *args, **kwargs) -> List[Any]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‘ì—… ì‹¤í–‰"""
        results = []
        
        # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        for i in range(0, len(tasks), self.batch_size):
            batch = tasks[i:i + self.batch_size]
            batch_results = await self._run_concurrent_batch(batch, *args, **kwargs)
            results.extend(batch_results)
            
            # ë°°ì¹˜ ê°„ ì§§ì€ ëŒ€ê¸° (API ì œí•œ íšŒí”¼)
            if i + self.batch_size < len(tasks):
                await asyncio.sleep(0.1)
        
        return results
    
    async def _run_concurrent_batch(self, batch: List[Callable], *args, **kwargs) -> List[Any]:
        """ë™ì‹œ ì‹¤í–‰ ë°°ì¹˜"""
        async def run_with_semaphore(task):
            async with self._semaphore:
                try:
                    if asyncio.iscoroutinefunction(task):
                        return await task(*args, **kwargs)
                    else:
                        return task(*args, **kwargs)
                except Exception as e:
                    logger.error(f"âŒ ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    return None
        
        # ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹œì‘
        batch_tasks = [run_with_semaphore(task) for task in batch]
        results = await asyncio.gather(*batch_tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"âŒ ë°°ì¹˜ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {result}")
                processed_results.append(None)
            else:
                processed_results.append(result)
        
        return processed_results

class MemoryOptimizer:
    """ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self, gc_threshold: int = 1000):
        self.gc_threshold = gc_threshold
        self._allocation_count = 0
        
        logger.info(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ê´€ë¦¬ì ì´ˆê¸°í™” (GC ì„ê³„ê°’: {gc_threshold})")
    
    def track_allocation(self):
        """ë©”ëª¨ë¦¬ í• ë‹¹ ì¶”ì """
        self._allocation_count += 1
        
        if self._allocation_count >= self.gc_threshold:
            self.force_cleanup()
            self._allocation_count = 0
    
    def force_cleanup(self):
        """ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        collected = gc.collect()
        if collected > 0:
            logger.debug(f"ğŸ§¹ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´ ì •ë¦¬")
    
    @staticmethod
    def optimize_dict(data: Dict) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ ë©”ëª¨ë¦¬ ìµœì í™”"""
        if not data:
            return {}
        
        # None ê°’ ì œê±°
        optimized = {k: v for k, v in data.items() if v is not None}
        
        # ë¬¸ìì—´ ìµœì í™”
        for key, value in optimized.items():
            if isinstance(value, str) and len(value) > 1000:
                optimized[key] = value[:1000] + "..."
        
        return optimized

def performance_monitor(func):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.debug(f"â±ï¸ {func.__name__} ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨ ({execution_time:.2f}ì´ˆ): {e}")
            raise
    
    return wrapper

class HighPerformanceCore:
    """ğŸš€ ê³ ì„±ëŠ¥ í•µì‹¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.cache = MultiLevelCache(max_size=20000)
        self.connection_pool = ConnectionPool(max_connections=100)
        self.task_manager = AsyncTaskManager(max_concurrent=50, batch_size=15)
        self.memory_optimizer = MemoryOptimizer(gc_threshold=1000)
        
        # ì„±ëŠ¥ í†µê³„
        self.start_time = datetime.now()
        self.total_requests = 0
        self.successful_requests = 0
        
        logger.info("ğŸš€ ê³ ì„±ëŠ¥ í•µì‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ì»¤ë„¥ì…˜ í’€ ì¤€ë¹„
            await self.connection_pool.get_session()
            
            # ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
            asyncio.create_task(self._cache_cleanup_scheduler())
            
            logger.info("âœ… ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _cache_cleanup_scheduler(self):
        """ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬"""
        while True:
            try:
                await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤
                self.cache.clear_expired()
                self.memory_optimizer.force_cleanup()
                
                # í†µê³„ ì¶œë ¥
                stats = self.get_performance_stats()
                logger.info(f"ğŸ“Š ì„±ëŠ¥ í†µê³„: {stats}")
                
            except Exception as e:
                logger.error(f"âŒ ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {e}")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        uptime = (datetime.now() - self.start_time).total_seconds()
        cache_stats = self.cache.get_stats()
        
        return {
            "uptime_seconds": uptime,
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "success_rate": (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0,
            "cache_stats": cache_stats,
            "requests_per_second": self.total_requests / uptime if uptime > 0 else 0
        }
    
    async def cleanup(self):
        """ì‹œìŠ¤í…œ ì •ë¦¬"""
        try:
            await self.connection_pool.close()
            self.memory_optimizer.force_cleanup()
            logger.info("âœ… ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_performance_core = None

async def get_performance_core() -> HighPerformanceCore:
    """ê³ ì„±ëŠ¥ í•µì‹¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _performance_core
    
    if _performance_core is None:
        _performance_core = HighPerformanceCore()
        await _performance_core.initialize()
    
    return _performance_core

if __name__ == "__main__":
    async def test_performance_core():
        """ì„±ëŠ¥ í•µì‹¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª ê³ ì„±ëŠ¥ í•µì‹¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        core = await get_performance_core()
        
        # ìºì‹œ í…ŒìŠ¤íŠ¸
        core.cache.set("test_key", {"data": "test_value"}, ttl=60)
        cached_data = core.cache.get("test_key")
        print(f"ğŸ“‹ ìºì‹œ í…ŒìŠ¤íŠ¸: {cached_data}")
        
        # ì„±ëŠ¥ í†µê³„
        stats = core.get_performance_stats()
        print(f"ğŸ“Š ì„±ëŠ¥ í†µê³„: {stats}")
        
        await core.cleanup()
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    asyncio.run(test_performance_core()) 