#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: quick_test.py
ëª¨ë“ˆ: ë¹ ë¥¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
ëª©ì : ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œì˜ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

Author: AI Assistant
Created: 2025-01-27
Modified: 2025-01-27
Version: 1.0.0
"""

from __future__ import annotations

import asyncio
import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path

try:
    import aiohttp
    import numpy as np
    import pandas as pd
    import redis.asyncio as redis
    import torch
except ImportError:
    aiohttp = None
    np = None
    pd = None
    redis = None
    torch = None

def test_environment() -> bool:
    """í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    print("ğŸ” í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸...")

    # Python ë²„ì „ í™•ì¸
    python_version = sys.version_info
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 11):
        print(f"âŒ Python 3.11+ í•„ìš” (í˜„ì¬: {python_version.major}.{python_version.minor})")
        return False
    print(f"âœ… Python ë²„ì „: {python_version.major}.{python_version.minor}.{python_version.micro}")

    # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
    required_packages = [
        'pandas', 'numpy', 'torch', 'aiohttp', 'redis'
    ]

    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package} íŒ¨í‚¤ì§€ í™•ì¸")
        except ImportError:
            missing_packages.append(package)
            print(f"âŒ {package} íŒ¨í‚¤ì§€ ëˆ„ë½")

    if missing_packages:
        print(f"\nâŒ ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
        print("pip install -r requirements_optimized.txtë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return False

    # GPU í™•ì¸
    if torch is None:
        print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GPU í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        try:
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                print(f"âœ… GPU í™•ì¸: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        except ImportError:
            print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_vars = ['LIVE_KIS_APP_KEY', 'LIVE_KIS_APP_SECRET']
    missing_env = [var for var in env_vars if not os.getenv(var)]

    if missing_env:
        print(f"âš ï¸ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_env)}")
        print("ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ì„œëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    else:
        print("âœ… í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸")

    return True

def test_redis_connection():
    """Redis ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”— Redis ì—°ê²° í…ŒìŠ¤íŠ¸...")

    try:

        # Redis ì—°ê²° í…ŒìŠ¤íŠ¸
        redis_client = redis.from_url('redis://localhost:6379/0', decode_responses=True)

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            loop.run_until_complete(redis_client.ping())
            print("âœ… Redis ì—°ê²° ì„±ê³µ")
            loop.run_until_complete(redis_client.close())
            return True
        except Exception as e:
            print(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
            print("Redis ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”: sudo systemctl start redis-server")
            return False
        finally:
            loop.close()

    except ImportError:
        print("âš ï¸ Redis íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

def test_gpu_functionality():
    """GPU ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nâš¡ GPU ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")

    try:

        if torch is None or not torch.cuda.is_available():
            print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU í…ŒìŠ¤íŠ¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return test_cpu_functionality()

        # GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
        device = torch.device('cuda')
        x = torch.randn(1000, 1000).to(device)
        y = torch.randn(1000, 1000).to(device)

        start_time = time.time()
        z = torch.mm(x, y)
        torch.cuda.synchronize()
        gpu_time = time.time() - start_time

        print(f"âœ… GPU í–‰ë ¬ ê³±ì…ˆ: {gpu_time:.4f}ì´ˆ")

        # CPU ë¹„êµ
        x_cpu = x.cpu()
        y_cpu = y.cpu()

        start_time = time.time()
        z_cpu = torch.mm(x_cpu, y_cpu)
        cpu_time = time.time() - start_time

        print(f"âœ… CPU í–‰ë ¬ ê³±ì…ˆ: {cpu_time:.4f}ì´ˆ")
        print(f"âœ… GPU ê°€ì† ë¹„ìœ¨: {cpu_time/gpu_time:.1f}x")

        return True

    except Exception as e:
        print(f"âŒ GPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_cpu_functionality():
    """CPU ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ’» CPU ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")

    try:

        # NumPy í…ŒìŠ¤íŠ¸
        start_time = time.time()
        x = np.random.randn(1000, 1000)
        y = np.random.randn(1000, 1000)
        z = np.dot(x, y)
        numpy_time = time.time() - start_time

        print(f"âœ… NumPy í–‰ë ¬ ê³±ì…ˆ: {numpy_time:.4f}ì´ˆ")

        # Pandas í…ŒìŠ¤íŠ¸
        start_time = time.time()
        df = pd.DataFrame(np.random.randn(10000, 10))
        result = df.describe()
        pandas_time = time.time() - start_time

        print(f"âœ… Pandas ë°ì´í„° ë¶„ì„: {pandas_time:.4f}ì´ˆ")

        return True

    except Exception as e:
        print(f"âŒ CPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_data_pipeline():
    """ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸...")

    try:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±

        # ê°€ìƒ ì£¼ì‹ ë°ì´í„° ìƒì„±
        dates = pd.date_range('2024-01-01', periods=1000, freq='D')
        symbols = ['005930', '000660', '035420']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER

        data = []
        for symbol in symbols:
            for date in dates:
                data.append({
                    'symbol': symbol,
                    'date': date,
                    'open': np.random.uniform(50000, 100000),
                    'high': np.random.uniform(50000, 100000),
                    'low': np.random.uniform(50000, 100000),
                    'close': np.random.uniform(50000, 100000),
                    'volume': np.random.randint(1000000, 10000000)
                })

        df = pd.DataFrame(data)

        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        start_time = time.time()

        # ì´ë™í‰ê· 
        df['ma_5'] = df.groupby('symbol')['close'].rolling(window=5).mean().reset_index(0, drop=True)
        df['ma_20'] = df.groupby('symbol')['close'].rolling(window=20).mean().reset_index(0, drop=True)

        # RSI
        def calculate_rsi(prices, window=14):
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
            rs = gain / loss
            return 100 - (100 / (1 + rs))

        df['rsi'] = df.groupby('symbol')['close'].apply(calculate_rsi)

        processing_time = time.time() - start_time

        print(f"âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(df):,} ë ˆì½”ë“œ")
        print(f"âœ… ì²˜ë¦¬ ì‹œê°„: {processing_time:.4f}ì´ˆ")
        print(f"âœ… ì²˜ë¦¬ ì†ë„: {len(df)/processing_time:.0f} ë ˆì½”ë“œ/ì´ˆ")

        # ê²°ê³¼ ì €ì¥
        output_file = f"test_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
        df.to_parquet(output_file, compression='snappy')

        file_size = Path(output_file).stat().st_size / (1024 * 1024)
        print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file} ({file_size:.1f}MB)")

        return True

    except Exception as e:
        print(f"âŒ ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_async_functionality():
    """ë¹„ë™ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”„ ë¹„ë™ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")

    async def async_test():

        # ë¹„ë™ê¸° HTTP ìš”ì²­ í…ŒìŠ¤íŠ¸
        async with aiohttp.ClientSession() as session:
            start_time = time.time()

            # ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì‹¤í–‰
            tasks = []
            for i in range(10):
                task = session.get('https://httpbin.org/delay/1')
                tasks.append(task)

            responses = await asyncio.gather(*tasks)
            async_time = time.time() - start_time

            print(f"âœ… ë¹„ë™ê¸° HTTP ìš”ì²­: {async_time:.4f}ì´ˆ (10ê°œ ìš”ì²­)")
            print(f"âœ… í‰ê·  ì‘ë‹µ ì‹œê°„: {async_time/10:.4f}ì´ˆ/ìš”ì²­")

            return len(responses) == 10

    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        result = loop.run_until_complete(async_test())
        loop.close()

        if result:
            print("âœ… ë¹„ë™ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        else:
            print("âŒ ë¹„ë™ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return False

    except Exception as e:
        print(f"âŒ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def generate_test_report(results):
    """í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸")
    print("=" * 50)

    total_tests = len(results)
    passed_tests = sum(results.values())

    for test_name, passed in results.items():
        status = "âœ… í†µê³¼" if passed else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")

    print(f"\nì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
    print(f"í†µê³¼: {passed_tests}ê°œ")
    print(f"ì‹¤íŒ¨: {total_tests - passed_tests}ê°œ")
    print(f"ì„±ê³µë¥ : {passed_tests/total_tests*100:.1f}%")

    if passed_tests == total_tests:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("1. í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš” (KIS API í‚¤)")
        print("2. python run_optimized_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ì‹¤íŒ¨í•œ í•­ëª©ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ìµœì í™”ëœ AI íŠ¸ë ˆì´ë”© íŒŒì´í”„ë¼ì¸ - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    start_time = time.time()

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results = {
        "í™˜ê²½ ì„¤ì •": test_environment(),
        "Redis ì—°ê²°": test_redis_connection(),
        "GPU/CPU ê¸°ëŠ¥": test_gpu_functionality(),
        "ë°ì´í„° íŒŒì´í”„ë¼ì¸": test_data_pipeline(),
        "ë¹„ë™ê¸° ê¸°ëŠ¥": test_async_functionality()
    }

    # í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    generate_test_report(test_results)

    total_time = time.time() - start_time
    print(f"\nì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_time:.2f}ì´ˆ")

if __name__ == "__main__":
    main()

