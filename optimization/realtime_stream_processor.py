#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: realtime_stream_processor.py
ëª¨ë“ˆ: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ
ëª©ì : ê³ ì† ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°, ì´ë²¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬, ì§€ì—°ì‹œê°„ ìµœì†Œí™”

Author: World-Class AI Trading System
Created: 2025-01-27
Version: 1.0.0

ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”:
âš¡ ê³ ì† ìŠ¤íŠ¸ë¦¬ë°:
- ë¬´ì ê¸ˆ í êµ¬ì¡°
- ë§ ë²„í¼ ìµœì í™”
- ì œë¡œì¹´í”¼ ë°ì´í„° ì „ì†¡
- ë©”ëª¨ë¦¬ í’€ ì¬ì‚¬ìš©

ğŸ“Š ì´ë²¤íŠ¸ ì²˜ë¦¬:
- ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜
- ë³µì¡ ì´ë²¤íŠ¸ ì²˜ë¦¬ (CEP)
- ìŠ¤íŠ¸ë¦¼ ì¡°ì¸ ì—°ì‚°
- ìœˆë„ìš° ì§‘ê³„ ì²˜ë¦¬

ğŸ”„ ë°±í”„ë ˆì…” ì œì–´:
- ì ì‘ì  ë°±í”„ë ˆì…”
- ë™ì  ë²„í¼ í¬ê¸° ì¡°ì •
- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë“œë¡­
- ë¶€í•˜ ë¶„ì‚°

â±ï¸ ì§€ì—°ì‹œê°„ ìµœì í™”:
- ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„ ì²˜ë¦¬
- CPU ìºì‹œ ìµœì í™”
- NUMA ì¸ì‹ ì²˜ë¦¬
- í•˜ë“œì›¨ì–´ ê°€ì†

License: MIT
"""

from __future__ import annotations
import asyncio
import time
import logging
from collections import deque
import defaultdict
from contextlib import asynccontextmanager
from dataclasses import dataclass
import field
from typing import (
    Dict, List, Optional, Any, Callable, AsyncIterator,
    Union, Tuple, TypeVar, Generic, Protocol
)
from concurrent.futures import ThreadPoolExecutor
from functools import wraps
import threading
import multiprocessing as mp
from queue import Queue
import Empty
import heapq
from enum import Enum
import uuid
import json
import numpy as np
import pandas as pd
from datetime import datetime
import timedelta
import weakref
import mmap
import os
import sys

# ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import uvloop
    if sys.platform != 'win32':
        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
except ImportError:
    pass

import psutil
import zmq
import zmq.asyncio
from prometheus_client import Counter
import Histogram, Gauge

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ë©”íŠ¸ë¦­ ì •ì˜
STREAM_MESSAGES = Counter('stream_messages_total', 'Total stream messages', ['stream_id', 'event_type'])
PROCESSING_LATENCY = Histogram('stream_processing_latency_seconds', 'Processing latency')
BUFFER_SIZE = Gauge('stream_buffer_size', 'Stream buffer size', ['stream_id'])
THROUGHPUT = Gauge('stream_throughput_per_second', 'Stream throughput', ['stream_id'])

T = TypeVar('T')
R = TypeVar('R')

class EventType(Enum):
    """ì´ë²¤íŠ¸ íƒ€ì…"""
    MARKET_DATA = "market_data"
    TRADE = "trade"
    ORDER = "order"
    NEWS = "news"
    HEARTBEAT = "heartbeat"
    CONTROL = "control"

class StreamState(Enum):
    """ìŠ¤íŠ¸ë¦¼ ìƒíƒœ"""
    STARTING = "starting"
    RUNNING = "running"
    PAUSED = "paused"
    STOPPING = "stopping"
    STOPPED = "stopped"
    ERROR = "error"

@dataclass
class StreamEvent:
    """ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸"""
    id: str
    event_type: EventType
    timestamp: float
    data: Any
    source: str
    sequence: int = 0
    priority: int = 0
    ttl: float = 0.0  # Time to live

    def __lt__(self, other):
        return self.priority > other.priority

@dataclass
class StreamWindow:
    """ìŠ¤íŠ¸ë¦¼ ìœˆë„ìš°"""
    window_id: str
    start_time: float
    end_time: float
    events: List[StreamEvent] = field(default_factory=list)
    aggregated_data: Optional[Any] = None

    def add_event(self, event: StreamEvent):
        """ì´ë²¤íŠ¸ ì¶”ê°€"""
        if self.start_time <= event.timestamp < self.end_time:
            self.events.append(event)
            return True
        return False

    def is_complete(self) -> bool:
        """ìœˆë„ìš° ì™„ë£Œ ì—¬ë¶€"""
        return time.time() >= self.end_time

@dataclass
class StreamConfig:
    """ìŠ¤íŠ¸ë¦¼ ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    stream_id: str
    buffer_size: int = 100000
    batch_size: int = 1000
    max_latency_ms: float = 10.0

    # ë°±í”„ë ˆì…” ì„¤ì •
    enable_backpressure: bool = True
    backpressure_threshold: float = 0.8
    drop_policy: str = "oldest"  # oldest, newest, lowest_priority

    # ìœˆë„ìš° ì„¤ì •
    window_size_ms: float = 1000.0
    window_slide_ms: float = 100.0
    enable_windowing: bool = True

    # ì„±ëŠ¥ ì„¤ì •
    enable_zero_copy: bool = True
    numa_aware: bool = True
    cpu_affinity: Optional[List[int]] = None

    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    enable_metrics: bool = True
    metrics_interval_ms: float = 1000.0

class LockFreeRingBuffer:
    """ë¬´ì ê¸ˆ ë§ ë²„í¼"""

    def __init__(self, capacity: int):
        self.capacity = capacity
        self.buffer = [None] * capacity
        self.head = 0
        self.tail = 0
        self.size = 0
        self._lock = threading.Lock()  # ë°±ì—…ìš©

    def put(self, item: Any) -> bool:
        """ì•„ì´í…œ ì¶”ê°€"""
        with self._lock:
            if self.size >= self.capacity:
                return False

            self.buffer[self.tail] = item
            self.tail = (self.tail + 1) % self.capacity
            self.size += 1
            return True

    def get(self) -> Optional[Any]:
        """ì•„ì´í…œ ì¡°íšŒ"""
        with self._lock:
            if self.size == 0:
                return None

            item = self.buffer[self.head]
            self.buffer[self.head] = None
            self.head = (self.head + 1) % self.capacity
            self.size -= 1
            return item

    def is_full(self) -> bool:
        """ë²„í¼ ê°€ë“ ì°¸ ì—¬ë¶€"""
        return self.size >= self.capacity

    def is_empty(self) -> bool:
        """ë²„í¼ ë¹„ì–´ìˆìŒ ì—¬ë¶€"""
        return self.size == 0

    def current_size(self) -> int:
        """í˜„ì¬ í¬ê¸°"""
        return self.size

class StreamBuffer:
    """ìŠ¤íŠ¸ë¦¼ ë²„í¼"""

    def __init__(self, config: StreamConfig):
        self.config = config
        self.ring_buffer = LockFreeRingBuffer(config.buffer_size)
        self.priority_queue = []
        self.sequence_counter = 0
        self.dropped_events = 0
        self.total_events = 0
        self.lock = threading.Lock()

    def put(self, event: StreamEvent) -> bool:
        """ì´ë²¤íŠ¸ ì¶”ê°€"""
        self.total_events += 1

        # TTL ì²´í¬
        if event.ttl > 0 and time.time() > event.timestamp + event.ttl:
            self.dropped_events += 1
            return False

        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ í• ë‹¹
        event.sequence = self.sequence_counter
        self.sequence_counter += 1

        # ë°±í”„ë ˆì…” ì²´í¬
        if self.config.enable_backpressure:
            buffer_ratio = self.ring_buffer.current_size() / self.config.buffer_size
            if buffer_ratio > self.config.backpressure_threshold:
                return self._handle_backpressure(event)

        # ìš°ì„ ìˆœìœ„ í ì‚¬ìš©
        if event.priority > 0:
            with self.lock:
                heapq.heappush(self.priority_queue, event)
            return True

        # ë§ ë²„í¼ì— ì¶”ê°€
        return self.ring_buffer.put(event)

    def get(self) -> Optional[StreamEvent]:
        """ì´ë²¤íŠ¸ ì¡°íšŒ"""
        # ìš°ì„ ìˆœìœ„ í ë¨¼ì € í™•ì¸
        with self.lock:
            if self.priority_queue:
                return heapq.heappop(self.priority_queue)

        # ë§ ë²„í¼ì—ì„œ ì¡°íšŒ
        return self.ring_buffer.get()

    def get_batch(self, batch_size: int) -> List[StreamEvent]:
        """ë°°ì¹˜ ì¡°íšŒ"""
        batch = []
        for _ in range(batch_size):
            event = self.get()
            if event is None:
                break
            batch.append(event)
        return batch

    def _handle_backpressure(self, event: StreamEvent) -> bool:
        """ë°±í”„ë ˆì…” ì²˜ë¦¬"""
        if self.config.drop_policy == "newest":
            # ìƒˆ ì´ë²¤íŠ¸ ë“œë¡­
            self.dropped_events += 1
            return False

        elif self.config.drop_policy == "oldest":
            # ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ë“œë¡­
            old_event = self.ring_buffer.get()
            if old_event:
                self.dropped_events += 1
            return self.ring_buffer.put(event)

        elif self.config.drop_policy == "lowest_priority":
            # ë‚®ì€ ìš°ì„ ìˆœìœ„ ì´ë²¤íŠ¸ ë“œë¡­
            if event.priority > 0:
                # ìš°ì„ ìˆœìœ„ íì—ì„œ ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„ ì œê±°
                with self.lock:
                    if self.priority_queue:
                        dropped = heapq.heappop(self.priority_queue)
                        if dropped.priority >= event.priority:
                            heapq.heappush(self.priority_queue, dropped)
                            self.dropped_events += 1
                            return False
                        else:
                            heapq.heappush(self.priority_queue, event)
                            self.dropped_events += 1
                            return True

            # ì¼ë°˜ ì´ë²¤íŠ¸ëŠ” ë“œë¡­
            self.dropped_events += 1
            return False

        return False

    def get_stats(self) -> Dict[str, Any]:
        """ë²„í¼ í†µê³„"""
        return {
            'buffer_size': self.ring_buffer.current_size(),
            'priority_queue_size': len(self.priority_queue),
            'total_events': self.total_events,
            'dropped_events': self.dropped_events,
            'drop_rate': self.dropped_events / max(self.total_events, 1),
            'buffer_utilization': self.ring_buffer.current_size() / self.config.buffer_size,
        }

class WindowManager:
    """ìœˆë„ìš° ê´€ë¦¬ì"""

    def __init__(self, config: StreamConfig):
        self.config = config
        self.windows = {}
        self.completed_windows = deque(maxlen=100)
        self.window_counter = 0
        self.lock = threading.Lock()

    def add_event(self, event: StreamEvent):
        """ì´ë²¤íŠ¸ë¥¼ ìœˆë„ìš°ì— ì¶”ê°€"""
        if not self.config.enable_windowing:
            return

        current_time = event.timestamp
        window_id = self._get_window_id(current_time)

        with self.lock:
            if window_id not in self.windows:
                self.windows[window_id] = self._create_window(current_time)

            window = self.windows[window_id]
            window.add_event(event)

    def get_completed_windows(self) -> List[StreamWindow]:
        """ì™„ë£Œëœ ìœˆë„ìš° ë°˜í™˜"""
        completed = []
        current_time = time.time()

        with self.lock:
            expired_windows = []
            for window_id, window in self.windows.items():
                if window.end_time <= current_time:
                    completed.append(window)
                    expired_windows.append(window_id)

            # ì™„ë£Œëœ ìœˆë„ìš° ì œê±°
            for window_id in expired_windows:
                del self.windows[window_id]

        return completed

    def _get_window_id(self, timestamp: float) -> str:
        """ìœˆë„ìš° ID ìƒì„±"""
        window_start = int(timestamp / (self.config.window_slide_ms / 1000)) * (self.config.window_slide_ms / 1000)
        return f"window_{window_start:.3f}"

    def _create_window(self, timestamp: float) -> StreamWindow:
        """ìœˆë„ìš° ìƒì„±"""
        window_start = int(timestamp / (self.config.window_slide_ms / 1000)) * (self.config.window_slide_ms / 1000)
        window_end = window_start + (self.config.window_size_ms / 1000)

        return StreamWindow(
            window_id=f"window_{self.window_counter}",
            start_time=window_start,
            end_time=window_end
        )

class StreamProcessor:
    """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸°"""

    def __init__(self, config: StreamConfig):
        self.config = config
        self.buffer = StreamBuffer(config)
        self.window_manager = WindowManager(config)
        self.processors = {}
        self.state = StreamState.STOPPED

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.processed_events = 0
        self.processing_times = deque(maxlen=1000)
        self.throughput_samples = deque(maxlen=100)
        self.last_throughput_time = time.time()

        # ì‘ì—…ì ìŠ¤ë ˆë“œ
        self.worker_threads = []
        self.is_running = False

        # ë©”íŠ¸ë¦­ ìŠ¤ë ˆë“œ
        self.metrics_thread = None

    def register_processor(self, event_type: EventType, processor: Callable[[StreamEvent], Any]):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬ê¸° ë“±ë¡"""
        self.processors[event_type] = processor
        logger.info(f"ì²˜ë¦¬ê¸° ë“±ë¡: {event_type.value}")

    def register_window_processor(self, processor: Callable[[StreamWindow], Any]):
        """ìœˆë„ìš° ì²˜ë¦¬ê¸° ë“±ë¡"""
        self.window_processor = processor
        logger.info("ìœˆë„ìš° ì²˜ë¦¬ê¸° ë“±ë¡")

    async def start(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘"""
        logger.info(f"ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸° ì‹œì‘: {self.config.stream_id}")

        self.state = StreamState.STARTING
        self.is_running = True

        # ì‘ì—…ì ìŠ¤ë ˆë“œ ì‹œì‘
        num_workers = min(mp.cpu_count(), 8)
        for i in range(num_workers):
            worker = threading.Thread(target=self._worker_loop, args=(f"worker-{i}",))
            worker.daemon = True
            worker.start()
            self.worker_threads.append(worker)

        # ìœˆë„ìš° ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
        window_worker = threading.Thread(target=self._window_worker_loop)
        window_worker.daemon = True
        window_worker.start()
        self.worker_threads.append(window_worker)

        # ë©”íŠ¸ë¦­ ìŠ¤ë ˆë“œ ì‹œì‘
        if self.config.enable_metrics:
            self.metrics_thread = threading.Thread(target=self._metrics_loop)
            self.metrics_thread.daemon = True
            self.metrics_thread.start()

        self.state = StreamState.RUNNING
        logger.info(f"ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸° ì‹œì‘ ì™„ë£Œ: {num_workers}ê°œ ì›Œì»¤")

    async def stop(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ì§€"""
        logger.info(f"ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸° ì¤‘ì§€: {self.config.stream_id}")

        self.state = StreamState.STOPPING
        self.is_running = False

        # ì‘ì—…ì ìŠ¤ë ˆë“œ ëŒ€ê¸°
        for worker in self.worker_threads:
            worker.join(timeout=5)

        if self.metrics_thread:
            self.metrics_thread.join(timeout=5)

        self.state = StreamState.STOPPED
        logger.info("ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸° ì¤‘ì§€ ì™„ë£Œ")

    def put_event(self, event: StreamEvent) -> bool:
        """ì´ë²¤íŠ¸ ì¶”ê°€"""
        if self.state != StreamState.RUNNING:
            return False

        success = self.buffer.put(event)
        if success:
            STREAM_MESSAGES.labels(
                stream_id=self.config.stream_id,
                event_type=event.event_type.value
            ).inc()

            # ìœˆë„ìš°ì— ì¶”ê°€
            self.window_manager.add_event(event)

        return success

    def _worker_loop(self, worker_id: str):
        """ì‘ì—…ì ë£¨í”„"""
        logger.info(f"ì‘ì—…ì {worker_id} ì‹œì‘")

        while self.is_running:
            try:
                # ë°°ì¹˜ ì²˜ë¦¬
                batch = self.buffer.get_batch(self.config.batch_size)
                if not batch:
                    time.sleep(0.001)  # 1ms ëŒ€ê¸°
                    continue

                # ì´ë²¤íŠ¸ ì²˜ë¦¬
                start_time = time.time()
                for event in batch:
                    self._process_event(event)

                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
                processing_time = time.time() - start_time
                self.processing_times.append(processing_time)
                self.processed_events += len(batch)

                PROCESSING_LATENCY.observe(processing_time / len(batch))

            except Exception as e:
                logger.error(f"ì‘ì—…ì {worker_id} ì˜¤ë¥˜: {e}")
                time.sleep(0.1)

        logger.info(f"ì‘ì—…ì {worker_id} ì¢…ë£Œ")

    def _window_worker_loop(self):
        """ìœˆë„ìš° ì²˜ë¦¬ ë£¨í”„"""
        logger.info("ìœˆë„ìš° ì‘ì—…ì ì‹œì‘")

        while self.is_running:
            try:
                # ì™„ë£Œëœ ìœˆë„ìš° ì²˜ë¦¬
                completed_windows = self.window_manager.get_completed_windows()

                for window in completed_windows:
                    if hasattr(self, 'window_processor'):
                        try:
                            self.window_processor(window)
                        except Exception as e:
                            logger.error(f"ìœˆë„ìš° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

                time.sleep(0.1)  # 100ms ëŒ€ê¸°

            except Exception as e:
                logger.error(f"ìœˆë„ìš° ì‘ì—…ì ì˜¤ë¥˜: {e}")
                time.sleep(1)

        logger.info("ìœˆë„ìš° ì‘ì—…ì ì¢…ë£Œ")

    def _process_event(self, event: StreamEvent):
        """ê°œë³„ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        try:
            processor = self.processors.get(event.event_type)
            if processor:
                processor(event)
            else:
                logger.warning(f"ì²˜ë¦¬ê¸° ì—†ìŒ: {event.event_type.value}")

        except Exception as e:
            logger.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def _metrics_loop(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë£¨í”„"""
        logger.info("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì‹œì‘")

        while self.is_running:
            try:
                # ë²„í¼ í¬ê¸° ë©”íŠ¸ë¦­
                buffer_stats = self.buffer.get_stats()
                BUFFER_SIZE.labels(stream_id=self.config.stream_id).set(buffer_stats['buffer_size'])

                # ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­
                current_time = time.time()
                time_diff = current_time - self.last_throughput_time
                if time_diff >= 1.0:  # 1ì´ˆë§ˆë‹¤
                    throughput = self.processed_events / time_diff
                    THROUGHPUT.labels(stream_id=self.config.stream_id).set(throughput)

                    self.throughput_samples.append(throughput)
                    self.processed_events = 0
                    self.last_throughput_time = current_time

                time.sleep(self.config.metrics_interval_ms / 1000)

            except Exception as e:
                logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                time.sleep(1)

        logger.info("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¢…ë£Œ")

    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        buffer_stats = self.buffer.get_stats()

        return {
            'stream_id': self.config.stream_id,
            'state': self.state.value,
            'processed_events': self.processed_events,
            'avg_processing_time': np.mean(self.processing_times) if self.processing_times else 0,
            'avg_throughput': np.mean(self.throughput_samples) if self.throughput_samples else 0,
            'buffer_stats': buffer_stats,
            'active_windows': len(self.window_manager.windows),
        }

class RealtimeStreamProcessor:
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.streams = {}
        self.global_stats = {
            'total_events': 0,
            'total_streams': 0,
            'start_time': time.time(),
        }

    def create_stream(self, config: StreamConfig) -> StreamProcessor:
        """ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        if config.stream_id in self.streams:
            raise ValueError(f"ìŠ¤íŠ¸ë¦¼ ì´ë¯¸ ì¡´ì¬: {config.stream_id}")

        stream = StreamProcessor(config)
        self.streams[config.stream_id] = stream
        self.global_stats['total_streams'] += 1

        logger.info(f"ìŠ¤íŠ¸ë¦¼ ìƒì„±: {config.stream_id}")
        return stream

    async def start_stream(self, stream_id: str):
        """ìŠ¤íŠ¸ë¦¼ ì‹œì‘"""
        if stream_id not in self.streams:
            raise ValueError(f"ìŠ¤íŠ¸ë¦¼ ì—†ìŒ: {stream_id}")

        await self.streams[stream_id].start()

    async def stop_stream(self, stream_id: str):
        """ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€"""
        if stream_id not in self.streams:
            raise ValueError(f"ìŠ¤íŠ¸ë¦¼ ì—†ìŒ: {stream_id}")

        await self.streams[stream_id].stop()

    async def start_all_streams(self):
        """ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ì‹œì‘"""
        for stream in self.streams.values():
            await stream.start()

    async def stop_all_streams(self):
        """ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€"""
        for stream in self.streams.values():
            await stream.stop()

    def get_stream(self, stream_id: str) -> Optional[StreamProcessor]:
        """ìŠ¤íŠ¸ë¦¼ ì¡°íšŒ"""
        return self.streams.get(stream_id)

    def put_event(self, stream_id: str, event: StreamEvent) -> bool:
        """ì´ë²¤íŠ¸ ì¶”ê°€"""
        stream = self.streams.get(stream_id)
        if stream:
            success = stream.put_event(event)
            if success:
                self.global_stats['total_events'] += 1
            return success
        return False

    def get_global_stats(self) -> Dict[str, Any]:
        """ì „ì²´ í†µê³„"""
        runtime = time.time() - self.global_stats['start_time']

        stream_stats = {}
        for stream_id, stream in self.streams.items():
            stream_stats[stream_id] = stream.get_stats()

        return {
            'runtime_seconds': runtime,
            'total_events': self.global_stats['total_events'],
            'total_streams': self.global_stats['total_streams'],
            'events_per_second': self.global_stats['total_events'] / max(runtime, 1),
            'streams': stream_stats,
        }

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    try:
        # ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ ìƒì„±
        processor = RealtimeStreamProcessor()

        # ìŠ¤íŠ¸ë¦¼ ì„¤ì •
        config = StreamConfig(
            stream_id="market_data",
            buffer_size=50000,
            batch_size=500,
            max_latency_ms=5.0,
            enable_windowing=True,
            window_size_ms=1000.0,
            window_slide_ms=100.0,
        )

        # ìŠ¤íŠ¸ë¦¼ ìƒì„±
        stream = processor.create_stream(config)

        # ì´ë²¤íŠ¸ ì²˜ë¦¬ê¸° ë“±ë¡
        def process_market_data(event: StreamEvent):
            # ì‹œì¥ ë°ì´í„° ì²˜ë¦¬
            data = event.data
            logger.info(f"ì‹œì¥ ë°ì´í„° ì²˜ë¦¬: {data.get('symbol', 'Unknown')}")

        def process_window(window: StreamWindow):
            # ìœˆë„ìš° ì§‘ê³„ ì²˜ë¦¬
            logger.info(f"ìœˆë„ìš° ì²˜ë¦¬: {len(window.events)}ê°œ ì´ë²¤íŠ¸")

        stream.register_processor(EventType.MARKET_DATA, process_market_data)
        stream.register_window_processor(process_window)

        # ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        await processor.start_stream("market_data")

        # í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸ ìƒì„±
        logger.info("í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸ ìƒì„±")
        for i in range(10000):
            event = StreamEvent(
                id=f"event_{i}",
                event_type=EventType.MARKET_DATA,
                timestamp=time.time(),
                data={
                    'symbol': f'STOCK_{i % 100}',
                    'price': 100.0 + i * 0.1,
                    'volume': 1000 + i * 10,
                },
                source="test_generator"
            )

            success = processor.put_event("market_data", event)
            if not success:
                logger.warning(f"ì´ë²¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {event.id}")

            if i % 1000 == 0:
                await asyncio.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°

        # ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
        await asyncio.sleep(5)

        # í†µê³„ ì¶œë ¥
        stats = processor.get_global_stats()
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ í†µê³„: {stats}")

        # ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
        await processor.stop_stream("market_data")

    except Exception as e:
        logger.error(f"ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
