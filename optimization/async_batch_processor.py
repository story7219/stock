#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: async_batch_processor.py
ëª¨ë“ˆ: ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ
ëª©ì : ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬, ë™ì  ë¡œë“œ ë°¸ëŸ°ì‹±, ë°±í”„ë ˆì…” ì œì–´

Author: World-Class AI Trading System
Created: 2025-01-27
Version: 1.0.0

ê³ ê¸‰ ë°°ì¹˜ ì²˜ë¦¬ ê¸°ë²•:
âš¡ ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬:
- ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ì ì‘ì  ì²˜ë¦¬ëŸ‰ ì œì–´
- ë°±í”„ë ˆì…” ë©”ì»¤ë‹ˆì¦˜
- ìš°ì„ ìˆœìœ„ í ê´€ë¦¬

ğŸ”„ ë¡œë“œ ë°¸ëŸ°ì‹±:
- ì‘ì—… ë¶€í•˜ ë¶„ì‚°
- ë™ì  ì›Œì»¤ ìŠ¤ì¼€ì¼ë§
- ì²˜ë¦¬ ì‹œê°„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

ğŸ“Š ì„±ëŠ¥ ìµœì í™”:
- ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”
- ì§€ì—°ì‹œê°„ ìµœì†Œí™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- CPU í™œìš©ë¥  ìµœì í™”

ğŸ›¡ï¸ ì•ˆì •ì„± ë³´ì¥:
- ì˜¤ë¥˜ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
- ì¬ì‹œë„ ì •ì±…
- ë°ë“œë½ ë°©ì§€
- íƒ€ì„ì•„ì›ƒ ê´€ë¦¬

License: MIT
"""

from __future__ import annotations
import asyncio
import time
import logging
from collections import deque, defaultdict
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from typing import (
    Dict, List, Optional, Any, Callable, Coroutine,
    AsyncIterator, Union, Tuple, TypeVar, Generic
)
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from functools import wraps
import threading
import multiprocessing as mp
import psutil
import weakref
import heapq
from enum import Enum
import uuid
import pickle
import json
import numpy as np
import pandas as pd

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

T = TypeVar('T')
R = TypeVar('R')

class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class BatchTask:
    """ë°°ì¹˜ ì‘ì—… í´ë˜ìŠ¤"""
    id: str
    data: Any
    processor: Callable
    priority: TaskPriority = TaskPriority.NORMAL
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Any] = None
    error: Optional[Exception] = None
    retry_count: int = 0
    max_retries: int = 3
    timeout: float = 300.0

    def __lt__(self, other):
        """ìš°ì„ ìˆœìœ„ ë¹„êµ"""
        return self.priority.value > other.priority.value

@dataclass
class BatchConfig:
    """ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    batch_size: int = 100
    max_batch_size: int = 1000
    min_batch_size: int = 10
    max_workers: int = mp.cpu_count()

    # íƒ€ì´ë° ì„¤ì •
    batch_timeout: float = 5.0
    processing_timeout: float = 300.0
    worker_timeout: float = 60.0

    # ë°±í”„ë ˆì…” ì„¤ì •
    max_queue_size: int = 10000
    backpressure_threshold: float = 0.8

    # ë™ì  ì¡°ì • ì„¤ì •
    enable_dynamic_sizing: bool = True
    performance_window: int = 100
    adjustment_factor: float = 1.2

    # ì¬ì‹œë„ ì„¤ì •
    max_retries: int = 3
    retry_delay: float = 1.0
    exponential_backoff: bool = True

class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""

    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.processing_times = deque(maxlen=window_size)
        self.throughput_samples = deque(maxlen=window_size)
        self.error_rates = deque(maxlen=window_size)
        self.queue_sizes = deque(maxlen=window_size)
        self.memory_usage = deque(maxlen=window_size)
        self.cpu_usage = deque(maxlen=window_size)

        self.total_processed = 0
        self.total_errors = 0
        self.start_time = time.time()

    def record_processing_time(self, duration: float):
        """ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡"""
        self.processing_times.append(duration)

    def record_throughput(self, items_per_second: float):
        """ì²˜ë¦¬ëŸ‰ ê¸°ë¡"""
        self.throughput_samples.append(items_per_second)

    def record_error_rate(self, error_rate: float):
        """ì˜¤ë¥˜ìœ¨ ê¸°ë¡"""
        self.error_rates.append(error_rate)

    def record_queue_size(self, size: int):
        """í í¬ê¸° ê¸°ë¡"""
        self.queue_sizes.append(size)

    def record_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.memory_usage.append(psutil.virtual_memory().percent)
        self.cpu_usage.append(psutil.cpu_percent())

    def get_avg_processing_time(self) -> float:
        """í‰ê·  ì²˜ë¦¬ ì‹œê°„"""
        return np.mean(self.processing_times) if self.processing_times else 0.0

    def get_avg_throughput(self) -> float:
        """í‰ê·  ì²˜ë¦¬ëŸ‰"""
        return np.mean(self.throughput_samples) if self.throughput_samples else 0.0

    def get_avg_error_rate(self) -> float:
        """í‰ê·  ì˜¤ë¥˜ìœ¨"""
        return np.mean(self.error_rates) if self.error_rates else 0.0

    def get_p95_processing_time(self) -> float:
        """95% ì²˜ë¦¬ ì‹œê°„"""
        return np.percentile(self.processing_times, 95) if self.processing_times else 0.0

    def get_system_load(self) -> Dict[str, float]:
        """ì‹œìŠ¤í…œ ë¶€í•˜ ì •ë³´"""
        return {
            'cpu_percent': np.mean(self.cpu_usage) if self.cpu_usage else 0.0,
            'memory_percent': np.mean(self.memory_usage) if self.memory_usage else 0.0,
            'avg_queue_size': np.mean(self.queue_sizes) if self.queue_sizes else 0.0,
        }

class DynamicBatchSizer:
    """ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •ê¸°"""

    def __init__(self, config: BatchConfig, metrics: PerformanceMetrics):
        self.config = config
        self.metrics = metrics
        self.current_batch_size = config.batch_size
        self.last_adjustment = time.time()
        self.adjustment_interval = 30.0  # 30ì´ˆë§ˆë‹¤ ì¡°ì •

    def should_adjust(self) -> bool:
        """ì¡°ì • í•„ìš” ì—¬ë¶€ í™•ì¸"""
        return (time.time() - self.last_adjustment > self.adjustment_interval and
                len(self.metrics.processing_times) >= self.config.performance_window)

    def adjust_batch_size(self) -> int:
        """ë°°ì¹˜ í¬ê¸° ì¡°ì •"""
        if not self.should_adjust():
            return self.current_batch_size

        # ì„±ëŠ¥ ì§€í‘œ ë¶„ì„
        avg_processing_time = self.metrics.get_avg_processing_time()
        avg_throughput = self.metrics.get_avg_throughput()
        system_load = self.metrics.get_system_load()

        # ì¡°ì • ê²°ì •
        adjustment_factor = 1.0

        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë°˜ ì¡°ì •
        if avg_processing_time > 10.0:  # 10ì´ˆ ì´ìƒì´ë©´ ë°°ì¹˜ í¬ê¸° ê°ì†Œ
            adjustment_factor *= 0.8
        elif avg_processing_time < 2.0:  # 2ì´ˆ ë¯¸ë§Œì´ë©´ ë°°ì¹˜ í¬ê¸° ì¦ê°€
            adjustment_factor *= 1.2

        # ì‹œìŠ¤í…œ ë¶€í•˜ ê¸°ë°˜ ì¡°ì •
        if system_load['cpu_percent'] > 80:
            adjustment_factor *= 0.9
        elif system_load['cpu_percent'] < 50:
            adjustment_factor *= 1.1

        if system_load['memory_percent'] > 85:
            adjustment_factor *= 0.8

        # ìƒˆ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        new_batch_size = int(self.current_batch_size * adjustment_factor)
        new_batch_size = max(self.config.min_batch_size,
                           min(self.config.max_batch_size, new_batch_size))

        if new_batch_size != self.current_batch_size:
            logger.info(f"ë°°ì¹˜ í¬ê¸° ì¡°ì •: {self.current_batch_size} â†’ {new_batch_size}")
            self.current_batch_size = new_batch_size
            self.last_adjustment = time.time()

        return self.current_batch_size

class BackpressureController:
    """ë°±í”„ë ˆì…” ì œì–´ê¸°"""

    def __init__(self, config: BatchConfig):
        self.config = config
        self.queue_size_history = deque(maxlen=50)
        self.processing_rate_history = deque(maxlen=50)
        self.backpressure_active = False
        self.last_check = time.time()

    def check_backpressure(self, queue_size: int, processing_rate: float) -> bool:
        """ë°±í”„ë ˆì…” ìƒíƒœ í™•ì¸"""
        self.queue_size_history.append(queue_size)
        self.processing_rate_history.append(processing_rate)

        # í í¬ê¸° ê¸°ë°˜ ë°±í”„ë ˆì…”
        queue_ratio = queue_size / self.config.max_queue_size
        if queue_ratio > self.config.backpressure_threshold:
            if not self.backpressure_active:
                logger.warning(f"ë°±í”„ë ˆì…” í™œì„±í™”: í í¬ê¸° {queue_size}/{self.config.max_queue_size}")
                self.backpressure_active = True
            return True

        # ì²˜ë¦¬ìœ¨ ê¸°ë°˜ ë°±í”„ë ˆì…”
        if len(self.processing_rate_history) >= 10:
            avg_rate = np.mean(list(self.processing_rate_history)[-10:])
            if avg_rate < 1.0:  # ì´ˆë‹¹ 1ê°œ ë¯¸ë§Œ
                if not self.backpressure_active:
                    logger.warning(f"ë°±í”„ë ˆì…” í™œì„±í™”: ë‚®ì€ ì²˜ë¦¬ìœ¨ {avg_rate:.2f}/s")
                    self.backpressure_active = True
                return True

        # ë°±í”„ë ˆì…” í•´ì œ
        if self.backpressure_active and queue_ratio < 0.5:
            logger.info("ë°±í”„ë ˆì…” í•´ì œ")
            self.backpressure_active = False

        return False

    def get_backpressure_delay(self) -> float:
        """ë°±í”„ë ˆì…” ì§€ì—° ì‹œê°„ ê³„ì‚°"""
        if not self.backpressure_active:
            return 0.0

        # í í¬ê¸°ì— ë”°ë¥¸ ì§€ì—° ì‹œê°„
        if self.queue_size_history:
            latest_queue_size = self.queue_size_history[-1]
            queue_ratio = latest_queue_size / self.config.max_queue_size
            return min(5.0, queue_ratio * 2.0)  # ìµœëŒ€ 5ì´ˆ

        return 1.0

class WorkerPool:
    """ì›Œì»¤ í’€ ê´€ë¦¬ì"""

    def __init__(self, config: BatchConfig):
        self.config = config
        self.workers = []
        self.active_workers = 0
        self.worker_stats = defaultdict(lambda: {'processed': 0, 'errors': 0, 'avg_time': 0.0})
        self.lock = asyncio.Lock()

    async def start_workers(self, worker_func: Callable):
        """ì›Œì»¤ ì‹œì‘"""
        async with self.lock:
            for i in range(self.config.max_workers):
                worker = asyncio.create_task(self._worker_loop(f"worker-{i}", worker_func))
                self.workers.append(worker)

            logger.info(f"ì›Œì»¤ í’€ ì‹œì‘: {len(self.workers)}ê°œ ì›Œì»¤")

    async def stop_workers(self):
        """ì›Œì»¤ ì¢…ë£Œ"""
        async with self.lock:
            for worker in self.workers:
                worker.cancel()

            await asyncio.gather(*self.workers, return_exceptions=True)
            self.workers.clear()

            logger.info("ì›Œì»¤ í’€ ì¢…ë£Œ")

    async def _worker_loop(self, worker_id: str, worker_func: Callable):
        """ì›Œì»¤ ë£¨í”„"""
        logger.info(f"ì›Œì»¤ {worker_id} ì‹œì‘")

        try:
            while True:
                try:
                    # ì‘ì—… ì²˜ë¦¬
                    await worker_func(worker_id)

                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {e}")
                    self.worker_stats[worker_id]['errors'] += 1
                    await asyncio.sleep(1)

        finally:
            logger.info(f"ì›Œì»¤ {worker_id} ì¢…ë£Œ")

    def get_worker_stats(self) -> Dict[str, Dict[str, Any]]:
        """ì›Œì»¤ í†µê³„ ë°˜í™˜"""
        return dict(self.worker_stats)

class AsyncBatchProcessor(Generic[T, R]):
    """ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸°"""

    def __init__(self, config: BatchConfig):
        self.config = config
        self.metrics = PerformanceMetrics(config.performance_window)
        self.batch_sizer = DynamicBatchSizer(config, self.metrics)
        self.backpressure = BackpressureController(config)
        self.worker_pool = WorkerPool(config)

        # í ê´€ë¦¬
        self.task_queue = asyncio.PriorityQueue(maxsize=config.max_queue_size)
        self.result_queue = asyncio.Queue()
        self.batch_queue = asyncio.Queue()

        # ìƒíƒœ ê´€ë¦¬
        self.is_running = False
        self.tasks_in_progress = weakref.WeakSet()
        self.completed_tasks = 0
        self.failed_tasks = 0

        # ë°°ì¹˜ ê´€ë¦¬
        self.current_batch = []
        self.batch_timer = None
        self.batch_lock = asyncio.Lock()

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.start()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.stop()

    async def start(self):
        """ë°°ì¹˜ ì²˜ë¦¬ê¸° ì‹œì‘"""
        logger.info("ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸° ì‹œì‘")

        self.is_running = True

        # ì›Œì»¤ ì‹œì‘
        await self.worker_pool.start_workers(self._worker_process)

        # ë°°ì¹˜ ê´€ë¦¬ì ì‹œì‘
        asyncio.create_task(self._batch_manager())

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì‹œì‘
        asyncio.create_task(self._metrics_collector())

    async def stop(self):
        """ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ"""
        logger.info("ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ")

        self.is_running = False

        # ë‚¨ì€ ì‘ì—… ì²˜ë¦¬
        await self._process_remaining_tasks()

        # ì›Œì»¤ ì¢…ë£Œ
        await self.worker_pool.stop_workers()

        # í†µê³„ ì¶œë ¥
        self._print_final_stats()

    async def submit_task(self, data: T, processor: Callable[[T], R],
                         priority: TaskPriority = TaskPriority.NORMAL,
                         timeout: float = None) -> str:
        """ì‘ì—… ì œì¶œ"""
        # ë°±í”„ë ˆì…” í™•ì¸
        queue_size = self.task_queue.qsize()
        processing_rate = self.metrics.get_avg_throughput()

        if self.backpressure.check_backpressure(queue_size, processing_rate):
            delay = self.backpressure.get_backpressure_delay()
            if delay > 0:
                await asyncio.sleep(delay)

        # ì‘ì—… ìƒì„±
        task = BatchTask(
            id=str(uuid.uuid4()),
            data=data,
            processor=processor,
            priority=priority,
            timeout=timeout or self.config.processing_timeout
        )

        # íì— ì¶”ê°€
        try:
            await self.task_queue.put(task)
            return task.id
        except asyncio.QueueFull:
            raise Exception("ì‘ì—… íê°€ ê°€ë“ ì°¸")

    async def submit_batch(self, batch_data: List[T], processor: Callable[[List[T]], List[R]],
                          priority: TaskPriority = TaskPriority.NORMAL) -> List[str]:
        """ë°°ì¹˜ ì‘ì—… ì œì¶œ"""
        task_ids = []

        for data in batch_data:
            task_id = await self.submit_task(data, processor, priority)
            task_ids.append(task_id)

        return task_ids

    async def get_result(self, task_id: str, timeout: float = None) -> R:
        """ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
        timeout = timeout or self.config.processing_timeout

        try:
            # ê²°ê³¼ íì—ì„œ ëŒ€ê¸°
            start_time = time.time()
            while time.time() - start_time < timeout:
                try:
                    result = await asyncio.wait_for(
                        self.result_queue.get(),
                        timeout=min(1.0, timeout - (time.time() - start_time))
                    )

                    if result['task_id'] == task_id:
                        if result['status'] == TaskStatus.COMPLETED:
                            return result['result']
                        else:
                            raise Exception(f"ì‘ì—… ì‹¤íŒ¨: {result['error']}")
                    else:
                        # ë‹¤ë¥¸ ì‘ì—…ì˜ ê²°ê³¼ë©´ ë‹¤ì‹œ íì— ë„£ê¸°
                        await self.result_queue.put(result)

                except asyncio.TimeoutError:
                    continue

            raise asyncio.TimeoutError(f"ì‘ì—… {task_id} íƒ€ì„ì•„ì›ƒ")

        except Exception as e:
            logger.error(f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    async def _batch_manager(self):
        """ë°°ì¹˜ ê´€ë¦¬ì"""
        while self.is_running:
            try:
                # ë°°ì¹˜ í¬ê¸° ì¡°ì •
                target_batch_size = self.batch_sizer.adjust_batch_size()

                # ë°°ì¹˜ ìˆ˜ì§‘
                batch = await self._collect_batch(target_batch_size)

                if batch:
                    await self.batch_queue.put(batch)

                await asyncio.sleep(0.1)

            except Exception as e:
                logger.error(f"ë°°ì¹˜ ê´€ë¦¬ì ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1)

    async def _collect_batch(self, target_size: int) -> List[BatchTask]:
        """ë°°ì¹˜ ìˆ˜ì§‘"""
        batch = []
        batch_timeout = self.config.batch_timeout
        start_time = time.time()

        while (len(batch) < target_size and:
               time.time() - start_time < batch_timeout and:
               self.is_running):

            try:
                task = await asyncio.wait_for(
                    self.task_queue.get(),
                    timeout=min(0.1, batch_timeout - (time.time() - start_time))
                )
                batch.append(task)

            except asyncio.TimeoutError:
                break

        return batch

    async def _worker_process(self, worker_id: str):
        """ì›Œì»¤ ì²˜ë¦¬ í•¨ìˆ˜"""
        try:
            # ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
            batch = await asyncio.wait_for(self.batch_queue.get(), timeout=1.0)

            if batch:
                await self._process_batch(batch, worker_id)

        except asyncio.TimeoutError:
            pass
        except Exception as e:
            logger.error(f"ì›Œì»¤ {worker_id} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    async def _process_batch(self, batch: List[BatchTask], worker_id: str):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        start_time = time.time()

        try:
            # ë°°ì¹˜ë³„ ì²˜ë¦¬
            for task in batch:
                task.status = TaskStatus.RUNNING
                task.started_at = time.time()

                try:
                    # ì‘ì—… ì²˜ë¦¬
                    if asyncio.iscoroutinefunction(task.processor):
                        result = await task.processor(task.data)
                    else:
                        result = task.processor(task.data)

                    # ê²°ê³¼ ì €ì¥
                    task.result = result
                    task.status = TaskStatus.COMPLETED
                    task.completed_at = time.time()

                    # ê²°ê³¼ íì— ì¶”ê°€
                    await self.result_queue.put({
                        'task_id': task.id,
                        'status': task.status,
                        'result': result,
                        'error': None
                    })

                    self.completed_tasks += 1

                except Exception as e:
                    # ì˜¤ë¥˜ ì²˜ë¦¬
                    task.error = e
                    task.status = TaskStatus.FAILED
                    task.completed_at = time.time()

                    # ì¬ì‹œë„ ë¡œì§
                    if task.retry_count < task.max_retries:
                        task.retry_count += 1
                        task.status = TaskStatus.PENDING
                        await self.task_queue.put(task)
                        logger.warning(f"ì‘ì—… ì¬ì‹œë„: {task.id} ({task.retry_count}/{task.max_retries})")
                    else:
                        await self.result_queue.put({
                            'task_id': task.id,
                            'status': task.status,
                            'result': None,
                            'error': str(e)
                        })
                        self.failed_tasks += 1
                        logger.error(f"ì‘ì—… ì‹¤íŒ¨: {task.id} - {e}")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            processing_time = time.time() - start_time
            self.metrics.record_processing_time(processing_time)

            # ì›Œì»¤ í†µê³„ ì—…ë°ì´íŠ¸
            self.worker_pool.worker_stats[worker_id]['processed'] += len(batch)
            self.worker_pool.worker_stats[worker_id]['avg_time'] = processing_time / len(batch)

        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            for task in batch:
                if task.status == TaskStatus.RUNNING:
                    task.status = TaskStatus.FAILED
                    task.error = e
                    self.failed_tasks += 1

    async def _metrics_collector(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
        while self.is_running:
            try:
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                self.metrics.record_system_metrics()
                self.metrics.record_queue_size(self.task_queue.qsize())

                # ì²˜ë¦¬ëŸ‰ ê³„ì‚°
                current_time = time.time()
                if hasattr(self, '_last_metrics_time'):
                    time_diff = current_time - self._last_metrics_time
                    if time_diff > 0:
                        completed_diff = self.completed_tasks - getattr(self, '_last_completed', 0)
                        throughput = completed_diff / time_diff
                        self.metrics.record_throughput(throughput)

                self._last_metrics_time = current_time
                self._last_completed = self.completed_tasks

                await asyncio.sleep(5)  # 5ì´ˆë§ˆë‹¤ ìˆ˜ì§‘

            except Exception as e:
                logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1)

    async def _process_remaining_tasks(self):
        """ë‚¨ì€ ì‘ì—… ì²˜ë¦¬"""
        logger.info("ë‚¨ì€ ì‘ì—… ì²˜ë¦¬ ì¤‘...")

        timeout = 30.0  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        start_time = time.time()

        while (not self.task_queue.empty() and :
               time.time() - start_time < timeout):
            await asyncio.sleep(0.1)

        if not self.task_queue.empty():
            logger.warning(f"íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•´ {self.task_queue.qsize()}ê°œ ì‘ì—… ë¯¸ì²˜ë¦¬")

    def _print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        total_tasks = self.completed_tasks + self.failed_tasks
        success_rate = self.completed_tasks / total_tasks if total_tasks > 0 else 0

        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ í†µê³„:")
        logger.info(f"  ì´ ì‘ì—…: {total_tasks}")
        logger.info(f"  ì„±ê³µ: {self.completed_tasks}")
        logger.info(f"  ì‹¤íŒ¨: {self.failed_tasks}")
        logger.info(f"  ì„±ê³µë¥ : {success_rate:.2%}")
        logger.info(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {self.metrics.get_avg_processing_time():.3f}ì´ˆ")
        logger.info(f"  í‰ê·  ì²˜ë¦¬ëŸ‰: {self.metrics.get_avg_throughput():.2f}ê°œ/ì´ˆ")

        # ì›Œì»¤ í†µê³„
        worker_stats = self.worker_pool.get_worker_stats()
        for worker_id, stats in worker_stats.items():
            logger.info(f"  {worker_id}: {stats['processed']}ê°œ ì²˜ë¦¬, í‰ê·  {stats['avg_time']:.3f}ì´ˆ")

    def get_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return {
            'is_running': self.is_running,
            'queue_size': self.task_queue.qsize(),
            'batch_queue_size': self.batch_queue.qsize(),
            'completed_tasks': self.completed_tasks,
            'failed_tasks': self.failed_tasks,
            'current_batch_size': self.batch_sizer.current_batch_size,
            'backpressure_active': self.backpressure.backpressure_active,
            'avg_processing_time': self.metrics.get_avg_processing_time(),
            'avg_throughput': self.metrics.get_avg_throughput(),
            'system_load': self.metrics.get_system_load(),
            'worker_stats': self.worker_pool.get_worker_stats(),
        }

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ë°°ì¹˜ ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸"""
    try:
        # ì„¤ì •
        config = BatchConfig(
            batch_size=50,
            max_batch_size=200,
            max_workers=8,
            enable_dynamic_sizing=True,
        )

        # í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
        def process_data(data: Dict[str, Any]) -> Dict[str, Any]:
            """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬"""
            time.sleep(0.1)  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            return {
                'id': data['id'],
                'result': data['value'] * 2,
                'processed_at': time.time()
            }

        # ë°°ì¹˜ ì²˜ë¦¬ê¸° ì‹œì‘
        async with AsyncBatchProcessor(config) as processor:

            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            test_data = [
                {'id': i, 'value': i * 10}
                for i in range(1000):
            ]:
            :
            logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì œì¶œ: {len(test_data)}ê°œ")

            # ì‘ì—… ì œì¶œ
            task_ids = []
            for data in test_data:
                task_id = await processor.submit_task(
                    data,
                    process_data,
                    priority=TaskPriority.NORMAL
                )
                task_ids.append(task_id)

            # ê²°ê³¼ ìˆ˜ì§‘
            results = []
            for task_id in task_ids:
                try:
                    result = await processor.get_result(task_id, timeout=30.0)
                    results.append(result)
                except Exception as e:
                    logger.error(f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")

            logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")

            # ìƒíƒœ í™•ì¸
            status = processor.get_status()
            logger.info(f"ìµœì¢… ìƒíƒœ: {status}")

    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
