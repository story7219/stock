```python
"""
ğŸš€ ìƒì„¸ GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
=====================================

NVIDIA RTX 5080 ìƒì„¸ ì„±ëŠ¥ ë¶„ì„
- GPU ì •ë³´ ìƒì„¸ ë¶„ì„
- PyTorch GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- cuPy GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
"""

import sys
import time
import numpy as np
import pandas as pd
from datetime import datetime

def test_gpu_info_detailed():
    """GPU ì •ë³´ ìƒì„¸ ë¶„ì„"""
    print("ğŸ” GPU ì •ë³´ ìƒì„¸ ë¶„ì„")
    print("=" * 50)
    
    try:
        import torch
        print(f"âœ… PyTorch ë²„ì „: {torch.__version__}")
        print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"âœ… CUDA ë²„ì „: {torch.version.cuda}")
            print(f"âœ… cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
            print(f"âœ… GPU ê°œìˆ˜: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                print(f"\nğŸ® GPU {i} ìƒì„¸ ì •ë³´:")
                print(f"   â€¢ ì´ë¦„: {torch.cuda.get_device_name(i)}")
                print(f"   â€¢ ë©”ëª¨ë¦¬ ì´ëŸ‰: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.1f}GB")
                print(f"   â€¢ ë©€í‹°í”„ë¡œì„¸ì„œ ìˆ˜: {torch.cuda.get_device_properties(i).multi_processor_count}")
                print(f"   â€¢ CUDA Capability: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}")
                
                # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                memory_allocated = torch.cuda.memory_allocated(i) / (1024**3)
                memory_reserved = torch.cuda.memory_reserved(i) / (1024**3)
                print(f"   â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_allocated:.3f}GB")
                print(f"   â€¢ ë©”ëª¨ë¦¬ ì˜ˆì•½: {memory_reserved:.3f}GB")
                
        else:
            print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥")
            
    except ImportError as e:
        print(f"âŒ PyTorch ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        return False
    
    # ... (ë‚˜ë¨¸ì§€ ì½”ë“œ)

```
