```python
"""
🚀 상세 GPU 성능 테스트
=====================================

NVIDIA RTX 5080 상세 성능 분석
- GPU 정보 상세 분석
- PyTorch GPU 성능 테스트
- cuPy GPU 성능 테스트
- 메모리 사용량 분석
- 성능 벤치마크
"""

import sys
import time
import numpy as np
import pandas as pd
from datetime import datetime

def test_gpu_info_detailed():
    """GPU 정보 상세 분석"""
    print("🔍 GPU 정보 상세 분석")
    print("=" * 50)
    
    try:
        import torch
        print(f"✅ PyTorch 버전: {torch.__version__}")
        print(f"✅ CUDA 사용 가능: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"✅ CUDA 버전: {torch.version.cuda}")
            print(f"✅ cuDNN 버전: {torch.backends.cudnn.version()}")
            print(f"✅ GPU 개수: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                print(f"\n🎮 GPU {i} 상세 정보:")
                print(f"   • 이름: {torch.cuda.get_device_name(i)}")
                print(f"   • 메모리 총량: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.1f}GB")
                print(f"   • 멀티프로세서 수: {torch.cuda.get_device_properties(i).multi_processor_count}")
                print(f"   • CUDA Capability: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}")
                
                # 현재 메모리 사용량
                memory_allocated = torch.cuda.memory_allocated(i) / (1024**3)
                memory_reserved = torch.cuda.memory_reserved(i) / (1024**3)
                print(f"   • 메모리 사용: {memory_allocated:.3f}GB")
                print(f"   • 메모리 예약: {memory_reserved:.3f}GB")
                
        else:
            print("❌ CUDA 사용 불가능")
            
    except ImportError as e:
        print(f"❌ PyTorch 설치 실패: {e}")
        return False
    
    # ... (나머지 코드)

```
