#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸ§ª Gemini AI 100% ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸
ìµœê³  ì„±ëŠ¥ ê²€ì¦ ë° ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ
"""

import asyncio
import json
import time
import logging
from typing import Dict, List, Any
from datetime import datetime
import statistics

from gemini_optimizer import GeminiOptimizer, OptimizationConfig
from ultra_ai_analyzer import UltraAIAnalyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiPerformanceTest:
    """ì œë¯¸ë‚˜ì´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = []
        self.performance_metrics = {
            'response_times': [],
            'success_count': 0,
            'error_count': 0,
            'cache_hits': 0,
            'total_tokens': 0
        }
        
        # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°
        self.sample_stocks = [
            {
                'symbol': '005930', 'name': 'ì‚¼ì„±ì „ìž', 'price': 75000,
                'market_cap': 450000000000000, 'pe_ratio': 15.5, 'pb_ratio': 1.2,
                'roe': 12.5, 'debt_ratio': 15.2, 'dividend_yield': 2.1,
                'revenue_growth': 8.5, 'profit_growth': 12.3, 'sector': 'ê¸°ìˆ '
            },
            {
                'symbol': '000660', 'name': 'SKí•˜ì´ë‹‰ìŠ¤', 'price': 125000,
                'market_cap': 90000000000000, 'pe_ratio': 22.1, 'pb_ratio': 1.8,
                'roe': 8.7, 'debt_ratio': 25.4, 'dividend_yield': 1.5,
                'revenue_growth': 15.2, 'profit_growth': 25.8, 'sector': 'ë°˜ë„ì²´'
            },
            {
                'symbol': '035420', 'name': 'NAVER', 'price': 180000,
                'market_cap': 30000000000000, 'pe_ratio': 28.5, 'pb_ratio': 2.1,
                'roe': 15.2, 'debt_ratio': 8.9, 'dividend_yield': 0.8,
                'revenue_growth': 22.1, 'profit_growth': 18.7, 'sector': 'ì¸í„°ë„·'
            },
            {
                'symbol': '207940', 'name': 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'price': 850000,
                'market_cap': 60000000000000, 'pe_ratio': 45.2, 'pb_ratio': 3.5,
                'roe': 18.9, 'debt_ratio': 12.1, 'dividend_yield': 0.0,
                'revenue_growth': 35.8, 'profit_growth': 42.1, 'sector': 'ë°”ì´ì˜¤'
            },
            {
                'symbol': '051910', 'name': 'LGí™”í•™', 'price': 420000,
                'market_cap': 30000000000000, 'pe_ratio': 18.7, 'pb_ratio': 1.4,
                'roe': 9.8, 'debt_ratio': 32.1, 'dividend_yield': 1.2,
                'revenue_growth': 12.5, 'profit_growth': 8.9, 'sector': 'í™”í•™'
            }
        ]
    
    async def test_individual_analysis(self) -> Dict[str, Any]:
        """ê°œë³„ ì¢…ëª© ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        logger.info("ðŸ§ª ê°œë³„ ì¢…ëª© ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        optimizer = GeminiOptimizer()
        test_stock = self.sample_stocks[0]  # ì‚¼ì„±ì „ìž
        
        start_time = time.time()
        
        try:
            result = await optimizer.ultra_analyze_stock(test_stock)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            self.performance_metrics['response_times'].append(response_time)
            self.performance_metrics['success_count'] += 1
            
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ê°œë³„_ì¢…ëª©_ë¶„ì„",
                "ì¢…ëª©": f"{test_stock['name']} ({test_stock['symbol']})",
                "ì‘ë‹µì‹œê°„": f"{response_time:.3f}ì´ˆ",
                "ìƒíƒœ": "âœ… ì„±ê³µ",
                "AIë“±ê¸‰": result.get('ultra_grade', 'N/A'),
                "AIì ìˆ˜": result.get('ai_score', 'N/A'),
                "íˆ¬ìžì˜ê²¬": result.get('investment_opinion', 'N/A'),
                "ì‹ ë¢°ë„": result.get('confidence_level', 'N/A')
            }
            
        except Exception as e:
            self.performance_metrics['error_count'] += 1
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ê°œë³„_ì¢…ëª©_ë¶„ì„",
                "ìƒíƒœ": f"âŒ ì‹¤íŒ¨: {str(e)}",
                "ì‘ë‹µì‹œê°„": f"{time.time() - start_time:.3f}ì´ˆ"
            }
        
        self.test_results.append(test_result)
        return test_result
    
    async def test_ultra_analyzer(self) -> Dict[str, Any]:
        """ìš¸íŠ¸ë¼ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
        logger.info("ðŸ§ª ìš¸íŠ¸ë¼ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        analyzer = UltraAIAnalyzer()
        symbols = [stock['symbol'] for stock in self.sample_stocks[:3]]
        
        start_time = time.time()
        
        try:
            results = await analyzer.analyze_stocks(
                symbols=symbols,
                strategy='comprehensive'
            )
            
            end_time = time.time()
            total_time = end_time - start_time
            avg_time = total_time / len(symbols)
            
            self.performance_metrics['response_times'].extend([avg_time] * len(symbols))
            self.performance_metrics['success_count'] += len(results)
            
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ìš¸íŠ¸ë¼_ë¶„ì„ê¸°",
                "ì¢…ëª©ìˆ˜": len(symbols),
                "ì´_ì‹œê°„": f"{total_time:.3f}ì´ˆ",
                "í‰ê· _ì‹œê°„": f"{avg_time:.3f}ì´ˆ",
                "ìƒíƒœ": "âœ… ì„±ê³µ",
                "ì²˜ë¦¬ëœ_ì¢…ëª©": len(results),
                "ì„±ê³µë¥ ": f"{len(results)/len(symbols)*100:.1f}%"
            }
            
        except Exception as e:
            self.performance_metrics['error_count'] += len(symbols)
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ìš¸íŠ¸ë¼_ë¶„ì„ê¸°",
                "ìƒíƒœ": f"âŒ ì‹¤íŒ¨: {str(e)}",
                "ì´_ì‹œê°„": f"{time.time() - start_time:.3f}ì´ˆ"
            }
        
        self.test_results.append(test_result)
        return test_result
    
    async def test_concurrent_processing(self) -> Dict[str, Any]:
        """ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("ðŸ§ª ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        optimizer = GeminiOptimizer()
        
        # ë™ì‹œ ì²˜ë¦¬ íƒœìŠ¤í¬ ìƒì„±
        tasks = [
            optimizer.ultra_analyze_stock(stock)
            for stock in self.sample_stocks
        ]
        
        start_time = time.time()
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ë¥˜
            successful_results = [r for r in results if not isinstance(r, Exception)]
            failed_results = [r for r in results if isinstance(r, Exception)]
            
            self.performance_metrics['success_count'] += len(successful_results)
            self.performance_metrics['error_count'] += len(failed_results)
            
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ë™ì‹œ_ì²˜ë¦¬_ì„±ëŠ¥",
                "ë™ì‹œ_ì²˜ë¦¬ìˆ˜": len(tasks),
                "ì´_ì‹œê°„": f"{total_time:.3f}ì´ˆ",
                "í‰ê· _ì‹œê°„": f"{total_time/len(tasks):.3f}ì´ˆ",
                "ì„±ê³µ": len(successful_results),
                "ì‹¤íŒ¨": len(failed_results),
                "ì„±ê³µë¥ ": f"{len(successful_results)/len(tasks)*100:.1f}%",
                "ìƒíƒœ": "âœ… ì„±ê³µ" if len(successful_results) > 0 else "âŒ ì‹¤íŒ¨",
                "ì²˜ë¦¬ëŸ‰": f"{len(tasks)/total_time:.2f} ì¢…ëª©/ì´ˆ"
            }
            
        except Exception as e:
            test_result = {
                "í…ŒìŠ¤íŠ¸": "ë™ì‹œ_ì²˜ë¦¬_ì„±ëŠ¥",
                "ìƒíƒœ": f"âŒ ì‹¤íŒ¨: {str(e)}",
                "ì´_ì‹œê°„": f"{time.time() - start_time:.3f}ì´ˆ"
            }
        
        self.test_results.append(test_result)
        return test_result
    
    async def test_cache_performance(self) -> Dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("ðŸ§ª ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        optimizer = GeminiOptimizer()
        test_stock = self.sample_stocks[0]
        
        # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        start_time1 = time.time()
        result1 = await optimizer.ultra_analyze_stock(test_stock)
        time1 = time.time() - start_time1
        
        # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ížˆíŠ¸)
        start_time2 = time.time()
        result2 = await optimizer.ultra_analyze_stock(test_stock)
        time2 = time.time() - start_time2
        
        cache_speedup = time1 / time2 if time2 > 0 else float('inf')
        
        test_result = {
            "í…ŒìŠ¤íŠ¸": "ìºì‹œ_ì„±ëŠ¥",
            "ì²«ë²ˆì§¸_ìš”ì²­": f"{time1:.3f}ì´ˆ (ìºì‹œ ë¯¸ìŠ¤)",
            "ë‘ë²ˆì§¸_ìš”ì²­": f"{time2:.3f}ì´ˆ (ìºì‹œ ížˆíŠ¸)",
            "ì†ë„_í–¥ìƒ": f"{cache_speedup:.1f}ë°°",
            "ìºì‹œ_íš¨ìœ¨ì„±": "âœ… ìš°ìˆ˜" if cache_speedup > 5 else "âš ï¸ ë³´í†µ",
            "ìƒíƒœ": "âœ… ì„±ê³µ"
        }
        
        if cache_speedup > 5:
            self.performance_metrics['cache_hits'] += 1
        
        self.test_results.append(test_result)
        return test_result
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ðŸš€ ì œë¯¸ë‚˜ì´ AI 100% ì„±ëŠ¥ ìµœì í™” ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œìž‘!")
        
        overall_start = time.time()
        
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_functions = [
            self.test_individual_analysis,
            self.test_ultra_analyzer,
            self.test_concurrent_processing,
            self.test_cache_performance
        ]
        
        for test_func in test_functions:
            try:
                await test_func()
                await asyncio.sleep(0.1)  # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
            except Exception as e:
                logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_func.__name__} - {e}")
        
        overall_time = time.time() - overall_start
        
        # ì¢…í•© ì„±ëŠ¥ ë¶„ì„
        total_requests = self.performance_metrics['success_count'] + self.performance_metrics['error_count']
        avg_response_time = statistics.mean(self.performance_metrics['response_times']) if self.performance_metrics['response_times'] else 0
        success_rate = (self.performance_metrics['success_count'] / total_requests * 100) if total_requests > 0 else 0
        
        comprehensive_result = {
            "ðŸš€ ì œë¯¸ë‚˜ì´ AI 100% ìµœì í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼": {
                "ì „ì²´_í…ŒìŠ¤íŠ¸_ì‹œê°„": f"{overall_time:.3f}ì´ˆ",
                "ì´_ìš”ì²­ìˆ˜": total_requests,
                "ì„±ê³µë¥ ": f"{success_rate:.1f}%",
                "í‰ê· _ì‘ë‹µì‹œê°„": f"{avg_response_time:.3f}ì´ˆ",
                "ìºì‹œ_ížˆíŠ¸ìˆ˜": self.performance_metrics['cache_hits'],
                "ì„±ëŠ¥_ë“±ê¸‰": self._calculate_performance_grade(success_rate, avg_response_time),
                "ìµœì í™”_ìƒíƒœ": "ðŸŸ¢ ìµœê³  ì„±ëŠ¥" if success_rate > 90 and avg_response_time < 5 else "ðŸŸ¡ ì–‘í˜¸",
                "ê°œë³„_í…ŒìŠ¤íŠ¸_ê²°ê³¼": self.test_results
            }
        }
        
        return comprehensive_result
    
    def _calculate_performance_grade(self, success_rate: float, avg_time: float) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        if success_rate >= 95 and avg_time <= 2:
            return "ðŸ† SSS+ (ì´ˆì›” ì„±ëŠ¥)"
        elif success_rate >= 90 and avg_time <= 3:
            return "ðŸ¥‡ SS (ìµœê³  ì„±ëŠ¥)"
        elif success_rate >= 85 and avg_time <= 5:
            return "ðŸ¥ˆ S (ìš°ìˆ˜ ì„±ëŠ¥)"
        elif success_rate >= 80 and avg_time <= 8:
            return "ðŸ¥‰ A (ì–‘í˜¸ ì„±ëŠ¥)"
        else:
            return "ðŸ“ˆ ê°œì„  í•„ìš”"

# ì‹¤í–‰ í•¨ìˆ˜ë“¤
async def run_quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = GeminiPerformanceTest()
    result = await tester.test_individual_analysis()
    print("ðŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

async def run_full_test():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = GeminiPerformanceTest()
    result = await tester.run_comprehensive_test()
    
    print("ðŸš€ ì œë¯¸ë‚˜ì´ AI 100% ì„±ëŠ¥ ìµœì í™” ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    print("=" * 60)
    
    return result

def run_sync_test():
    """ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    return asyncio.run(run_full_test())

if __name__ == "__main__":
    print("ðŸ§ª Gemini AI ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    import os
    if not os.getenv('GEMINI_API_KEY'):
        print("âŒ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ðŸ’¡ .env íŒŒì¼ì— GEMINI_API_KEY=your_api_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    else:
        print("âœ… GEMINI_API_KEY í™•ì¸ë¨")
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì„ íƒ
        test_type = input("\ní…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ (1: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸, 2: ì „ì²´ í…ŒìŠ¤íŠ¸): ").strip()
        
        if test_type == "1":
            asyncio.run(run_quick_test())
        else:
            asyncio.run(run_full_test()) 