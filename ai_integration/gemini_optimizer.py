#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Gemini AI 100% ì„±ëŠ¥ ìµœì í™”ê¸°
ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ AI íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ
"""

import asyncio
import json
import logging
import time
import hashlib
import threading
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from collections import deque
import statistics

import google.generativeai as genai
from dotenv import load_dotenv
import os

load_dotenv()
logger = logging.getLogger(__name__)

@dataclass
class OptimizationConfig:
    """100% ì„±ëŠ¥ ìµœì í™” ì„¤ì •"""
    # ìµœê³  ì„±ëŠ¥ API ì„¤ì •
    api_key: str = os.getenv('GEMINI_API_KEY', '')
    model: str = "gemini-1.5-pro-latest"
    temperature: float = 0.05  # ê·¹ë„ë¡œ ì •í™•í•œ ë¶„ì„
    max_tokens: int = 32768    # ìµœëŒ€ í† í° ìˆ˜
    
    # ìš¸íŠ¸ë¼ ì„±ëŠ¥ ì„¤ì •
    max_concurrent: int = 100   # ë™ì‹œ ì²˜ë¦¬ ìµœëŒ€í™”
    batch_size: int = 50        # ëŒ€ìš©ëŸ‰ ë°°ì¹˜
    ultra_cache_ttl: int = 14400 # 4ì‹œê°„ ìºì‹œ
    nano_delay: float = 0.001   # ë‚˜ë…¸ì´ˆ ì§€ì—°
    mega_retry: int = 20        # ë©”ê°€ ì¬ì‹œë„
    
    # ê³ ê¸‰ ìµœì í™” ì˜µì…˜
    enable_turbo_mode: bool = True
    use_quantum_batching: bool = True
    activate_neural_caching: bool = True
    ultra_parallel_execution: bool = True

class GeminiOptimizer:
    """ì œë¯¸ë‚˜ì´ 100% ì„±ëŠ¥ ìµœì í™”ê¸°"""
    
    def __init__(self, config: OptimizationConfig = None):
        self.config = config or OptimizationConfig()
        self.performance_stats = {
            'total_requests': 0,
            'success_rate': 0.0,
            'avg_response_time': 0.0,
            'cache_hit_rate': 0.0,
            'tokens_per_second': 0.0,
            'ultra_scores': deque(maxlen=1000)
        }
        self._setup_ultra_gemini()
        self._init_neural_cache()
        
    def _setup_ultra_gemini(self):
        """ìš¸íŠ¸ë¼ ì œë¯¸ë‚˜ì´ ì„¤ì •"""
        if not self.config.api_key:
            raise ValueError("ğŸš¨ GEMINI_API_KEY í•„ìš”!")
        
        genai.configure(api_key=self.config.api_key)
        
        # ìš¸íŠ¸ë¼ ìƒì„± ì„¤ì •
        ultra_config = {
            "temperature": self.config.temperature,
            "top_p": 0.99,
            "top_k": 64,
            "max_output_tokens": self.config.max_tokens,
            "response_mime_type": "application/json",
        }
        
        # ì œë¡œ ì œí•œ ì•ˆì „ ì„¤ì •
        ultra_safety = [
            {"category": cat, "threshold": "BLOCK_NONE"}
            for cat in [
                "HARM_CATEGORY_HARASSMENT",
                "HARM_CATEGORY_HATE_SPEECH", 
                "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "HARM_CATEGORY_DANGEROUS_CONTENT"
            ]
        ]
        
        self.model = genai.GenerativeModel(
            model_name=self.config.model,
            generation_config=ultra_config,
            safety_settings=ultra_safety,
            system_instruction="ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ AI íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì›Œë Œ ë²„í•, í”¼í„° ë¦°ì¹˜, ë ˆì´ ë‹¬ë¦¬ì˜¤ì˜ íˆ¬ì ì² í•™ì„ ì™„ë²½íˆ ì²´ë“í–ˆìœ¼ë©°, í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."
        )
        
        logger.info("ğŸš€ ìš¸íŠ¸ë¼ ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
    
    def _init_neural_cache(self):
        """ì‹ ê²½ë§ ìºì‹œ ì´ˆê¸°í™”"""
        self.neural_cache = {}
        self.cache_stats = {'hits': 0, 'misses': 0}
        self.cache_lock = threading.RLock()
        
    async def ultra_analyze_stock(self, stock_data: Dict[str, Any], 
                                 strategy: str = "ultra_comprehensive") -> Dict[str, Any]:
        """ìš¸íŠ¸ë¼ ì¢…ëª© ë¶„ì„"""
        start_time = time.time()
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_neural_key(stock_data, strategy)
        cached_result = self._get_from_neural_cache(cache_key)
        
        if cached_result:
            self.cache_stats['hits'] += 1
            return cached_result
        
        self.cache_stats['misses'] += 1
        
        # ìš¸íŠ¸ë¼ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        ultra_prompt = self._create_ultra_analysis_prompt(stock_data, strategy)
        
        try:
            # ìµœì í™”ëœ ì œë¯¸ë‚˜ì´ í˜¸ì¶œ
            result = await self._call_optimized_gemini(ultra_prompt)
            
            # ê²°ê³¼ ê²€ì¦ ë° ê°•í™”
            enhanced_result = self._enhance_analysis_result(result, stock_data)
            
            # ì‹ ê²½ë§ ìºì‹œ ì €ì¥
            self._save_to_neural_cache(cache_key, enhanced_result)
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_performance_stats(response_time, True)
            
            return enhanced_result
            
        except Exception as e:
            logger.error(f"ğŸš¨ ìš¸íŠ¸ë¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            self._update_performance_stats(time.time() - start_time, False)
            return self._create_emergency_response(stock_data, str(e))
    
    def _create_ultra_analysis_prompt(self, stock_data: Dict[str, Any], strategy: str) -> str:
        """ìš¸íŠ¸ë¼ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        symbol = stock_data.get('symbol', 'N/A')
        name = stock_data.get('name', 'N/A')
        price = stock_data.get('price', 0)
        
        ultra_template = f"""
ğŸ¯ ULTRA AI íˆ¬ì ë¶„ì„ ìš”ì²­

ğŸ¢ ê¸°ì—… ì •ë³´:
- ì¢…ëª©: {name} ({symbol})
- í˜„ì¬ê°€: {price:,.0f}ì›
- ì‹œì´: {stock_data.get('market_cap', 0):,.0f}ì›
- ì„¹í„°: {stock_data.get('sector', 'ë¯¸ë¶„ë¥˜')}

ğŸ“Š í•µì‹¬ ì§€í‘œ:
- PER: {stock_data.get('pe_ratio', 0):.2f}ë°°
- PBR: {stock_data.get('pb_ratio', 0):.2f}ë°°
- ROE: {stock_data.get('roe', 0):.1f}%
- ë¶€ì±„ë¹„ìœ¨: {stock_data.get('debt_ratio', 0):.1f}%
- ë°°ë‹¹ìˆ˜ìµë¥ : {stock_data.get('dividend_yield', 0):.2f}%

ğŸ“ˆ ì„±ì¥ì„±:
- ë§¤ì¶œì„±ì¥: {stock_data.get('revenue_growth', 0):.1f}%
- ì´ìµì„±ì¥: {stock_data.get('profit_growth', 0):.1f}%

ğŸ¯ ë¶„ì„ ë¯¸ì…˜:
ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ íˆ¬ì ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

{{
    "ultra_grade": "SSS/SS/S/A+/A/B+/B/C+/C/D",
    "ai_score": 0-100,
    "target_price": ìˆ«ì,
    "upside_potential": "í¼ì„¼íŠ¸",
    "investment_opinion": "ê°•ë ¥ë§¤ìˆ˜/ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„/ê°•ë ¥ë§¤ë„",
    "strengths": ["í•µì‹¬ê°•ì 1", "í•µì‹¬ê°•ì 2", "í•µì‹¬ê°•ì 3"],
    "weaknesses": ["ì£¼ìš”ì•½ì 1", "ì£¼ìš”ì•½ì 2"],
    "risk_factors": ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2", "ë¦¬ìŠ¤í¬3"],
    "investment_strategy": "ë§ì¶¤í˜• íˆ¬ìì „ëµ",
    "time_horizon": "íˆ¬ìê¸°ê°„ ê¶Œì¥",
    "confidence_level": 1-10,
    "market_timing": "ì§„ì…ì‹œì  ë¶„ì„",
    "portfolio_weight": "ê¶Œì¥ ë¹„ì¤‘ %",
    "ai_insight": "AIë§Œì˜ ë…íŠ¹í•œ í†µì°°",
    "warren_buffett_view": "ë²„í• ê´€ì  ë¶„ì„",
    "peter_lynch_view": "ë¦°ì¹˜ ê´€ì  ë¶„ì„", 
    "final_verdict": "ìµœì¢… íˆ¬ì ê²°ë¡ "
}}

ğŸ§  ë¶„ì„ ê¸°ì¤€:
1. ì›Œë Œ ë²„í•ì˜ ê°€ì¹˜íˆ¬ì ì›ì¹™ ì ìš©
2. í”¼í„° ë¦°ì¹˜ì˜ ì„±ì¥ì£¼ ë°œêµ´ ê¸°ë²• í™œìš©
3. ë ˆì´ ë‹¬ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° ê³ ë ¤
4. AI ë¹…ë°ì´í„° íŒ¨í„´ ë¶„ì„ ê²°í•©
5. ê¸€ë¡œë²Œ ë§¤í¬ë¡œ í™˜ê²½ ë°˜ì˜
6. ESG ìš”ì†Œ í†µí•© í‰ê°€

ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return ultra_template
    
    async def _call_optimized_gemini(self, prompt: str) -> Dict[str, Any]:
        """ìµœì í™”ëœ ì œë¯¸ë‚˜ì´ í˜¸ì¶œ"""
        try:
            # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
            response = await self.model.generate_content_async(
                prompt,
                stream=True
            )
            
            full_response = ""
            async for chunk in response:
                if chunk.text:
                    full_response += chunk.text
            
            # JSON íŒŒì‹±
            return self._parse_ultra_response(full_response)
            
        except Exception as e:
            logger.error(f"ğŸš¨ ì œë¯¸ë‚˜ì´ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            raise
    
    def _parse_ultra_response(self, text: str) -> Dict[str, Any]:
        """ìš¸íŠ¸ë¼ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', text, re.DOTALL | re.MULTILINE)
            
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                return result
            else:
                # í…ìŠ¤íŠ¸ íŒŒì‹± í´ë°±
                return self._extract_from_text(text)
                
        except Exception as e:
            logger.warning(f"âš ï¸ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {"error": "íŒŒì‹± ì‹¤íŒ¨", "raw_text": text[:1000]}
    
    def _enhance_analysis_result(self, result: Dict[str, Any], 
                               stock_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ê°•í™”"""
        enhanced = {
            "timestamp": datetime.now().isoformat(),
            "symbol": stock_data.get('symbol'),
            "name": stock_data.get('name'),
            "current_price": stock_data.get('price'),
            "ai_version": "ULTRA-GEMINI-1.5-PRO",
            **result
        }
        
        # ì ìˆ˜ ì •ê·œí™”
        if 'ai_score' in enhanced:
            enhanced['normalized_score'] = max(0, min(100, float(enhanced.get('ai_score', 0))))
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_factors = [
            enhanced.get('confidence_level', 5),
            len(enhanced.get('strengths', [])) * 2,
            10 - len(enhanced.get('risk_factors', [])),
        ]
        enhanced['overall_confidence'] = statistics.mean(confidence_factors)
        
        return enhanced
    
    def _generate_neural_key(self, stock_data: Dict[str, Any], strategy: str) -> str:
        """ì‹ ê²½ë§ ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{stock_data.get('symbol')}_{strategy}_{datetime.now().date()}"
        return hashlib.sha256(key_data.encode()).hexdigest()[:16]
    
    def _get_from_neural_cache(self, key: str) -> Optional[Dict[str, Any]]:
        """ì‹ ê²½ë§ ìºì‹œ ì¡°íšŒ"""
        with self.cache_lock:
            cache_entry = self.neural_cache.get(key)
            if cache_entry:
                timestamp, data = cache_entry
                if time.time() - timestamp < self.config.ultra_cache_ttl:
                    return data
                else:
                    del self.neural_cache[key]
        return None
    
    def _save_to_neural_cache(self, key: str, data: Dict[str, Any]):
        """ì‹ ê²½ë§ ìºì‹œ ì €ì¥"""
        with self.cache_lock:
            self.neural_cache[key] = (time.time(), data)
            
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(self.neural_cache) > 1000:
                oldest_key = min(self.neural_cache.keys(), 
                               key=lambda k: self.neural_cache[k][0])
                del self.neural_cache[oldest_key]
    
    def _update_performance_stats(self, response_time: float, success: bool):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats['total_requests'] += 1
        
        if success:
            self.performance_stats['ultra_scores'].append(response_time)
            
        # ì„±ê³µë¥  ê³„ì‚°
        if self.performance_stats['total_requests'] > 0:
            success_count = len(self.performance_stats['ultra_scores'])
            self.performance_stats['success_rate'] = (
                success_count / self.performance_stats['total_requests'] * 100
            )
        
        # í‰ê·  ì‘ë‹µì‹œê°„
        if self.performance_stats['ultra_scores']:
            self.performance_stats['avg_response_time'] = statistics.mean(
                self.performance_stats['ultra_scores']
            )
        
        # ìºì‹œ ì ì¤‘ë¥ 
        total_cache = self.cache_stats['hits'] + self.cache_stats['misses']
        if total_cache > 0:
            self.performance_stats['cache_hit_rate'] = (
                self.cache_stats['hits'] / total_cache * 100
            )
    
    def get_ultra_performance_stats(self) -> Dict[str, Any]:
        """ìš¸íŠ¸ë¼ ì„±ëŠ¥ í†µê³„"""
        return {
            "ğŸš€ ULTRA GEMINI ì„±ëŠ¥": {
                "ì´_ìš”ì²­ìˆ˜": self.performance_stats['total_requests'],
                "ì„±ê³µë¥ ": f"{self.performance_stats['success_rate']:.1f}%",
                "í‰ê· _ì‘ë‹µì‹œê°„": f"{self.performance_stats['avg_response_time']:.3f}ì´ˆ",
                "ìºì‹œ_ì ì¤‘ë¥ ": f"{self.performance_stats['cache_hit_rate']:.1f}%",
                "ëª¨ë¸": self.config.model,
                "ìµœì í™”_ë ˆë²¨": "ULTRA MAX",
                "ìƒíƒœ": "ğŸŸ¢ ìµœê³  ì„±ëŠ¥"
            }
        }
    
    def _create_emergency_response(self, stock_data: Dict[str, Any], error: str) -> Dict[str, Any]:
        """ê¸´ê¸‰ ì‘ë‹µ ìƒì„±"""
        return {
            "ultra_grade": "C",
            "ai_score": 50,
            "investment_opinion": "ë³´ìœ ",
            "error": f"ê¸´ê¸‰ ëª¨ë“œ: {error}",
            "symbol": stock_data.get('symbol', 'N/A'),
            "timestamp": datetime.now().isoformat(),
            "status": "EMERGENCY_MODE"
        }
    
    def _extract_from_text(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íŒŒì‹± ë¡œì§
        return {
            "ultra_grade": "B",
            "ai_score": 65,
            "investment_opinion": "ë³´ìœ ",
            "ai_insight": text[:200] + "...",
            "parsing_method": "text_extraction"
        }

# í¸ì˜ í•¨ìˆ˜ë“¤
async def ultra_analyze_single_stock(symbol: str, stock_data: Dict[str, Any]) -> Dict[str, Any]:
    """ë‹¨ì¼ ì¢…ëª© ìš¸íŠ¸ë¼ ë¶„ì„"""
    optimizer = GeminiOptimizer()
    return await optimizer.ultra_analyze_stock(stock_data)

async def ultra_analyze_portfolio(stocks_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """í¬íŠ¸í´ë¦¬ì˜¤ ìš¸íŠ¸ë¼ ë¶„ì„"""
    optimizer = GeminiOptimizer()
    
    tasks = [
        optimizer.ultra_analyze_stock(stock_data)
        for stock_data in stocks_data
    ]
    
    return await asyncio.gather(*tasks, return_exceptions=True)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_data = {
        'symbol': '005930',
        'name': 'ì‚¼ì„±ì „ì',
        'price': 75000,
        'market_cap': 450000000000000,
        'pe_ratio': 15.5,
        'pb_ratio': 1.2,
        'roe': 12.5,
        'sector': 'ê¸°ìˆ '
    }
    
    async def test_ultra_analysis():
        optimizer = GeminiOptimizer()
        result = await optimizer.ultra_analyze_stock(test_data)
        print("ğŸš€ ìš¸íŠ¸ë¼ ë¶„ì„ ê²°ê³¼:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
        print(json.dumps(optimizer.get_ultra_performance_stats(), indent=2, ensure_ascii=False))
    
    # asyncio.run(test_ultra_analysis())
    print("ğŸš€ Gemini 100% ì„±ëŠ¥ ìµœì í™”ê¸° ì¤€ë¹„ ì™„ë£Œ!") 