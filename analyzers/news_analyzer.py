"""
ê³ ì„±ëŠ¥ ë‰´ìŠ¤ ë¶„ì„ê¸° - Gemini AI ìµœëŒ€ ì„±ëŠ¥ ë°œíœ˜ìš©
"""
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any
import asyncio
import aiohttp
from urllib.parse import quote
import json
from ai_integration.gemini_optimizer import GeminiOptimizer
from ai_integration.test_gemini_optimization import run_full_test
from ai_integration.ultra_ai_analyzer import UltraAIAnalyzer

class NewsAnalyzer:
    """ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¶„ì„ ë° ê°ì • ë¶„ì„"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.sentiment_keywords = {
            'positive': [
                'ìƒìŠ¹', 'ì¦ê°€', 'ì„±ì¥', 'í˜¸ì¬', 'ê¸ì •', 'ê°œì„ ', 'í™•ëŒ€', 'íˆ¬ì', 'ë§¤ìˆ˜', 
                'ì‹¤ì ', 'ìˆ˜ìµ', 'ì´ìµ', 'ë°°ë‹¹', 'ì‹ ê³ ê°€', 'ëŒíŒŒ', 'ê°•ì„¸', 'íšŒë³µ',
                'í˜ì‹ ', 'ê¸°ëŒ€', 'ì „ë§', 'ê³„ì•½', 'ìˆ˜ì£¼', 'ì¶œì‹œ', 'ê°œë°œ', 'íŠ¹í—ˆ'
            ],
            'negative': [
                'í•˜ë½', 'ê°ì†Œ', 'ì•…í™”', 'ì•…ì¬', 'ë¶€ì •', 'ìš°ë ¤', 'ì¶•ì†Œ', 'ë§¤ë„', 
                'ì†ì‹¤', 'ì ì', 'í•˜ë½', 'ì‹ ì €ê°€', 'ì•½ì„¸', 'ì¹¨ì²´', 'ë¦¬ìŠ¤í¬',
                'ê·œì œ', 'ì œì¬', 'ì†Œì†¡', 'ì‚¬ê³ ', 'íŒŒì—…', 'ì¤‘ë‹¨', 'ì—°ê¸°', 'ì·¨ì†Œ'
            ]
        }
    
    async def analyze_stock_news(self, stock_code: str, company_name: str) -> Dict[str, Any]:
        """ì¢…ëª©ë³„ ë‰´ìŠ¤ ë¶„ì„"""
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ í¬ë¡¤ë§
            news_data = await self._crawl_naver_finance_news(stock_code, company_name)
            
            # ê°ì • ë¶„ì„
            sentiment_analysis = self._analyze_sentiment(news_data)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(news_data)
            
            # ë‰´ìŠ¤ ìš”ì•½
            summary = self._create_news_summary(news_data, sentiment_analysis)
            
            # ìš¸íŠ¸ë¼ ìµœì í™”ê¸° ì‚¬ìš©
            optimizer = GeminiOptimizer()
            result = await optimizer.ultra_analyze_stock(stock_data)
            
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            test_results = await run_full_test()
            
            # ê¸°ì¡´ ìš¸íŠ¸ë¼ ë¶„ì„ê¸° (ìµœì í™”ë¨)
            analyzer = UltraAIAnalyzer()
            results = await analyzer.analyze_stocks(symbols, strategy='comprehensive')
            
            return {
                'news_count': len(news_data),
                'sentiment_score': sentiment_analysis['score'],
                'sentiment_label': sentiment_analysis['label'],
                'key_keywords': keywords[:10],
                'summary': summary,
                'latest_news': news_data[:3],  # ìµœì‹  3ê°œ
                'analysis_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'news_count': 0,
                'sentiment_score': 0,
                'sentiment_label': 'ì¤‘ë¦½',
                'key_keywords': [],
                'summary': f'ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                'latest_news': [],
                'analysis_time': datetime.now().isoformat()
            }
    
    async def _crawl_naver_finance_news(self, stock_code: str, company_name: str) -> List[Dict]:
        """ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ í¬ë¡¤ë§"""
        news_list = []
        
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ URL
            url = f"https://finance.naver.com/item/news_news.naver?code={stock_code}&page=1"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.headers) as response:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
                    news_items = soup.select('.tb_cont tr')
                    
                    for item in news_items[:10]:  # ìµœì‹  10ê°œ
                        try:
                            title_elem = item.select_one('.title a')
                            if title_elem:
                                title = title_elem.get_text(strip=True)
                                link = title_elem.get('href')
                                
                                date_elem = item.select_one('.date')
                                date = date_elem.get_text(strip=True) if date_elem else ''
                                
                                source_elem = item.select_one('.info')
                                source = source_elem.get_text(strip=True) if source_elem else ''
                                
                                news_list.append({
                                    'title': title,
                                    'link': f"https://finance.naver.com{link}" if link else '',
                                    'date': date,
                                    'source': source
                                })
                        except:
                            continue
                            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë‰´ìŠ¤ ìƒì„±
            news_list = [
                {
                    'title': f'{company_name} ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„ ì¤‘',
                    'link': '',
                    'date': datetime.now().strftime('%Y.%m.%d'),
                    'source': 'ì¢…í•©'
                }
            ]
        
        return news_list
    
    def _analyze_sentiment(self, news_data: List[Dict]) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„"""
        if not news_data:
            return {'score': 0, 'label': 'ì¤‘ë¦½'}
        
        positive_count = 0
        negative_count = 0
        total_count = len(news_data)
        
        for news in news_data:
            title = news.get('title', '').lower()
            
            # ê¸ì • í‚¤ì›Œë“œ ê²€ì‚¬
            pos_matches = sum(1 for keyword in self.sentiment_keywords['positive'] if keyword in title)
            # ë¶€ì • í‚¤ì›Œë“œ ê²€ì‚¬
            neg_matches = sum(1 for keyword in self.sentiment_keywords['negative'] if keyword in title)
            
            if pos_matches > neg_matches:
                positive_count += 1
            elif neg_matches > pos_matches:
                negative_count += 1
        
        # ê°ì • ì ìˆ˜ ê³„ì‚° (-100 ~ +100)
        if total_count > 0:
            score = ((positive_count - negative_count) / total_count) * 100
        else:
            score = 0
        
        # ë¼ë²¨ ê²°ì •
        if score > 30:
            label = 'ë§¤ìš° ê¸ì •'
        elif score > 10:
            label = 'ê¸ì •'
        elif score > -10:
            label = 'ì¤‘ë¦½'
        elif score > -30:
            label = 'ë¶€ì •'
        else:
            label = 'ë§¤ìš° ë¶€ì •'
        
        return {'score': round(score, 1), 'label': label}
    
    def _extract_keywords(self, news_data: List[Dict]) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join([news.get('title', '') for news in news_data])
        
        # í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ
        korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = {}
        for word in korean_words:
            if len(word) >= 2:  # 2ê¸€ì ì´ìƒë§Œ
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        return [word for word, freq in sorted_words if freq > 1][:20]
    
    def _create_news_summary(self, news_data: List[Dict], sentiment: Dict) -> str:
        """ë‰´ìŠ¤ ìš”ì•½ ìƒì„±"""
        if not news_data:
            return "ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        latest_news = news_data[0] if news_data else {}
        
        summary = f"""
ğŸ“° ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½:
â€¢ ì´ {len(news_data)}ê±´ì˜ ë‰´ìŠ¤ ë¶„ì„
â€¢ ê°ì • ì ìˆ˜: {sentiment['score']}ì  ({sentiment['label']})
â€¢ ìµœì‹  ë‰´ìŠ¤: {latest_news.get('title', 'N/A')}
â€¢ ë¶„ì„ ì‹œì : {datetime.now().strftime('%Y-%m-%d %H:%M')}
        """.strip()
        
        return summary 