#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“ íŒŒì¼ ê´€ë¦¬ ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ v1.0
ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ í”„ë¡œì íŠ¸ íŒŒì¼ ê´€ë¦¬ ë„êµ¬

Features:
- ğŸ” ì „ì²´ íŒŒì¼ ìŠ¤ìº” ë° ë¶„ì„
- ğŸ—‚ï¸ ìë™ íŒŒì¼ ë¶„ë¥˜ ë° ì •ë¦¬
- ğŸ“Š í”„ë¡œì íŠ¸ êµ¬ì¡° ì‹œê°í™”
- ğŸ§¹ ì¤‘ë³µ íŒŒì¼ ì œê±°
- ğŸ“ˆ íŒŒì¼ ì‚¬ìš©ëŸ‰ í†µê³„
- ğŸ”§ ìë™ ë°±ì—… ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import shutil
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, Counter
import logging
from dataclasses import dataclass, asdict
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/file_manager.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

@dataclass
class FileInfo:
    """íŒŒì¼ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    path: str
    name: str
    size: int
    created: str
    modified: str
    extension: str
    category: str
    hash_md5: Optional[str] = None
    is_duplicate: bool = False
    usage_score: int = 0

class FileManager:
    """ğŸ—‚ï¸ íŒŒì¼ ê´€ë¦¬ ë§ˆìŠ¤í„° í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.files_data: Dict[str, FileInfo] = {}
        self.categories = {
            'core': ['app.py', 'launcher.py', 'run_analysis.py'],
            'modules': ['.py'],
            'config': ['.env', '.json', '.yaml', '.yml', '.ini', '.conf'],
            'docs': ['.md', '.txt', '.rst', '.pdf'],
            'scripts': ['.bat', '.sh', '.ps1', 'Makefile'],
            'data': ['.csv', '.xlsx', '.json', '.pickle', '.pkl'],
            'logs': ['.log'],
            'reports': ['.html', '.pdf', '.json'],
            'tests': ['test_', '_test.py', '.pytest'],
            'backup': ['backup_', 'old_', '.bak'],
            'temp': ['.tmp', '.temp', '__pycache__'],
            'media': ['.png', '.jpg', '.jpeg', '.gif', '.svg'],
            'archive': ['.zip', '.tar', '.gz', '.rar']
        }
        
        # í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ì˜
        self.target_structure = {
            'core/': 'í•µì‹¬ ì‹¤í–‰ íŒŒì¼ë“¤',
            'modules/': 'ë¶„ì„ ëª¨ë“ˆë“¤',
            'config/': 'ì„¤ì • íŒŒì¼ë“¤',
            'docs/': 'ë¬¸ì„œ íŒŒì¼ë“¤',
            'scripts/': 'ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤',
            'data/': 'ë°ì´í„° íŒŒì¼ë“¤',
            'logs/': 'ë¡œê·¸ íŒŒì¼ë“¤',
            'reports/': 'ë¦¬í¬íŠ¸ íŒŒì¼ë“¤',
            'tests/': 'í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤',
            'backup_old_files/': 'ë°±ì—… íŒŒì¼ë“¤',
            'src/': 'ê¸°ì¡´ ì†ŒìŠ¤ íŒŒì¼ë“¤'
        }
        
        self._ensure_directories()
    
    def _ensure_directories(self) -> None:
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for directory in self.target_structure.keys():
            dir_path = self.project_root / directory
            if not dir_path.exists():
                dir_path.mkdir(parents=True, exist_ok=True)
                logging.info(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")
    
    def scan_all_files(self, exclude_dirs: List[str] = None) -> None:
        """ğŸ“Š ì „ì²´ íŒŒì¼ ìŠ¤ìº” ë° ë¶„ì„"""
        if exclude_dirs is None:
            exclude_dirs = ['.git', '.venv', '__pycache__', 'node_modules', '.vscode']
        
        print("ğŸ” íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
        start_time = time.time()
        
        for root, dirs, files in os.walk(self.project_root):
            # ì œì™¸í•  ë””ë ‰í† ë¦¬ ê±´ë„ˆë›°ê¸°
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                file_path = Path(root) / file
                try:
                    self._analyze_file(file_path)
                except Exception as e:
                    logging.warning(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path} - {e}")
        
        scan_time = time.time() - start_time
        print(f"âœ… ìŠ¤ìº” ì™„ë£Œ! ({len(self.files_data)}ê°œ íŒŒì¼, {scan_time:.2f}ì´ˆ)")
    
    def _analyze_file(self, file_path: Path) -> None:
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        try:
            stat = file_path.stat()
            
            file_info = FileInfo(
                path=str(file_path.relative_to(self.project_root)),
                name=file_path.name,
                size=stat.st_size,
                created=datetime.fromtimestamp(stat.st_ctime).isoformat(),
                modified=datetime.fromtimestamp(stat.st_mtime).isoformat(),
                extension=file_path.suffix.lower(),
                category=self._categorize_file(file_path),
                usage_score=self._calculate_usage_score(file_path)
            )
            
            # MD5 í•´ì‹œ ê³„ì‚° (ì¤‘ë³µ íŒŒì¼ ê²€ì¶œìš©)
            if stat.st_size < 50 * 1024 * 1024:  # 50MB ë¯¸ë§Œë§Œ
                file_info.hash_md5 = self._calculate_md5(file_path)
            
            self.files_data[str(file_path)] = file_info
            
        except Exception as e:
            logging.error(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {file_path} - {e}")
    
    def _categorize_file(self, file_path: Path) -> str:
        """íŒŒì¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        file_name = file_path.name.lower()
        extension = file_path.suffix.lower()
        
        # íŠ¹ë³„í•œ íŒŒì¼ë“¤ ìš°ì„  ì²´í¬
        if file_name in ['requirements.txt', 'setup.py', 'pyproject.toml', '.gitignore']:
            return 'config'
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŒ¨í„´ ë§¤ì¹­
        for category, patterns in self.categories.items():
            for pattern in patterns:
                if pattern.startswith('.') and extension == pattern:
                    return category
                elif file_name.startswith(pattern) or pattern in file_name:
                    return category
        
        # ë””ë ‰í† ë¦¬ ê¸°ë°˜ ë¶„ë¥˜
        parts = file_path.parts
        for part in parts:
            if part in self.categories:
                return part
        
        return 'misc'
    
    def _calculate_usage_score(self, file_path: Path) -> int:
        """íŒŒì¼ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        file_name = file_path.name.lower()
        
        # í•µì‹¬ íŒŒì¼ë“¤
        if file_name in ['app.py', 'launcher.py', 'main.py']:
            score += 10
        elif file_name == 'requirements.txt':
            score += 9
        elif file_name.endswith('_analyzer.py'):
            score += 8
        elif file_name.endswith('.py'):
            score += 5
        
        # ìµœê·¼ ìˆ˜ì •ëœ íŒŒì¼
        try:
            mtime = file_path.stat().st_mtime
            days_old = (time.time() - mtime) / (24 * 3600)
            if days_old < 1:
                score += 5
            elif days_old < 7:
                score += 3
            elif days_old < 30:
                score += 1
        except:
            pass
        
        return score
    
    def _calculate_md5(self, file_path: Path) -> str:
        """MD5 í•´ì‹œ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return ""
    
    def find_duplicates(self) -> Dict[str, List[str]]:
        """ğŸ” ì¤‘ë³µ íŒŒì¼ ì°¾ê¸°"""
        print("ğŸ” ì¤‘ë³µ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        
        hash_groups = defaultdict(list)
        for file_path, file_info in self.files_data.items():
            if file_info.hash_md5:
                hash_groups[file_info.hash_md5].append(file_path)
        
        duplicates = {h: files for h, files in hash_groups.items() if len(files) > 1}
        
        # ì¤‘ë³µ í”Œë˜ê·¸ ì„¤ì •
        for file_list in duplicates.values():
            for file_path in file_list[1:]:  # ì²« ë²ˆì§¸ ì œì™¸í•˜ê³  ì¤‘ë³µ í‘œì‹œ
                if file_path in self.files_data:
                    self.files_data[file_path].is_duplicate = True
        
        print(f"âœ… ì¤‘ë³µ íŒŒì¼ {len(duplicates)}ê°œ ê·¸ë£¹ ë°œê²¬")
        return duplicates
    
    def auto_organize(self, dry_run: bool = True) -> Dict[str, int]:
        """ğŸ—‚ï¸ ìë™ íŒŒì¼ ì •ë¦¬"""
        print(f"ğŸ—‚ï¸ ìë™ íŒŒì¼ ì •ë¦¬ {'(ì‹œë®¬ë ˆì´ì…˜)' if dry_run else '(ì‹¤í–‰)'}")
        
        moves = defaultdict(int)
        
        for file_path, file_info in self.files_data.items():
            current_path = Path(file_path)
            
            # ì´ë¯¸ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ ì²´í¬
            if self._is_in_correct_location(current_path, file_info.category):
                continue
            
            # ìƒˆ ìœ„ì¹˜ ê²°ì •
            new_location = self._get_target_location(file_info)
            if new_location:
                new_path = self.project_root / new_location / current_path.name
                
                if not dry_run:
                    try:
                        new_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.move(str(current_path), str(new_path))
                        logging.info(f"ì´ë™: {current_path} â†’ {new_path}")
                    except Exception as e:
                        logging.error(f"ì´ë™ ì‹¤íŒ¨: {current_path} - {e}")
                
                moves[file_info.category] += 1
        
        return dict(moves)
    
    def _is_in_correct_location(self, file_path: Path, category: str) -> bool:
        """íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸"""
        parts = file_path.parts
        if len(parts) > 1 and parts[0] == category:
            return True
        return False
    
    def _get_target_location(self, file_info: FileInfo) -> Optional[str]:
        """íŒŒì¼ì˜ ëª©í‘œ ìœ„ì¹˜ ê²°ì •"""
        category_mapping = {
            'core': 'core',
            'modules': 'modules',
            'config': 'config',
            'docs': 'docs',
            'scripts': 'scripts',
            'data': 'data',
            'logs': 'logs',
            'reports': 'reports',
            'tests': 'tests',
            'backup': 'backup_old_files',
            'temp': 'backup_old_files',
            'media': 'docs',
            'archive': 'backup_old_files'
        }
        return category_mapping.get(file_info.category)
    
    def generate_report(self) -> str:
        """ğŸ“Š ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("ğŸ“ íŒŒì¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 50)
        report.append(f"ğŸ“… ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ“‚ í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.project_root}")
        report.append(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {len(self.files_data)}")
        report.append("")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = Counter(f.category for f in self.files_data.values())
        report.append("ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ë¶„í¬:")
        for category, count in category_stats.most_common():
            percentage = (count / len(self.files_data)) * 100
            report.append(f"  {category:12} : {count:4}ê°œ ({percentage:5.1f}%)")
        report.append("")
        
        # í¬ê¸°ë³„ í†µê³„
        total_size = sum(f.size for f in self.files_data.values())
        report.append(f"ğŸ’¾ ì´ ìš©ëŸ‰: {self._format_size(total_size)}")
        
        # ìƒìœ„ 10ê°œ í° íŒŒì¼
        large_files = sorted(self.files_data.values(), key=lambda x: x.size, reverse=True)[:10]
        report.append("\nğŸ“ í¬ê¸°ê°€ í° íŒŒì¼ Top 10:")
        for i, file_info in enumerate(large_files, 1):
            report.append(f"  {i:2}. {file_info.name:30} ({self._format_size(file_info.size)})")
        
        # ì¤‘ìš”ë„ ë†’ì€ íŒŒì¼
        important_files = sorted(self.files_data.values(), key=lambda x: x.usage_score, reverse=True)[:10]
        report.append("\nâ­ ì¤‘ìš”ë„ ë†’ì€ íŒŒì¼ Top 10:")
        for i, file_info in enumerate(important_files, 1):
            report.append(f"  {i:2}. {file_info.name:30} (ì ìˆ˜: {file_info.usage_score})")
        
        # í™•ì¥ìë³„ í†µê³„
        ext_stats = Counter(f.extension for f in self.files_data.values() if f.extension)
        report.append("\nğŸ“„ í™•ì¥ìë³„ íŒŒì¼ ìˆ˜:")
        for ext, count in ext_stats.most_common(10):
            report.append(f"  {ext:8} : {count:4}ê°œ")
        
        return "\n".join(report)
    
    def _format_size(self, size: int) -> str:
        """íŒŒì¼ í¬ê¸° í¬ë§·íŒ…"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024.0:
                return f"{size:3.1f} {unit}"
            size /= 1024.0
        return f"{size:.1f} TB"
    
    def create_backup(self) -> str:
        """ğŸ’¾ ì „ì²´ í”„ë¡œì íŠ¸ ë°±ì—…"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"project_backup_{timestamp}"
        backup_path = self.project_root.parent / backup_name
        
        print(f"ğŸ’¾ ë°±ì—… ìƒì„± ì¤‘: {backup_path}")
        
        try:
            shutil.copytree(
                self.project_root,
                backup_path,
                ignore=shutil.ignore_patterns('.git', '.venv', '__pycache__', '*.pyc')
            )
            print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")
            return str(backup_path)
        except Exception as e:
            print(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            return ""
    
    def cleanup_temp_files(self) -> int:
        """ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        print("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        
        temp_patterns = ['.tmp', '.temp', '.log', '__pycache__', '.pyc', '.pyo']
        cleaned = 0
        
        for file_path, file_info in self.files_data.items():
            if any(pattern in file_info.name.lower() for pattern in temp_patterns):
                try:
                    full_path = self.project_root / file_path
                    if full_path.exists():
                        if full_path.is_file():
                            full_path.unlink()
                        else:
                            shutil.rmtree(full_path)
                        cleaned += 1
                        logging.info(f"ì‚­ì œ: {file_path}")
                except Exception as e:
                    logging.warning(f"ì‚­ì œ ì‹¤íŒ¨: {file_path} - {e}")
        
        print(f"âœ… {cleaned}ê°œ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        return cleaned
    
    def save_analysis(self, filename: str = None) -> str:
        """ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"file_analysis_{timestamp}.json"
        
        output_path = self.project_root / "reports" / filename
        output_path.parent.mkdir(exist_ok=True)
        
        # ë¶„ì„ ë°ì´í„° ì¤€ë¹„
        analysis_data = {
            'timestamp': datetime.now().isoformat(),
            'project_root': str(self.project_root),
            'total_files': len(self.files_data),
            'files': [asdict(file_info) for file_info in self.files_data.values()],
            'statistics': {
                'categories': dict(Counter(f.category for f in self.files_data.values())),
                'extensions': dict(Counter(f.extension for f in self.files_data.values())),
                'total_size': sum(f.size for f in self.files_data.values())
            }
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
        return str(output_path)
    
    def interactive_menu(self) -> None:
        """ğŸ¯ ëŒ€í™”í˜• ë©”ë‰´"""
        while True:
            print("\n" + "="*60)
            print("ğŸ“ íŒŒì¼ ê´€ë¦¬ ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ")
            print("="*60)
            print("1. ğŸ“Š ì „ì²´ íŒŒì¼ ìŠ¤ìº”")
            print("2. ğŸ—‚ï¸  ìë™ íŒŒì¼ ì •ë¦¬ (ì‹œë®¬ë ˆì´ì…˜)")
            print("3. ğŸ—‚ï¸  ìë™ íŒŒì¼ ì •ë¦¬ (ì‹¤ì œ ì‹¤í–‰)")
            print("4. ğŸ” ì¤‘ë³µ íŒŒì¼ ê²€ìƒ‰")
            print("5. ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
            print("6. ğŸ’¾ í”„ë¡œì íŠ¸ ë°±ì—…")
            print("7. ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬")
            print("8. ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥")
            print("9. ğŸ“Š í˜„ì¬ êµ¬ì¡° ë³´ê¸°")
            print("0. ğŸšª ì¢…ë£Œ")
            print("-"*60)
            
            choice = input("ì„ íƒí•˜ì„¸ìš” (0-9): ").strip()
            
            try:
                if choice == '1':
                    self.scan_all_files()
                elif choice == '2':
                    moves = self.auto_organize(dry_run=True)
                    print("ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼:", moves)
                elif choice == '3':
                    confirm = input("â— ì‹¤ì œë¡œ íŒŒì¼ì„ ì´ë™í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                    if confirm.lower() == 'y':
                        moves = self.auto_organize(dry_run=False)
                        print("íŒŒì¼ ì´ë™ ì™„ë£Œ:", moves)
                elif choice == '4':
                    duplicates = self.find_duplicates()
                    if duplicates:
                        print(f"\nğŸ” ì¤‘ë³µ íŒŒì¼ {len(duplicates)}ê°œ ê·¸ë£¹:")
                        for i, (hash_val, files) in enumerate(duplicates.items(), 1):
                            print(f"  ê·¸ë£¹ {i}: {len(files)}ê°œ íŒŒì¼")
                            for file_path in files:
                                print(f"    - {file_path}")
                elif choice == '5':
                    if not self.files_data:
                        print("â— ë¨¼ì € íŒŒì¼ ìŠ¤ìº”ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    else:
                        report = self.generate_report()
                        print("\n" + report)
                elif choice == '6':
                    backup_path = self.create_backup()
                    if backup_path:
                        print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")
                elif choice == '7':
                    cleaned = self.cleanup_temp_files()
                    print(f"âœ… {cleaned}ê°œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                elif choice == '8':
                    if not self.files_data:
                        print("â— ë¨¼ì € íŒŒì¼ ìŠ¤ìº”ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    else:
                        save_path = self.save_analysis()
                        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
                elif choice == '9':
                    self.show_current_structure()
                elif choice == '0':
                    print("ğŸ‘‹ íŒŒì¼ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                else:
                    print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logging.error(f"ë©”ë‰´ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    
    def show_current_structure(self) -> None:
        """ğŸ“Š í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ë³´ê¸°"""
        print("\nğŸ“Š í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°:")
        print("-" * 40)
        
        for root, dirs, files in os.walk(self.project_root):
            level = root.replace(str(self.project_root), '').count(os.sep)
            indent = ' ' * 2 * level
            folder_name = os.path.basename(root) if level > 0 else "ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸"
            print(f"{indent}ğŸ“ {folder_name}/")
            
            subindent = ' ' * 2 * (level + 1)
            for file in files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                print(f"{subindent}ğŸ“„ {file}")
            
            if len(files) > 5:
                print(f"{subindent}   ... ì™¸ {len(files) - 5}ê°œ íŒŒì¼")
            
            if level >= 2:  # ë„ˆë¬´ ê¹Šì´ ë“¤ì–´ê°€ì§€ ì•Šê¸°
                dirs.clear()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ íŒŒì¼ ê´€ë¦¬ ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ v1.0 ì‹œì‘!")
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹œì‘
    file_manager = FileManager()
    
    # ëŒ€í™”í˜• ë©”ë‰´ ì‹œì‘
    file_manager.interactive_menu()

if __name__ == "__main__":
    main()