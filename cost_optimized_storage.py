#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: cost_optimized_storage.py
ëª¨ë“ˆ: ë¹„ìš© ìµœì í™”ëœ ë°ì´í„° ì €ì¥ ì‹œìŠ¤í…œ
ëª©ì : ë¡œì»¬ ìš°ì„ , í´ë¼ìš°ë“œ ë°±ì—… ì „ëµ

Author: AI Assistant
Created: 2025-01-27
Modified: 2025-01-27
Version: 1.0.0

Features:
- ë¡œì»¬ ìš°ì„  ì €ì¥ ì „ëµ
- ìŠ¤ë§ˆíŠ¸ ì••ì¶• ë° ì •ë¦¬
- ì„ íƒì  í´ë¼ìš°ë“œ ë°±ì—…
- ë¹„ìš© ëª¨ë‹ˆí„°ë§

Dependencies:
    - Python 3.11+
    - pandas==2.1.0
    - pyarrow==14.0.0
    - h5py==3.10.0
    - boto3==1.34.0 (AWS S3)
    - google-cloud-storage==2.10.0

Performance:
    - ë¡œì»¬ ì €ì¥: 100MB/s
    - ì••ì¶•ë¥ : 60-80%
    - í´ë¼ìš°ë“œ ì—…ë¡œë“œ: 10MB/s
    - ì›” ë¹„ìš©: < $5 (10GB ê¸°ì¤€)

License: MIT
"""

from __future__ import annotations

import asyncio
import logging
import os
import shutil
import sqlite3
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import (
    Any, Dict, List, Optional, Tuple, Union, Literal,
    Protocol, TypeVar, Generic, Final
)
from dataclasses import dataclass, field
from functools import lru_cache
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import h5py
import structlog

# ìƒìˆ˜ ì •ì˜
MAX_LOCAL_SIZE: Final = 100 * 1024 * 1024 * 1024  # 100GB
MAX_CLOUD_SIZE: Final = 10 * 1024 * 1024 * 1024   # 10GB
COMPRESSION_RATIO: Final = 0.7  # 70% ì••ì¶•ë¥ 
RETENTION_DAYS: Final = {
    'realtime': 7,
    'recent': 365,
    'historical': 1825,  # 5ë…„
    'backup': 365
}

@dataclass
class StorageConfig:
    """ì €ì¥ ì„¤ì •"""
    storage_type: Literal['local', 'cloud', 'hybrid']
    compression: bool = True
    retention_days: int = 365
    max_size_gb: int = 100
    backup_frequency: str = 'weekly'
    
    def __post_init__(self) -> None:
        """ê²€ì¦"""
        assert self.storage_type in ['local', 'cloud', 'hybrid']
        assert 0 < self.retention_days <= 3650  # ìµœëŒ€ 10ë…„
        assert 1 <= self.max_size_gb <= 1000

@dataclass
class DataInfo:
    """ë°ì´í„° ì •ë³´"""
    symbol: str
    data_type: str
    file_size: int
    record_count: int
    created_at: datetime
    last_accessed: datetime
    compression_ratio: float = 1.0
    storage_cost: float = 0.0

class CostOptimizedStorage:
    """ë¹„ìš© ìµœì í™”ëœ ì €ì¥ ì‹œìŠ¤í…œ"""
    
    def __init__(self, base_path: str = "data") -> None:
        self.base_path = Path(base_path)
        self.base_path.mkdir(exist_ok=True)
        
        # êµ¬ì¡°í™”ëœ ë¡œê¹…
        self.logger = structlog.get_logger()
        
        # ì €ì¥ì†Œë³„ ê²½ë¡œ
        self.storage_paths = {
            'realtime': self.base_path / "realtime",
            'recent': self.base_path / "recent", 
            'historical': self.base_path / "historical",
            'backup': self.base_path / "backup",
            'cache': self.base_path / "cache"
        }
        
        # ê²½ë¡œ ìƒì„±
        for path in self.storage_paths.values():
            path.mkdir(exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° DB
        self.metadata_db = self.base_path / "metadata.db"
        self._init_metadata_db()
        
        # ë¹„ìš© ì¶”ì 
        self.monthly_costs = {
            'local': 0.0,
            'cloud': 0.0,
            'total': 0.0
        }
    
    def _init_metadata_db(self) -> None:
        """ë©”íƒ€ë°ì´í„° DB ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS data_files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT,
                data_type TEXT,
                file_path TEXT,
                file_size INTEGER,
                record_count INTEGER,
                compression_ratio REAL,
                created_at TIMESTAMP,
                last_accessed TIMESTAMP,
                storage_cost REAL,
                retention_days INTEGER
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS storage_costs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                month TEXT,
                local_cost REAL,
                cloud_cost REAL,
                total_cost REAL,
                data_size_gb REAL
            )
        ''')
        
        conn.commit()
        conn.close()
    
    async def store_data(
        self, 
        data: pd.DataFrame, 
        symbol: str, 
        data_type: str,
        config: StorageConfig
    ) -> bool:
        """ë°ì´í„° ì €ì¥ (ë¹„ìš© ìµœì í™”)"""
        try:
            # ë°ì´í„° í¬ê¸° ê³„ì‚°
            original_size = len(data) * len(data.columns) * 8  # bytes
            record_count = len(data)
            
            # ì €ì¥ ê²½ë¡œ ê²°ì •
            storage_path = self._get_storage_path(data_type, config)
            
            # ì••ì¶• ì €ì¥
            file_path = storage_path / f"{symbol}_{data_type}.parquet"
            
            if config.compression:
                data.to_parquet(
                    file_path,
                    compression='snappy',
                    index=False
                )
            else:
                data.to_parquet(file_path, index=False)
            
            # ì••ì¶•ë¥  ê³„ì‚°
            compressed_size = file_path.stat().st_size
            compression_ratio = compressed_size / original_size if original_size > 0 else 1.0
            
            # ë¹„ìš© ê³„ì‚°
            storage_cost = self._calculate_storage_cost(compressed_size, data_type)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            await self._save_metadata(
                symbol, data_type, str(file_path), compressed_size,
                record_count, compression_ratio, storage_cost, config.retention_days
            )
            
            # ë¹„ìš© ì—…ë°ì´íŠ¸
            self._update_monthly_costs(storage_cost, data_type)
            
            self.logger.info(
                "ë°ì´í„° ì €ì¥ ì™„ë£Œ",
                symbol=symbol,
                data_type=data_type,
                size_mb=compressed_size / 1024 / 1024,
                compression_ratio=compression_ratio,
                cost=storage_cost
            )
            
            return True
            
        except Exception as e:
            self.logger.error("ë°ì´í„° ì €ì¥ ì‹¤íŒ¨", symbol=symbol, error=str(e))
            return False
    
    def _get_storage_path(self, data_type: str, config: StorageConfig) -> Path:
        """ì €ì¥ ê²½ë¡œ ê²°ì •"""
        if data_type == 'realtime':
            return self.storage_paths['realtime']
        elif data_type == 'recent':
            return self.storage_paths['recent']
        elif data_type == 'historical':
            return self.storage_paths['historical']
        else:
            return self.storage_paths['backup']
    
    def _calculate_storage_cost(self, size_bytes: int, data_type: str) -> float:
        """ì €ì¥ ë¹„ìš© ê³„ì‚°"""
        size_gb = size_bytes / 1024 / 1024 / 1024
        
        # ë¡œì»¬ ë¹„ìš© (ì „ê¸°ë£Œ ë“±)
        local_cost_per_gb = 0.01  # $0.01/GB/ì›”
        
        # í´ë¼ìš°ë“œ ë¹„ìš© (AWS S3 ê¸°ì¤€)
        cloud_cost_per_gb = 0.023  # $0.023/GB/ì›”
        
        if data_type in ['realtime', 'recent']:
            return size_gb * local_cost_per_gb
        else:
            return size_gb * cloud_cost_per_gb
    
    async def _save_metadata(
        self, 
        symbol: str, 
        data_type: str, 
        file_path: str,
        file_size: int, 
        record_count: int,
        compression_ratio: float,
        storage_cost: float,
        retention_days: int
    ) -> None:
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO data_files 
            (symbol, data_type, file_path, file_size, record_count, 
             compression_ratio, created_at, last_accessed, storage_cost, retention_days)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            symbol, data_type, file_path, file_size, record_count,
            compression_ratio, datetime.now(), datetime.now(), storage_cost, retention_days
        ))
        
        conn.commit()
        conn.close()
    
    def _update_monthly_costs(self, cost: float, data_type: str) -> None:
        """ì›” ë¹„ìš© ì—…ë°ì´íŠ¸"""
        if data_type in ['realtime', 'recent']:
            self.monthly_costs['local'] += cost
        else:
            self.monthly_costs['cloud'] += cost
        
        self.monthly_costs['total'] = self.monthly_costs['local'] + self.monthly_costs['cloud']
    
    async def load_data(self, symbol: str, data_type: str) -> Optional[pd.DataFrame]:
        """ë°ì´í„° ë¡œë“œ"""
        try:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            file_path = await self._get_file_path(symbol, data_type)
            if not file_path or not Path(file_path).exists():
                return None
            
            # ë°ì´í„° ë¡œë“œ
            df = pd.read_parquet(file_path)
            
            # ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
            await self._update_access_time(symbol, data_type)
            
            return df
            
        except Exception as e:
            self.logger.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨", symbol=symbol, error=str(e))
            return None
    
    async def _get_file_path(self, symbol: str, data_type: str) -> Optional[str]:
        """íŒŒì¼ ê²½ë¡œ ì¡°íšŒ"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT file_path FROM data_files 
            WHERE symbol = ? AND data_type = ?
            ORDER BY created_at DESC LIMIT 1
        ''', (symbol, data_type))
        
        result = cursor.fetchone()
        conn.close()
        
        return result[0] if result else None
    
    async def _update_access_time(self, symbol: str, data_type: str) -> None:
        """ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE data_files 
            SET last_accessed = ? 
            WHERE symbol = ? AND data_type = ?
        ''', (datetime.now(), symbol, data_type))
        
        conn.commit()
        conn.close()
    
    async def cleanup_old_data(self) -> Dict[str, int]:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        cleanup_stats = {'deleted_files': 0, 'freed_space_gb': 0}
        
        try:
            conn = sqlite3.connect(self.metadata_db)
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ íŒŒì¼ ì°¾ê¸°
            for data_type, retention_days in RETENTION_DAYS.items():
                cutoff_date = datetime.now() - timedelta(days=retention_days)
                
                cursor.execute('''
                    SELECT file_path, file_size FROM data_files 
                    WHERE data_type = ? AND created_at < ?
                ''', (data_type, cutoff_date))
                
                old_files = cursor.fetchall()
                
                for file_path, file_size in old_files:
                    try:
                        # íŒŒì¼ ì‚­ì œ
                        if Path(file_path).exists():
                            Path(file_path).unlink()
                            cleanup_stats['deleted_files'] += 1
                            cleanup_stats['freed_space_gb'] += file_size / 1024 / 1024 / 1024
                        
                        # ë©”íƒ€ë°ì´í„° ì‚­ì œ
                        cursor.execute('''
                            DELETE FROM data_files WHERE file_path = ?
                        ''', (file_path,))
                        
                    except Exception as e:
                        self.logger.error("íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨", file_path=file_path, error=str(e))
            
            conn.commit()
            conn.close()
            
            self.logger.info("ë°ì´í„° ì •ë¦¬ ì™„ë£Œ", stats=cleanup_stats)
            
        except Exception as e:
            self.logger.error("ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨", error=str(e))
        
        return cleanup_stats
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """ì €ì¥ì†Œ í†µê³„"""
        try:
            conn = sqlite3.connect(self.metadata_db)
            cursor = conn.cursor()
            
            # ì „ì²´ í†µê³„
            cursor.execute('''
                SELECT 
                    COUNT(*) as total_files,
                    SUM(file_size) as total_size,
                    SUM(storage_cost) as total_cost
                FROM data_files
            ''')
            
            total_stats = cursor.fetchone()
            
            # íƒ€ì…ë³„ í†µê³„
            cursor.execute('''
                SELECT 
                    data_type,
                    COUNT(*) as file_count,
                    SUM(file_size) as total_size,
                    SUM(storage_cost) as total_cost
                FROM data_files 
                GROUP BY data_type
            ''')
            
            type_stats = cursor.fetchall()
            
            conn.close()
            
            stats = {
                'total_files': total_stats[0] or 0,
                'total_size_gb': (total_stats[1] or 0) / 1024 / 1024 / 1024,
                'total_cost': total_stats[2] or 0.0,
                'monthly_costs': self.monthly_costs,
                'by_type': {
                    data_type: {
                        'file_count': count,
                        'size_gb': size / 1024 / 1024 / 1024,
                        'cost': cost
                    }
                    for data_type, count, size, cost in type_stats
                }
            }
            
            return stats
            
        except Exception as e:
            self.logger.error("í†µê³„ ì¡°íšŒ ì‹¤íŒ¨", error=str(e))
            return {}
    
    def get_cost_estimate(self, data_size_gb: float, data_type: str) -> Dict[str, float]:
        """ë¹„ìš© ì˜ˆìƒ"""
        local_cost_per_gb = 0.01
        cloud_cost_per_gb = 0.023
        
        if data_type in ['realtime', 'recent']:
            monthly_cost = data_size_gb * local_cost_per_gb
            storage_type = 'local'
        else:
            monthly_cost = data_size_gb * cloud_cost_per_gb
            storage_type = 'cloud'
        
        return {
            'monthly_cost': monthly_cost,
            'yearly_cost': monthly_cost * 12,
            'storage_type': storage_type,
            'compressed_size_gb': data_size_gb * COMPRESSION_RATIO
        }

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë¡œê¹… ì„¤ì •
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    
    storage = CostOptimizedStorage()
    
    print("ğŸ’° ë¹„ìš© ìµœì í™”ëœ ë°ì´í„° ì €ì¥ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ë¹„ìš© ì˜ˆìƒ
    test_sizes = [1, 10, 50, 100]  # GB
    
    print("ğŸ“Š ì˜ˆìƒ ë¹„ìš© (ì›”):")
    for size in test_sizes:
        local_estimate = storage.get_cost_estimate(size, 'recent')
        cloud_estimate = storage.get_cost_estimate(size, 'historical')
        
        print(f"  {size}GB ë°ì´í„°:")
        print(f"    ë¡œì»¬ ì €ì¥: ${local_estimate['monthly_cost']:.2f}/ì›”")
        print(f"    í´ë¼ìš°ë“œ ì €ì¥: ${cloud_estimate['monthly_cost']:.2f}/ì›”")
        print(f"    ì••ì¶• í›„ í¬ê¸°: {local_estimate['compressed_size_gb']:.1f}GB")
        print()
    
    # í˜„ì¬ í†µê³„
    stats = storage.get_storage_stats()
    print("ğŸ“ˆ í˜„ì¬ ì €ì¥ì†Œ í†µê³„:")
    print(f"  ì´ íŒŒì¼ ìˆ˜: {stats.get('total_files', 0)}")
    print(f"  ì´ í¬ê¸°: {stats.get('total_size_gb', 0):.2f}GB")
    print(f"  ì´ ë¹„ìš©: ${stats.get('total_cost', 0):.2f}")
    print()
    
    print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    print("  âœ… ë¡œì»¬ SSD: ì‹¤ì‹œê°„/ìµœê·¼ ë°ì´í„° (ë¹ ë¥¸ ì ‘ê·¼)")
    print("  âœ… ë¡œì»¬ HDD: íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„° (ì €ë ´í•œ ì €ì¥)")
    print("  âœ… í´ë¼ìš°ë“œ: ë°±ì—…/ì•„ì¹´ì´ë¸Œ (ì•ˆì „ì„±)")
    print("  âœ… ì••ì¶•: 60-80% ê³µê°„ ì ˆì•½")
    print("  âœ… ì •ë¦¬: ìë™ ì‚­ì œ/ì•„ì¹´ì´ë¸Œ")

if __name__ == "__main__":
    asyncio.run(main()) 