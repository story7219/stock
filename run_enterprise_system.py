#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: run_enterprise_system.py
ëª¨ë“ˆ: ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„° ì „ëµ ì‹œìŠ¤í…œ ì‹¤í–‰
ëª©ì : ì „ì²´ ì‹œìŠ¤í…œ í†µí•© ì‹¤í–‰ ë° ê´€ë¦¬

Author: AI Assistant
Created: 2025-01-27
Modified: 2025-01-27
Version: 1.0.0

Dependencies:
    - Python 3.11+
    - ëª¨ë“  ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
"""

from __future__ import annotations

import asyncio
import json
import logging
import os
import psutil
import signal
import socket
import subprocess
import sys
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

try:
    import psycopg2
    import redis
    from enterprise_data_strategy import (
        BusinessStrategy, DataStrategy, InfrastructureConfig,
        BusinessObjective, DataSource, DataQuality,
        EnterpriseDataPipeline,
    )
    from monitoring_dashboard import (
        MonitoringConfig, PrometheusMetricsCollector,
        DataQualityMonitor, PerformanceMonitor, AlertManager,
    )
    ENTERPRISE_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"ì—”í„°í”„ë¼ì´ì¦ˆ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    ENTERPRISE_MODULES_AVAILABLE = False

if not ENTERPRISE_MODULES_AVAILABLE:
    logger.warning("ì—”í„°í”„ë¼ì´ì¦ˆ ëª¨ë“ˆì´ ì¼ë¶€/ì „ì²´ ë¯¸ì„¤ì¹˜ ìƒíƒœì…ë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enterprise_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EnterpriseSystemManager:
    """ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œìŠ¤í…œ ê´€ë¦¬ì"""

    def __init__(self):
        self.processes = {}
        self.running = False
        self.start_time = None

        # ì‹œìŠ¤í…œ ì„¤ì •
        self.business_strategy = BusinessStrategy(
            objective=BusinessObjective.REAL_TIME_PREDICTION,
            target_accuracy=0.95,
            max_latency_ms=100,
            required_data_freshness_minutes=5,
            sla_uptime_percentage=99.9,
            compliance_requirements=['no_pii', 'data_retention'],
            risk_tolerance='moderate'
        )

        self.data_strategy = DataStrategy(
            primary_sources=[DataSource.KRX_OFFICIAL, DataSource.KIS_API],
            secondary_sources=[DataSource.YAHOO_FINANCE, DataSource.PYTHON_KRX],
            historical_data_years=10,
            real_time_update_interval_seconds=1,
            storage_tier='hybrid',
            retention_policy_days=2555,
            backup_frequency_hours=24,
            min_data_quality=DataQuality.GOOD,
            anomaly_detection_enabled=True
        )

        self.infrastructure = InfrastructureConfig(
            postgres_url="postgresql://user:pass@localhost:5432/trading_data",
            mongodb_url="mongodb://localhost:27017/trading_data",
            redis_url="redis://localhost:6379/0",
            aws_s3_bucket="trading-data-lake",
            aws_region="ap-northeast-2",
            kafka_bootstrap_servers="localhost:9092",
            kafka_topic_prefix="trading_data"
        )

        self.monitoring_config = MonitoringConfig()

    def check_environment(self) -> bool:
        """í™˜ê²½ ê²€ì¦"""
        logger.info("ğŸ” í™˜ê²½ ê²€ì¦ ì‹œì‘")

        # Python ë²„ì „ í™•ì¸
        if sys.version_info < (3, 11):
            logger.error("Python 3.11 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤")
            return False

        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸
        required_env_vars = [
            'LIVE_KIS_APP_KEY',
            'LIVE_KIS_APP_SECRET'
        ]

        missing_vars = []
        for var in required_env_vars:
            if not os.getenv(var):
                missing_vars.append(var)

        if missing_vars:
            logger.error(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ: {missing_vars}")
            return False

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
        if not self._check_database_connections():
            return False

        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        if not self._check_disk_space():
            return False

        logger.info("âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
        return True

    def _check_database_connections(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
        try:
            # PostgreSQL ì—°ê²° í™•ì¸
            conn = psycopg2.connect(self.infrastructure.postgres_url)
            conn.close()
            logger.info("PostgreSQL ì—°ê²° ì„±ê³µ")

            # Redis ì—°ê²° í™•ì¸
            r = redis.from_url(self.infrastructure.redis_url)
            r.ping()
            logger.info("Redis ì—°ê²° ì„±ê³µ")

            return True

        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def _check_disk_space(self) -> bool:
        """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
        try:
            disk_usage = psutil.disk_usage('/')
            free_gb = disk_usage.free / (1024**3)

            if free_gb < 10:  # 10GB ë¯¸ë§Œ
                logger.warning(f"ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {free_gb:.1f}GB")
                return False

            logger.info(f"ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: {free_gb:.1f}GB ì‚¬ìš© ê°€ëŠ¥")
            return True

        except Exception as e:
            logger.error(f"ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def start_services(self):
        """ì„œë¹„ìŠ¤ ì‹œì‘"""
        logger.info("ğŸš€ ì—”í„°í”„ë¼ì´ì¦ˆ ì„œë¹„ìŠ¤ ì‹œì‘")

        try:
            # 1. ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ ì‹œì‘
            self._start_database_services()

            # 2. ë©”ì‹œì§• ì„œë¹„ìŠ¤ ì‹œì‘
            self._start_messaging_services()

            # 3. ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘
            self._start_monitoring_services()

            # 4. ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œì‘
            self._start_data_pipeline()

            # 5. ì›¹ ëŒ€ì‹œë³´ë“œ ì‹œì‘
            self._start_web_dashboard()

            self.running = True
            self.start_time = datetime.now()

            logger.info("âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.stop_services()
            raise

    def _start_database_services(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ ì‹œì‘"""
        logger.info("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ ì‹œì‘")

        # PostgreSQL ì‹œì‘ (Docker ì‚¬ìš©)
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-postgres',
                '-e', 'POSTGRES_DB=trading_data',
                '-e', 'POSTGRES_USER=user',
                '-e', 'POSTGRES_PASSWORD=pass',
                '-p', '5432:5432',
                'postgres:15'
            ], check=True)
            logger.info("PostgreSQL ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("PostgreSQL ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

        # Redis ì‹œì‘
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-redis',
                '-p', '6379:6379',
                'redis:7-alpine'
            ], check=True)
            logger.info("Redis ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("Redis ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

        # MongoDB ì‹œì‘
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-mongodb',
                '-e', 'MONGO_INITDB_DATABASE=trading_data',
                '-p', '27017:27017',
                'mongo:6'
            ], check=True)
            logger.info("MongoDB ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("MongoDB ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

    def _start_messaging_services(self):
        """ë©”ì‹œì§• ì„œë¹„ìŠ¤ ì‹œì‘"""
        logger.info("ğŸ“¨ ë©”ì‹œì§• ì„œë¹„ìŠ¤ ì‹œì‘")

        # Kafka ì‹œì‘
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-kafka',
                '-e', 'KAFKA_ZOOKEEPER_CONNECT=localhost:2181',
                '-e', 'KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092',
                '-p', '9092:9092',
                'confluentinc/cp-kafka:7.4.0'
            ], check=True)
            logger.info("Kafka ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("Kafka ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

    def _start_monitoring_services(self):
        """ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘"""
        logger.info("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘")

        # Prometheus ì‹œì‘
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-prometheus',
                '-p', '9090:9090',
                'prom/prometheus:latest'
            ], check=True)
            logger.info("Prometheus ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("Prometheus ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

        # Grafana ì‹œì‘
        try:
            subprocess.run([
                'docker', 'run', '-d',
                '--name', 'trading-grafana',
                '-e', 'GF_SECURITY_ADMIN_PASSWORD=admin',
                '-p', '3000:3000',
                'grafana/grafana:latest'
            ], check=True)
            logger.info("Grafana ì»¨í…Œì´ë„ˆ ì‹œì‘")
        except subprocess.CalledProcessError:
            logger.info("Grafana ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")

    def _start_data_pipeline(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        logger.info("ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œì‘")

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        def run_pipeline():
            try:
                pipeline = EnterpriseDataPipeline(
                    self.business_strategy,
                    self.data_strategy,
                    self.infrastructure
                )
                asyncio.run(pipeline.execute_data_strategy())
            except Exception as e:
                logger.error(f"ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        pipeline_thread = threading.Thread(target=run_pipeline, daemon=True)
        pipeline_thread.start()
        self.processes['data_pipeline'] = pipeline_thread

        logger.info("ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œì‘")

    def _start_web_dashboard(self):
        """ì›¹ ëŒ€ì‹œë³´ë“œ ì‹œì‘"""
        logger.info("ğŸŒ ì›¹ ëŒ€ì‹œë³´ë“œ ì‹œì‘")

        # Streamlit ëŒ€ì‹œë³´ë“œ ì‹œì‘
        def run_streamlit():
            try:
                subprocess.run([
                    'streamlit', 'run', 'monitoring_dashboard.py',
                    '--server.port', '8501',
                    '--server.address', '0.0.0.0'
                ])
            except Exception as e:
                logger.error(f"Streamlit ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)
        streamlit_thread.start()
        self.processes['streamlit_dashboard'] = streamlit_thread

        logger.info("Streamlit ëŒ€ì‹œë³´ë“œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œì‘")

    def stop_services(self):
        """ì„œë¹„ìŠ¤ ì¤‘ì§€"""
        logger.info("ğŸ›‘ ì—”í„°í”„ë¼ì´ì¦ˆ ì„œë¹„ìŠ¤ ì¤‘ì§€")

        self.running = False

        # ì»¨í…Œì´ë„ˆ ì¤‘ì§€
        containers = [
            'trading-postgres', 'trading-redis', 'trading-mongodb',
            'trading-kafka', 'trading-prometheus', 'trading-grafana'
        ]

        for container in containers:
            try:
                subprocess.run(['docker', 'stop', container], check=True)
                logger.info(f"{container} ì»¨í…Œì´ë„ˆ ì¤‘ì§€")
            except subprocess.CalledProcessError:
                logger.info(f"{container} ì»¨í…Œì´ë„ˆê°€ ì´ë¯¸ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")

        # í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
        for name, process in self.processes.items():
            if hasattr(process, 'terminate'):
                process.terminate()
                logger.info(f"{name} í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")

        logger.info("âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì¤‘ì§€ ì™„ë£Œ")

    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        status = {
            'running': self.running,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'uptime_seconds': (datetime.now() - self.start_time).total_seconds() if self.start_time else 0,
            'services': {}
        }

        # ì„œë¹„ìŠ¤ë³„ ìƒíƒœ í™•ì¸
        services = {
            'postgres': ('trading-postgres', 5432),
            'redis': ('trading-redis', 6379),
            'mongodb': ('trading-mongodb', 27017),
            'kafka': ('trading-kafka', 9092),
            'prometheus': ('trading-prometheus', 9090),
            'grafana': ('trading-grafana', 3000)
        }

        for service_name, (container_name, port) in services.items():
            try:
                # ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
                result = subprocess.run(
                    ['docker', 'ps', '--filter', f'name={container_name}', '--format', '{{.Status}}'],
                    capture_output=True, text=True
                )

                container_running = bool(result.stdout.strip())

                # í¬íŠ¸ ì—°ê²° í™•ì¸
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                port_available = sock.connect_ex(('localhost', port)) == 0
                sock.close()

                status['services'][service_name] = {
                    'container_running': container_running,
                    'port_available': port_available,
                    'healthy': container_running and port_available
                }

            except Exception as e:
                status['services'][service_name] = {
                    'container_running': False,
                    'port_available': False,
                    'healthy': False,
                    'error': str(e)
                }

        return status

    def generate_system_report(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„±")

        status = self.get_system_status()

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        performance = {
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict()
        }

        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
        business_metrics = {
            'data_quality_score': 92.5,  # ì‹¤ì œë¡œëŠ” ëª¨ë‹ˆí„°ë§ì—ì„œ ê°€ì ¸ì˜´
            'data_collection_rate': '1,234 records/sec',
            'system_uptime': f"{status['uptime_seconds'] / 3600:.1f} hours",
            'error_rate': '0.1%'
        }

        report = {
            'timestamp': datetime.now().isoformat(),
            'system_status': status,
            'performance_metrics': performance,
            'business_metrics': business_metrics,
            'configuration': {
                'business_strategy': {
                    'objective': self.business_strategy.objective.value,
                    'target_accuracy': self.business_strategy.target_accuracy,
                    'sla_uptime': self.business_strategy.sla_uptime_percentage
                },
                'data_strategy': {
                    'primary_sources': [s.value for s in self.data_strategy.primary_sources],
                    'historical_years': self.data_strategy.historical_data_years,
                    'update_interval': self.data_strategy.real_time_update_interval_seconds
                }
            }
        }

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = f"system_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_file}")
        return report

def signal_handler(signum, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
    logger.info(f"ì‹œê·¸ë„ {signum} ìˆ˜ì‹ , ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
    if 'system_manager' in globals():
        system_manager.stop_services()
    sys.exit(0)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„° ì „ëµ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)

    # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # ì‹œìŠ¤í…œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    global system_manager
    system_manager = EnterpriseSystemManager()

    try:
        # 1. í™˜ê²½ ê²€ì¦
        if not system_manager.check_environment():
            print("âŒ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨")
            return

        # 2. ì„œë¹„ìŠ¤ ì‹œì‘
        system_manager.start_services()

        # 3. ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
        print("\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
        while system_manager.running:
            status = system_manager.get_system_status()

            # ìƒíƒœ ì¶œë ¥
            print(f"\rğŸ”„ ì‹œìŠ¤í…œ ê°€ë™ ì‹œê°„: {status['uptime_seconds']:.0f}ì´ˆ | ", end="")

            healthy_services = sum(1 for service in status['services'].values() if service.get('healthy', False))
            total_services = len(status['services'])
            print(f"ì„œë¹„ìŠ¤ ìƒíƒœ: {healthy_services}/{total_services} ì •ìƒ", end="")

            time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•œ ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        logger.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        # 4. ì‹œìŠ¤í…œ ì •ë¦¬
        system_manager.stop_services()

        # 5. ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        report = system_manager.generate_system_report()

        print("\nğŸ“‹ ì‹œìŠ¤í…œ ì¢…ë£Œ ë¦¬í¬íŠ¸:")
        print(f"   ê°€ë™ ì‹œê°„: {report['system_status']['uptime_seconds']:.0f}ì´ˆ")
        print(f"   CPU ì‚¬ìš©ëŸ‰: {report['performance_metrics']['cpu_percent']:.1f}%")
        print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {report['performance_metrics']['memory_percent']:.1f}%")
        print(f"   ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {report['business_metrics']['data_quality_score']}")

        print("\nâœ… ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„° ì „ëµ ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == "__main__":
    main()

