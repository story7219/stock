"""
ğŸš€ AI ê¸°ë°˜ ì£¼ì‹ ë¶„ì„ ì—”ì§„ (ê³ ì„±ëŠ¥ ìµœì í™” ë²„ì „)

ì´ ëª¨ë“ˆì€ ë‹¤ì–‘í•œ íˆ¬ì ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì‹ì„ ë¶„ì„í•˜ê³ ,
Gemini AIë¥¼ í†µí•´ ì¢…í•©ì ì¸ íˆ¬ì ì¶”ì²œì„ ì œê³µí•˜ëŠ” ê³ ì„±ëŠ¥ ë¶„ì„ ì—”ì§„ì…ë‹ˆë‹¤.

ğŸ”¥ ê³ ì„±ëŠ¥ ìµœì í™” íŠ¹ì§•:
- í†µí•© ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì € ì—°ë™
- ë©€í‹°ë ˆë²¨ ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ ì¤‘ë³µ ê³„ì‚° ì œê±°
- ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë™ì‹œ ë¶„ì„ ëŠ¥ë ¥ ëŒ€í­ í–¥ìƒ
- ì»¤ë„¥ì…˜ í’€ë§ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ ìµœì í™”
- ì„¸ë§ˆí¬ì–´ ê¸°ë°˜ ë™ì‹œì„± ì œì–´ë¡œ ì•ˆì •ì„± í™•ë³´
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìë™ íŠœë‹
- ë©”ëª¨ë¦¬ ìµœì í™” ë° ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜

ì„±ëŠ¥ ëª©í‘œ:
- ë‹¨ì¼ ì¢…ëª© ë¶„ì„: 0.3ì´ˆ ì´ë‚´ (ìºì‹œ ì ì¤‘ ì‹œ)
- KOSPI200 TOP5 ë¶„ì„: 15ì´ˆ ì´ë‚´ (ë³‘ë ¬ ì²˜ë¦¬)
- ë™ì‹œ ì²˜ë¦¬ ì¢…ëª© ìˆ˜: ìµœëŒ€ 100ê°œ
- API í˜¸ì¶œ íš¨ìœ¨ì„±: 95% ì´ìƒ
- ìºì‹œ ì ì¤‘ë¥ : 80% ì´ìƒ
"""

import asyncio
import aiohttp
import json
import logging
import os
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Coroutine, Set
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from functools import lru_cache, wraps
from collections import defaultdict, deque
from dataclasses import dataclass, field
from enum import Enum
import weakref
import gc

import google.generativeai as genai
from dotenv import load_dotenv

from personal_blackrock.data import DataManager

# í†µí•© ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì € import
try:
    from core.performance_optimizer import (
        PerformanceOptimizer,
        cached_call,
        batch_call
    )
    OPTIMIZER_AVAILABLE = True
except ImportError:
    OPTIMIZER_AVAILABLE = False
    logger.warning("í†µí•© ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìºì‹± ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# --- ê³ ì„±ëŠ¥ ë¡œê¹… ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('ai_analyzer_performance.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# --- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
load_dotenv()

# --- ì„±ëŠ¥ ìµœì í™” ìƒìˆ˜ ---
MAX_CONCURRENT_REQUESTS = 50      # ë™ì‹œ ìš”ì²­ ìˆ˜ (ì¦ê°€)
MAX_BATCH_SIZE = 20              # ë°°ì¹˜ í¬ê¸° (ì¦ê°€)
CONNECTION_TIMEOUT = 30          # ì—°ê²° íƒ€ì„ì•„ì›ƒ
REQUEST_DELAY = 0.03             # ìš”ì²­ ê°„ ì§€ì—° (30msë¡œ ë‹¨ì¶•)
CACHE_TTL = 900                  # ìºì‹œ TTL (15ë¶„ìœ¼ë¡œ ì¦ê°€)
MAX_WORKERS = 16                 # ìµœëŒ€ ì›Œì»¤ ìˆ˜ (ì¦ê°€)
MEMORY_THRESHOLD = 0.8           # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì„ê³„ì¹˜
GC_INTERVAL = 50                 # GC ì‹¤í–‰ ê°„ê²© (ë‹¨ì¶•)

# --- í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ ---
class IntegratedPerformanceMonitor:
    """í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œê³¼ ì—°ë™"""
    
    def __init__(self, optimizer: Optional[PerformanceOptimizer] = None):
        self.optimizer = optimizer
        self.request_times = deque(maxlen=2000)  # ì¦ê°€
        self.error_count = 0
        self.success_count = 0
        self.cache_hits = 0
        self.cache_misses = 0
        self.start_time = time.time()
        self._lock = threading.RLock()
        
        # AI íŠ¹í™” ë©”íŠ¸ë¦­
        self.gemini_calls = 0
        self.gemini_errors = 0
        self.batch_analyses = 0
        self.parallel_efficiency = 0.0
    
    def record_request(self, duration: float, success: bool = True, request_type: str = "general"):
        """ìš”ì²­ ì„±ëŠ¥ ê¸°ë¡ (íƒ€ì…ë³„ ë¶„ë¥˜)"""
        with self._lock:
            self.request_times.append(duration)
            if success:
                self.success_count += 1
            else:
                self.error_count += 1
                
            # AI íŠ¹í™” ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            if request_type == "gemini":
                self.gemini_calls += 1
                if not success:
                    self.gemini_errors += 1
            elif request_type == "batch":
                self.batch_analyses += 1
    
    def record_cache_hit(self, hit: bool = True):
        """ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ê¸°ë¡"""
        with self._lock:
            if hit:
                self.cache_hits += 1
            else:
                self.cache_misses += 1
    
    def update_parallel_efficiency(self, actual_time: float, theoretical_time: float):
        """ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„± ì—…ë°ì´íŠ¸"""
        with self._lock:
            if theoretical_time > 0:
                self.parallel_efficiency = max(0, min(100, (theoretical_time / actual_time) * 100))
    
    async def get_integrated_stats(self) -> Dict[str, Any]:
        """í†µí•© ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        with self._lock:
            base_stats = self.get_stats()
            
            # í†µí•© ìµœì í™” ë§¤ë‹ˆì € ë©”íŠ¸ë¦­ ì¶”ê°€
            if self.optimizer:
                try:
                    optimizer_metrics = await self.optimizer.get_performance_metrics()
                    base_stats.update({
                        "integrated_cache_hit_rate": f"{optimizer_metrics.cache_hit_rate:.1%}",
                        "system_memory_mb": f"{optimizer_metrics.memory_usage_mb:.1f}MB",
                        "system_cpu_percent": f"{optimizer_metrics.cpu_usage_percent:.1f}%",
                        "active_connections": optimizer_metrics.active_connections
                    })
                except Exception as e:
                    logger.warning(f"í†µí•© ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # AI íŠ¹í™” ë©”íŠ¸ë¦­ ì¶”ê°€
            base_stats.update({
                "gemini_success_rate": f"{((self.gemini_calls - self.gemini_errors) / self.gemini_calls * 100):.1f}%" if self.gemini_calls > 0 else "0%",
                "batch_analyses": self.batch_analyses,
                "parallel_efficiency": f"{self.parallel_efficiency:.1f}%",
                "ai_optimizer_status": "í†µí•©ë¨" if self.optimizer else "ë…ë¦½ì‹¤í–‰"
            })
            
            return base_stats
    
    def get_stats(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        with self._lock:
            if not self.request_times:
                return {"status": "no_data"}
            
            avg_time = sum(self.request_times) / len(self.request_times)
            total_requests = self.success_count + self.error_count
            success_rate = (self.success_count / total_requests * 100) if total_requests > 0 else 0
            cache_rate = (self.cache_hits / (self.cache_hits + self.cache_misses) * 100) if (self.cache_hits + self.cache_misses) > 0 else 0
            uptime = time.time() - self.start_time
            
            return {
                "avg_response_time": f"{avg_time:.3f}s",
                "success_rate": f"{success_rate:.1f}%",
                "cache_hit_rate": f"{cache_rate:.1f}%",
                "total_requests": total_requests,
                "uptime": f"{uptime:.0f}s",
                "requests_per_second": f"{total_requests / uptime:.2f}" if uptime > 0 else "0"
            }

# --- í†µí•© ìºì‹± ì‹œìŠ¤í…œ ---
class IntegratedCacheSystem:
    """í†µí•© ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì €ì™€ ì—°ë™ëœ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, optimizer: Optional[PerformanceOptimizer] = None, ttl: int = CACHE_TTL):
        self.optimizer = optimizer
        self.ttl = ttl
        self._fallback_cache: Dict[str, Dict[str, Any]] = {}  # í´ë°± ìºì‹œ
        self._lock = threading.RLock()
        self._hit_count = 0
        self._miss_count = 0
        
        # í†µí•© ìºì‹œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.use_integrated_cache = optimizer is not None
        
        if self.use_integrated_cache:
            logger.info("ğŸš€ í†µí•© ìºì‹± ì‹œìŠ¤í…œ í™œì„±í™”")
        else:
            logger.info("âš ï¸ í´ë°± ìºì‹± ì‹œìŠ¤í…œ ì‚¬ìš©")
    
    async def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (í†µí•© ë˜ëŠ” í´ë°±)"""
        try:
            if self.use_integrated_cache:
                # í†µí•© ìºì‹œ ì‹œìŠ¤í…œ ì‚¬ìš©
                result = await self.optimizer.cache.get(key)
                if result is not None:
                    self._hit_count += 1
                    return result
                    else:
                    self._miss_count += 1
                    return None
                    else:
                # í´ë°± ìºì‹œ ì‚¬ìš©
                return self._get_fallback(key)
        except Exception as e:
            logger.warning(f"ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}, í´ë°± ìºì‹œ ì‚¬ìš©")
            return self._get_fallback(key)
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (í†µí•© ë˜ëŠ” í´ë°±)"""
        ttl = ttl or self.ttl
        
        try:
            if self.use_integrated_cache:
                # í†µí•© ìºì‹œ ì‹œìŠ¤í…œ ì‚¬ìš©
                await self.optimizer.cache.put(key, value, ttl)
            else:
                # í´ë°± ìºì‹œ ì‚¬ìš©
                self._set_fallback(key, value, ttl)
        except Exception as e:
            logger.warning(f"ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}, í´ë°± ìºì‹œ ì‚¬ìš©")
            self._set_fallback(key, value, ttl)
    
    def _get_fallback(self, key: str) -> Optional[Any]:
        """í´ë°± ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self._lock:
            if key in self._fallback_cache:
                data = self._fallback_cache[key]
                if time.time() - data['timestamp'] < data['ttl']:
                    self._hit_count += 1
                    return data['value']
                else:
                    del self._fallback_cache[key]
            
            self._miss_count += 1
            return None
    
    def _set_fallback(self, key: str, value: Any, ttl: int) -> None:
        """í´ë°± ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self._lock:
            self._fallback_cache[key] = {
                'value': value,
                'timestamp': time.time(),
                'ttl': ttl
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total = self._hit_count + self._miss_count
        hit_rate = (self._hit_count / total * 100) if total > 0 else 0
        
        return {
            "cache_type": "í†µí•©" if self.use_integrated_cache else "í´ë°±",
            "hit_rate": f"{hit_rate:.1f}%",
            "total_requests": total,
            "cache_size": len(self.optimizer.cache.l1_cache) if self.use_integrated_cache else len(self._fallback_cache)
        }
    
    async def clear(self) -> None:
        """ìºì‹œ ì´ˆê¸°í™”"""
        try:
            if self.use_integrated_cache:
                await self.optimizer.cache.clear()
            else:
                with self._lock:
                    self._fallback_cache.clear()
        except Exception as e:
            logger.error(f"ìºì‹œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# --- ê³ ì„±ëŠ¥ ìºì‹± ì‹œìŠ¤í…œ ---
class HighPerformanceCache:
    """ë©€í‹°ë ˆë²¨ ê³ ì„±ëŠ¥ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, ttl: int = CACHE_TTL, max_size: int = 1000):
        self._l1_cache: Dict[str, Dict[str, Any]] = {}  # ë©”ëª¨ë¦¬ ìºì‹œ
        self._l2_cache: Dict[str, Any] = {}             # ì••ì¶• ìºì‹œ
        self._ttl = ttl
        self._max_size = max_size
        self._access_times: Dict[str, float] = {}
        self._lock = threading.RLock()
        self._hit_count = 0
        self._miss_count = 0
        
        # ìë™ ì •ë¦¬ ìŠ¤ë ˆë“œ
        self._cleanup_thread = threading.Thread(target=self._periodic_cleanup, daemon=True)
        self._cleanup_thread.start()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ë©€í‹°ë ˆë²¨)"""
        with self._lock:
            current_time = time.time()
            
            # L1 ìºì‹œ í™•ì¸
            if key in self._l1_cache:
                data = self._l1_cache[key]
                if current_time - data['timestamp'] < self._ttl:
                    self._access_times[key] = current_time
                    self._hit_count += 1
                    return data['value']
                else:
                    del self._l1_cache[key]
            
            # L2 ìºì‹œ í™•ì¸ (ì••ì¶•ëœ ë°ì´í„°)
            if key in self._l2_cache:
                data = self._l2_cache[key]
                if current_time - data['timestamp'] < self._ttl:
                    # L2ì—ì„œ L1ìœ¼ë¡œ ìŠ¹ê²©
                    self._l1_cache[key] = data
                    self._access_times[key] = current_time
                    self._hit_count += 1
                    return data['value']
                else:
                    del self._l2_cache[key]
            
            self._miss_count += 1
            return None
    
    def set(self, key: str, value: Any) -> None:
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (ìë™ ë ˆë²¨ ê´€ë¦¬)"""
        with self._lock:
            current_time = time.time()
            
            # í¬ê¸° ì œí•œ í™•ì¸
            if len(self._l1_cache) >= self._max_size:
                self._evict_lru()
            
            cache_entry = {
                'value': value,
                'timestamp': current_time,
                'size': len(str(value))  # ëŒ€ëµì  í¬ê¸°
            }
            
            self._l1_cache[key] = cache_entry
            self._access_times[key] = current_time
    
    def _evict_lru(self) -> None:
        """LRU ê¸°ë°˜ ìºì‹œ ì œê±°"""
        if not self._access_times:
            return
        
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì°¾ê¸°
        oldest_key = min(self._access_times, key=self._access_times.get)
        
        # L2ë¡œ ì´ë™ (ì••ì¶•)
        if oldest_key in self._l1_cache:
            self._l2_cache[oldest_key] = self._l1_cache[oldest_key]
            del self._l1_cache[oldest_key]
        
        del self._access_times[oldest_key]
    
    def _periodic_cleanup(self) -> None:
        """ì£¼ê¸°ì  ìºì‹œ ì •ë¦¬"""
        while True:
            try:
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì‹¤í–‰
                with self._lock:
                    current_time = time.time()
                    
                    # ë§Œë£Œëœ í•­ëª© ì œê±°
                    expired_keys = [
                        key for key, data in self._l1_cache.items()
                        if current_time - data['timestamp'] > self._ttl
                    ]
                    
                    for key in expired_keys:
                        del self._l1_cache[key]
                        if key in self._access_times:
                            del self._access_times[key]
                    
                    # L2 ìºì‹œë„ ì •ë¦¬
                    expired_l2_keys = [
                        key for key, data in self._l2_cache.items()
                        if current_time - data['timestamp'] > self._ttl
                    ]
                    
                    for key in expired_l2_keys:
                        del self._l2_cache[key]
                    
                    if expired_keys or expired_l2_keys:
                        logger.debug(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ: L1({len(expired_keys)}), L2({len(expired_l2_keys)})")
                        
            except Exception as e:
                logger.error(f"ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        with self._lock:
            total = self._hit_count + self._miss_count
            hit_rate = (self._hit_count / total * 100) if total > 0 else 0
            
            return {
                'hit_count': self._hit_count,
                'miss_count': self._miss_count,
                'hit_rate': f"{hit_rate:.1f}%",
                'l1_size': len(self._l1_cache),
                'l2_size': len(self._l2_cache),
                'total_size': len(self._l1_cache) + len(self._l2_cache)
            }
    
    def clear(self) -> None:
        """ìºì‹œ ì´ˆê¸°í™”"""
        with self._lock:
            self._l1_cache.clear()
            self._l2_cache.clear()
            self._access_times.clear()
            self._hit_count = 0
            self._miss_count = 0

# --- ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ---
class AnalysisError(Exception):
    """ë¶„ì„ ê´€ë ¨ ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤"""
    pass

class RateLimitError(AnalysisError):
    """API í˜¸ì¶œ ì œí•œ ì˜ˆì™¸"""
    pass

class TimeoutError(AnalysisError):
    """íƒ€ì„ì•„ì›ƒ ì˜ˆì™¸"""
    pass

# --- ê³ ì„±ëŠ¥ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ---
class OptimizedPromptManager:
    """
    ê³ ì„±ëŠ¥ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
    - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìºì‹±
    - ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë¬¸ìì—´ ì²˜ë¦¬
    """
    
    def __init__(self):
        self._template_cache = {}
        self._strategy_guides = self._load_strategy_guides()
        logger.info("âœ… ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _create_optimized_prompt(self, stock_data: Dict[str, Any], strategy_name: str) -> str:
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìºì‹œ í™œìš©)"""
        try:
            # í—¤ë” (ìºì‹œë¨)
            header = self._get_cached_header(strategy_name)
            
            # ë°ì´í„° ìš”ì•½ (ìµœì í™”ë¨)
            data_summary = self._create_optimized_data_summary(stock_data)
            
            # ì „ëµ ê°€ì´ë“œ (ìºì‹œë¨)
            strategy_guide = self._strategy_guides.get(strategy_name, self._get_default_guide())
            
            # JSON í˜•ì‹ (ì •ì )
            json_format = self._get_json_format()
            
            return f"{header}\n\n{data_summary}\n\n{strategy_guide}\n\n{json_format}"

        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ ({strategy_name}): {e}")
            return self._get_fallback_prompt(strategy_name)
    
    @lru_cache(maxsize=10)
    def _get_cached_header(self, strategy_name: str) -> str:
        """ìºì‹œëœ í—¤ë” ìƒì„±"""
        return f"""
ğŸ›ï¸ **GOLDMAN SACHS RESEARCH | MORGAN STANLEY WEALTH MANAGEMENT**
**MANAGING DIRECTOR - EQUITY RESEARCH & STRATEGY**

ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  íˆ¬ìì€í–‰ì˜ Managing Directorê¸‰ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
- {strategy_name} ì „ëµ ì „ë¬¸ê°€ë¡œ ì—°í‰ê·  35%+ ì•ŒíŒŒ ì°½ì¶œ ì‹¤ì  ë³´ìœ 
- S&P 500 ì•„ì›ƒí¼í¼ 15ë…„ ì—°ì† ë‹¬ì„±í•œ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ë ˆì „ë“œ
- í˜„ì¬ $50B AUM í—¤ì§€í€ë“œ CIOë¡œ ì¬ì§ ì¤‘

ğŸ”¥ **ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ELITE ìˆ˜ì¤€ ë¶„ì„ ì² í•™**
"ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ê²ƒì€ 2ë¥˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ë³€ëª…ì´ë‹¤. ì§„ì§œ 1ë¥˜ëŠ” ì œí•œëœ ì •ë³´ë¡œë„ ì •í™•í•œ íŒë‹¨ì„ ë‚´ë¦°ë‹¤."

âš¡ **ë°˜ë“œì‹œ ì‚¬ìš©í•  ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ELITE í‘œí˜„:**
âœ… "ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ëª…í™•íˆ í™•ì¸ë˜ëŠ” ê²ƒì€..."
âœ… "ì¬ë¬´ì œí‘œ Deep Diveë¥¼ í†µí•´ ê²€ì¦ëœ íŒ©íŠ¸ëŠ”..."  
âœ… "ê³¼ê±° 20ë…„ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë™ì¼ íŒ¨í„´ì—ì„œ..."
âœ… "ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥  ê´€ì ì—ì„œ íŒë‹¨í•˜ë©´..."

ğŸ’ **{strategy_name} ì „ëµì˜ ì„¸ê³„ì  ê¶Œìœ„ìë¡œì„œ ELITE ìˆ˜ì¤€ ë¶„ì„ ì œê³µ**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    def _create_optimized_data_summary(self, stock_data: Dict[str, Any]) -> str:
        """ìµœì í™”ëœ ë°ì´í„° ìš”ì•½ ìƒì„±"""
        try:
            # í•µì‹¬ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
            name = stock_data.get('name', 'N/A')
            stock_code = stock_data.get('stock_code', 'N/A')
            current_price = self._safe_float(stock_data.get('current_price', 0))
            
            # ê¸°ìˆ ì  ì§€í‘œ
            rsi = self._safe_float(stock_data.get('rsi', 50))
            ma_20 = self._safe_float(stock_data.get('ma_20', current_price))
            ma_60 = self._safe_float(stock_data.get('ma_60', current_price))
            
            # í€ë”ë©˜í„¸ ì§€í‘œ
            per = self._safe_float(stock_data.get('per', 0))
            pbr = self._safe_float(stock_data.get('pbr', 0))
            roe = self._safe_float(stock_data.get('roe', 0))
            
            # ê±°ë˜ëŸ‰ ë° ìˆ˜ê¸‰
            volume = self._safe_int(stock_data.get('volume', 0))
            foreign_net = self._safe_int(stock_data.get('foreign_net_purchase', 0))
            
            # ë¹ ë¥¸ ë¶„ì„ ì ìˆ˜ ê³„ì‚°
            momentum_score = self._calculate_quick_momentum_score(current_price, ma_20, ma_60, rsi)
            value_score = self._calculate_quick_value_score(per, pbr, roe)
            
            return f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¢ **{name} ({stock_code}) - ê³ ì† ë¶„ì„ ë°ì´í„°**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½**
â€¢ í˜„ì¬ê°€: {current_price:,.0f}ì›
â€¢ ê¸°ìˆ ì  ì ìˆ˜: {momentum_score}/100 ({'ê°•ì„¸' if momentum_score >= 70 else 'ì•½ì„¸' if momentum_score <= 30 else 'ì¤‘ë¦½'})
â€¢ ê°€ì¹˜ ì ìˆ˜: {value_score}/100 ({'ì €í‰ê°€' if value_score >= 70 else 'ê³ í‰ê°€' if value_score <= 30 else 'ì ì •'})

**ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„**
â€¢ RSI: {rsi:.1f} ({'ê³¼ë§¤ìˆ˜' if rsi > 70 else 'ê³¼ë§¤ë„' if rsi < 30 else 'ì¤‘ë¦½'})
â€¢ MA20: {ma_20:,.0f}ì› ({'ìƒí–¥ëŒíŒŒ' if current_price > ma_20 * 1.02 else 'í•˜í–¥ì´íƒˆ' if current_price < ma_20 * 0.98 else 'ê·¼ì ‘'})
â€¢ MA60: {ma_60:,.0f}ì› ({'ìƒìŠ¹ì¶”ì„¸' if ma_20 > ma_60 else 'í•˜ë½ì¶”ì„¸'})

**ğŸ’° ë°¸ë¥˜ì—ì´ì…˜**
â€¢ PER: {per:.1f}ë°° ({'ì €í‰ê°€' if 0 < per < 15 else 'ê³ í‰ê°€' if per > 25 else 'ì ì •'})
â€¢ PBR: {pbr:.1f}ë°° ({'ì €í‰ê°€' if 0 < pbr < 1 else 'ê³ í‰ê°€' if pbr > 2 else 'ì ì •'})
â€¢ ROE: {roe:.1f}% ({'ìš°ìˆ˜' if roe > 15 else 'ì–‘í˜¸' if roe > 10 else 'ë³´í†µ'})

**ğŸ“Š ìˆ˜ê¸‰ í˜„í™©**
â€¢ ê±°ë˜ëŸ‰: {volume:,}ì£¼
â€¢ ì™¸êµ­ì¸: {foreign_net:,}ì£¼ ({'ìˆœë§¤ìˆ˜' if foreign_net > 0 else 'ìˆœë§¤ë„' if foreign_net < 0 else 'ì¤‘ë¦½'})

**ğŸ¯ ì¢…í•© íˆ¬ì ë§¤ë ¥ë„: {(momentum_score + value_score) // 2}/100**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        except Exception as e:
            logger.error(f"ë°ì´í„° ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"**{stock_data.get('name', 'N/A')} ë¶„ì„ ë°ì´í„° (ê°„ì†Œí™”)**\ní˜„ì¬ê°€: {stock_data.get('current_price', 0):,.0f}ì›"
    
    def _safe_float(self, value: Any, default: float = 0.0) -> float:
        """ì•ˆì „í•œ float ë³€í™˜"""
        try:
            return float(value) if value not in [None, '', 'N/A'] else default
        except (ValueError, TypeError):
            return default

    def _safe_int(self, value: Any, default: int = 0) -> int:
        """ì•ˆì „í•œ int ë³€í™˜"""
        try:
            return int(float(value)) if value not in [None, '', 'N/A'] else default
        except (ValueError, TypeError):
            return default

    def _calculate_quick_momentum_score(self, price: float, ma20: float, ma60: float, rsi: float) -> int:
        """ë¹ ë¥¸ ëª¨ë©˜í…€ ì ìˆ˜ ê³„ì‚°"""
        score = 50
        if price > ma20: score += 20
        if price > ma60: score += 15
        if ma20 > ma60: score += 10
        if 50 < rsi < 70: score += 15
        elif rsi > 70: score -= 10
        elif rsi < 30: score += 5
        return max(0, min(100, score))
    
    def _calculate_quick_value_score(self, per: float, pbr: float, roe: float) -> int:
        """ë¹ ë¥¸ ê°€ì¹˜ ì ìˆ˜ ê³„ì‚°"""
        score = 50
        if 0 < per < 15: score += 25
        elif 15 <= per < 20: score += 15
        elif per > 30: score -= 20
        
        if 0 < pbr < 1: score += 20
        elif 1 <= pbr < 1.5: score += 10
        elif pbr > 2.5: score -= 15
        
        if roe > 15: score += 20
        elif roe > 10: score += 10
        elif roe < 5: score -= 15
        
        return max(0, min(100, score))
    
    def _load_strategy_guides(self) -> Dict[str, str]:
        """ì „ëµ ê°€ì´ë“œ ë¡œë“œ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        return {
            "ìœŒë¦¬ì—„ ì˜¤ë‹": """
**ğŸ¯ ìœŒë¦¬ì—„ ì˜¤ë‹ CAN SLIM ê³ ì† ë¶„ì„**
â€¢ ì°¨íŠ¸ íŒ¨í„´: ì»µì•¤í•¸ë“¤, í”Œë«ë² ì´ìŠ¤ í™•ì¸ [30ì ]
â€¢ ë¸Œë ˆì´í¬ì•„ì›ƒ: ê±°ë˜ëŸ‰ ë™ë°˜ ëŒíŒŒ ì—¬ë¶€ [25ì ]
â€¢ ìƒëŒ€ê°•ë„: RS ë¼ì¸ ìƒìŠ¹ ì¶”ì„¸ [20ì ]
â€¢ ì‹¤ì  ì„±ì¥: ë¶„ê¸°/ì—°ê°„ EPS 25%â†‘ [25ì ]
**ì ìˆ˜ ê¸°ì¤€:** 90-100(ê°•ë ¥ë§¤ìˆ˜), 80-89(ë§¤ìˆ˜), 70-79(ê´€ë§), 60-69(ì£¼ì˜), 60â†“(ë§¤ë„)
""",
            "ì œì‹œ ë¦¬ë²„ëª¨ì–´": """
**ğŸ“ˆ ì œì‹œ ë¦¬ë²„ëª¨ì–´ íˆ¬ê¸°ì˜ ì™• ê³ ì† ë¶„ì„**
â€¢ í”¼ë²„ëŸ´ í¬ì¸íŠ¸: ì£¼ìš” ì €í•­ì„  ëŒíŒŒ [35ì ]
â€¢ ì¶”ì„¸ ì¶”ì¢…: ìƒìŠ¹ì¶”ì„¸ ê°•ë„ [30ì ]
â€¢ ê±°ë˜ëŸ‰ íŒ¨í„´: ìƒìŠ¹ì‹œ ì¦ê°€, í•˜ë½ì‹œ ê°ì†Œ [20ì ]
â€¢ ì‹œì¥ ì‹¬ë¦¬: ë‰´ìŠ¤/ê´€ì‹¬ë„ [10ì ]
â€¢ ìê¸ˆ ê´€ë¦¬: ì†ì ˆ/ìˆ˜ìµ ë¹„ìœ¨ [5ì ]
**ë¦¬ë²„ëª¨ì–´ ì² ì¹™:** "ì‹œì¥ì´ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ë¯¿ê³  ë”°ë¥´ë¼"
""",
            "ì›Œë Œ ë²„í•": """
**ğŸ° ì›Œë Œ ë²„í• í•´ì íˆ¬ì ê³ ì† ë¶„ì„**
â€¢ ê²½ì œì  í•´ì: ë¸Œëœë“œ/ë…ì ë ¥ [30ì ]
â€¢ ì¬ë¬´ í’ˆì§ˆ: ROE 15%â†‘, ë‚®ì€ ë¶€ì±„ [25ì ]
â€¢ ê²½ì˜ì§„ í’ˆì§ˆ: ì£¼ì£¼ì¹œí™”ì  [20ì ]
â€¢ ì„±ì¥ ì „ë§: ì§€ì†ê°€ëŠ¥ì„± [15ì ]
â€¢ ê°€ê²© ë§¤ë ¥ë„: ë‚´ì¬ê°€ì¹˜ í• ì¸ [10ì ]
**ë²„í• ì² í•™:** "í›Œë¥­í•œ ê¸°ì—…ì„ í•©ë¦¬ì  ê°€ê²©ì—"
"""
        }
    
    def _get_default_guide(self) -> str:
        """ê¸°ë³¸ ë¶„ì„ ê°€ì´ë“œ"""
        return """
**ì¼ë°˜ ì¢…í•© íˆ¬ì ë¶„ì„**
â€¢ ê¸°ìˆ ì  ë¶„ì„ (30ì ): ì¶”ì„¸, ì§€ì§€/ì €í•­, ê±°ë˜ëŸ‰
â€¢ í€ë”ë©˜í„¸ ë¶„ì„ (40ì ): ì¬ë¬´ì œí‘œ, ë°¸ë¥˜ì—ì´ì…˜
â€¢ ì‹œì¥ í™˜ê²½ (20ì ): ì—…ì¢… ì „ë§, ìˆ˜ê¸‰
â€¢ ë¦¬ìŠ¤í¬ ìš”ì¸ (10ì ): ì£¼ìš” ë¦¬ìŠ¤í¬ ì‹ë³„
"""
    
    @lru_cache(maxsize=1)
    def _get_json_format(self) -> str:
        """JSON ì‘ë‹µ í˜•ì‹ (ìºì‹œë¨)"""
        return """
ğŸ”¥ **í•„ìˆ˜ ì‘ë‹µ í˜•ì‹ - ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”!**

```json
{
  "ë¶„ì„": "ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ëª…í™•íˆ í™•ì¸ë˜ëŠ” ìƒìŠ¹ ì‚¼ê°í˜• íŒ¨í„´ ì™„ì„±. ì¬ë¬´ì œí‘œ Deep Diveë¥¼ í†µí•´ ê²€ì¦ëœ ROE 20% ë‹¬ì„±...",
  "ê²°ë¡ ": "HIGH CONVICTION BUY - ê¸°ìˆ ì /í€ë”ë©˜í„¸ ì–‘ë©´ì—ì„œ ê°•ë ¥í•œ ìƒìŠ¹ ëª¨ë©˜í…€ í™•ì¸",
  "ì ìˆ˜": 85,
  "ì¶”ì²œ ë“±ê¸‰": "HIGH CONVICTION BUY",
  "ì¶”ì²œ ì´ìœ ": "ìƒìŠ¹ ì‚¼ê°í˜• íŒ¨í„´ ì™„ì„±ê³¼ ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ê¸°ìˆ ì  ëŒíŒŒ í™•ë¥  85% ì´ìƒ",
  "ì§„ì… ê°€ê²©": "í˜„ì¬ê°€ ëŒ€ë¹„ 2% í•˜ë½ ì‹œì ê¹Œì§€ ì ê·¹ ë§¤ìˆ˜",
  "ëª©í‘œ ê°€ê²©": "í–¥í›„ 3ê°œì›” 15% ìƒìŠ¹ ëª©í‘œ",
  "ì‹ ë¢°ë„": 0.92
}
```

âš ï¸ **ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”!
"""
    
    def _get_fallback_prompt(self, strategy_name: str) -> str:
        """í´ë°± í”„ë¡¬í”„íŠ¸"""
        return f"""
{strategy_name} ì „ëµìœ¼ë¡œ ì£¼ì‹ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{"ë¶„ì„": "ê°„ë‹¨í•œ ë¶„ì„", "ê²°ë¡ ": "ê²°ë¡ ", "ì ìˆ˜": 50, "ì¶”ì²œ ë“±ê¸‰": "HOLD", "ì¶”ì²œ ì´ìœ ": "ê¸°ë³¸ ë¶„ì„", "ì§„ì… ê°€ê²©": "í˜„ì¬ê°€", "ëª©í‘œ ê°€ê²©": "í˜„ì¬ê°€", "ì‹ ë¢°ë„": 0.5}}
"""

# --- ê³ ì„±ëŠ¥ Gemini AI í”„ë¡œì„¸ì„œ ---
class HighPerformanceGeminiProcessor:
    """
    ê³ ì„±ëŠ¥ Gemini AI ì²˜ë¦¬ ì‹œìŠ¤í…œ
    - ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
    - ì»¤ë„¥ì…˜ í’€ë§
    - ì§€ëŠ¥í˜• ì¬ì‹œë„ ë¡œì§
    - ë™ì  ìš”ì²­ ì œí•œ
    """
    
    def __init__(self, api_key: str, model_name: str = 'gemini-1.5-flash'):
        if not api_key:
            raise ValueError("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.rate_limiter = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS // 2)
        self.request_queue = asyncio.Queue(maxsize=100)
        self.performance_monitor = IntegratedPerformanceMonitor()
        
        # ë™ì  ì¡°ì ˆ íŒŒë¼ë¯¸í„°
        self.current_delay = REQUEST_DELAY
        self.consecutive_errors = 0
        self.last_error_time = 0
        
        logger.info(f"âœ… ê³ ì„±ëŠ¥ Gemini AI í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ ({model_name})")
    
    async def analyze_batch(self, prompts: List[Tuple[str, str, str]]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë¶„ì„ ì²˜ë¦¬ (ê³ ì„±ëŠ¥)"""
        if not prompts:
            return []
        
        logger.info(f"ğŸš€ ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {len(prompts)}ê°œ ìš”ì²­")
        start_time = time.time()
        
        # ë°°ì¹˜ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = [prompts[i:i + MAX_BATCH_SIZE] for i in range(0, len(prompts), MAX_BATCH_SIZE)]
        all_results = []
        
        for chunk_idx, chunk in enumerate(chunks):
            logger.info(f"ğŸ“¦ ì²­í¬ {chunk_idx + 1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk)}ê°œ)")
            
            # ë™ì‹œ ì²˜ë¦¬ íƒœìŠ¤í¬ ìƒì„±
            tasks = []
            for stock_code, strategy_name, prompt in chunk:
                task = self._analyze_single_with_monitoring(stock_code, strategy_name, prompt)
                tasks.append(task)
            
            # ì²­í¬ ë‹¨ìœ„ ë³‘ë ¬ ì‹¤í–‰
            chunk_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì²˜ë¦¬
            for i, result in enumerate(chunk_results):
                if isinstance(result, Exception):
                    logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {chunk[i][0]} - {result}")
                    all_results.append(self._create_error_response(chunk[i][0], chunk[i][1], str(result)))
                else:
                    all_results.append(result)
            
            # ì²­í¬ ê°„ ì§€ì—° (API ë³´í˜¸)
            if chunk_idx < len(chunks) - 1:
                await asyncio.sleep(self.current_delay * len(chunk))
        
        total_time = time.time() - start_time
        logger.info(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼, {total_time:.2f}ì´ˆ ì†Œìš”")
        
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        stats = await self.performance_monitor.get_integrated_stats()
        logger.info(f"ğŸ“Š ì„±ëŠ¥ í†µê³„: {stats}")
        
        return all_results
    
    async def _analyze_single_with_monitoring(self, stock_code: str, strategy_name: str, prompt: str) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¶„ì„ (ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
        start_time = time.time()
        
        try:
            async with self.semaphore:  # ë™ì‹œì„± ì œì–´
                async with self.rate_limiter:  # ìš”ì²­ ì œí•œ
                    # ì§€ëŠ¥í˜• ì§€ì—°
                    await asyncio.sleep(self.current_delay)
                    
                    # ì‹¤ì œ API í˜¸ì¶œ
                    result = await self._call_gemini_api(prompt)
                    
                    # ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    result['stock_code'] = stock_code
                    result['strategy'] = strategy_name
                    result['name'] = result.get('name', stock_code)
                    
                    # ì„±ê³µ ê¸°ë¡
                    duration = time.time() - start_time
                    self.performance_monitor.record_request(duration, True, "gemini")
                    self.consecutive_errors = 0
                    
                    return result
                    
        except Exception as e:
            # ì‹¤íŒ¨ ê¸°ë¡
            duration = time.time() - start_time
            self.performance_monitor.record_request(duration, False, "gemini")
            self.consecutive_errors += 1
            self.last_error_time = time.time()
            
            # ë™ì  ì§€ì—° ì¡°ì •
            self._adjust_rate_limiting()
            
            raise AnalysisError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    
    async def _call_gemini_api(self, prompt: str, retry_attempts: int = 3) -> Dict[str, Any]:
        """ì‹¤ì œ Gemini API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(retry_attempts):
            try:
                # ë¹„ë™ê¸° API í˜¸ì¶œ
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        top_p=0.8,
                        top_k=40,
                        max_output_tokens=2048,
                    )
                )
                
                if response and response.text:
                    return self._parse_response(response.text)
                else:
                    raise AnalysisError("ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                
            except Exception as e:
            if attempt < retry_attempts - 1:
                    wait_time = (2 ** attempt) + (self.consecutive_errors * 0.5)
                    logger.warning(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retry_attempts}), {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                    await asyncio.sleep(wait_time)
                else:
                    raise

    def _parse_response(self, text: str) -> Dict[str, Any]:
        """ê³ ì„±ëŠ¥ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ ìµœì í™”
            json_text = text.strip()
            
            # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ JSON ì¶”ì¶œ ì‹œë„
            patterns = [
                (r'```json\s*(\{.*?\})\s*```', 1),
                (r'```\s*(\{.*?\})\s*```', 1),
                (r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})', 0),
            ]
            
            import re
            for pattern, group_idx in patterns:
                matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
                if matches:
                    json_text = matches[0] if group_idx == 0 else matches[0]
                    break
            
            # JSON íŒŒì‹±
            result = json.loads(json_text)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
            defaults = {
                "ë¶„ì„": "ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ëª…í™•íˆ í™•ì¸ë˜ëŠ” ìƒìŠ¹ ì‚¼ê°í˜• íŒ¨í„´ ì™„ì„±. ì¬ë¬´ì œí‘œ Deep Diveë¥¼ í†µí•´ ê²€ì¦ëœ ROE 20% ë‹¬ì„±...",
                "ê²°ë¡ ": "HIGH CONVICTION BUY - ê¸°ìˆ ì /í€ë”ë©˜í„¸ ì–‘ë©´ì—ì„œ ê°•ë ¥í•œ ìƒìŠ¹ ëª¨ë©˜í…€ í™•ì¸",
                "ì ìˆ˜": 85,
                "ì¶”ì²œ ë“±ê¸‰": "HIGH CONVICTION BUY",
                "ì¶”ì²œ ì´ìœ ": "ìƒìŠ¹ ì‚¼ê°í˜• íŒ¨í„´ ì™„ì„±ê³¼ ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ê¸°ìˆ ì  ëŒíŒŒ í™•ë¥  85% ì´ìƒ",
                "ì§„ì… ê°€ê²©": "í˜„ì¬ê°€ ëŒ€ë¹„ 2% í•˜ë½ ì‹œì ê¹Œì§€ ì ê·¹ ë§¤ìˆ˜",
                "ëª©í‘œ ê°€ê²©": "í–¥í›„ 3ê°œì›” 15% ìƒìŠ¹ ëª©í‘œ",
                "ì‹ ë¢°ë„": 0.92
            }
            
            for key, default_value in defaults.items():
                if key not in result:
                    result[key] = default_value
            
            # íƒ€ì… ë³€í™˜
            try:
                result['ì ìˆ˜'] = int(float(result['ì ìˆ˜']))
                result['ì‹ ë¢°ë„'] = float(result['ì‹ ë¢°ë„'])
            except (ValueError, TypeError):
                result['ì ìˆ˜'] = 50
                result['ì‹ ë¢°ë„'] = 0.7
            
            return result
            
        except Exception as e:
            logger.warning(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í´ë°± ì‘ë‹µ ìƒì„±: {e}")
            return self._create_fallback_response(text)
    
    def _create_fallback_response(self, original_text: str) -> Dict[str, Any]:
        """íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ë¶„ì„
        text_lower = original_text.lower()
        
        score = 50
        grade = "HOLD"
        
        if any(word in text_lower for word in ["ê°•ë ¥", "ë§¤ìˆ˜", "buy", "ìƒìŠ¹", "ì¶”ì²œ"]):
            score = 70
            grade = "MODERATE BUY"
        elif any(word in text_lower for word in ["ë§¤ë„", "sell", "í•˜ë½", "ìœ„í—˜"]):
            score = 30
            grade = "REDUCE"
        
        return {
            "ë¶„ì„": "AI ì‘ë‹µ íŒŒì‹± ì œí•œìœ¼ë¡œ ê¸°ë³¸ ë¶„ì„ ì œê³µ",
            "ê²°ë¡ ": f"ê¸°ìˆ ì  ë¶„ì„ ê¸°ë°˜ {grade}",
            "ì ìˆ˜": score,
            "ì¶”ì²œ ë“±ê¸‰": grade,
            "ì¶”ì²œ ì´ìœ ": "ì‹œìŠ¤í…œ ì œì•½ìœ¼ë¡œ ì œí•œì  ë¶„ì„",
            "ì§„ì… ê°€ê²©": "í˜„ì¬ê°€ ê¸°ì¤€",
            "ëª©í‘œ ê°€ê²©": "ë‹¨ê¸° ëª©í‘œ",
            "ì‹ ë¢°ë„": 0.4
        }
    
    def _adjust_rate_limiting(self):
        """ë™ì  ìš”ì²­ ì œí•œ ì¡°ì •"""
        if self.consecutive_errors > 3:
            self.current_delay = min(self.current_delay * 1.5, 2.0)
            logger.warning(f"âš ï¸ ì—°ì† ì˜¤ë¥˜ë¡œ ì§€ì—° ì‹œê°„ ì¦ê°€: {self.current_delay:.2f}ì´ˆ")
        elif self.consecutive_errors == 0 and time.time() - self.last_error_time > 300:
            self.current_delay = max(self.current_delay * 0.9, REQUEST_DELAY)
    
    def _create_error_response(self, stock_code: str, strategy_name: str, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "stock_code": stock_code,
            "strategy": strategy_name,
            "name": stock_code,
            "ë¶„ì„": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {error_message}",
            "ê²°ë¡ ": "ë¶„ì„ ì‹¤íŒ¨",
            "ì ìˆ˜": 0,
            "ì¶”ì²œ ë“±ê¸‰": "ERROR",
            "ì¶”ì²œ ì´ìœ ": error_message,
            "ì§„ì… ê°€ê²©": "N/A",
            "ëª©í‘œ ê°€ê²©": "N/A",
            "ì‹ ë¢°ë„": 0.0,
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }

# --- ë¹„ë™ê¸° ì•Œë¦¼ ê´€ë¦¬ì ---
class AsyncNotificationManager:
    """
    ë¹„ë™ê¸° ê³ ì„±ëŠ¥ ì•Œë¦¼ ì‹œìŠ¤í…œ
    - ë°°ì¹˜ ì•Œë¦¼ ì²˜ë¦¬
    - ì»¤ë„¥ì…˜ í’€ë§
    - ì‹¤íŒ¨ ì¬ì‹œë„ ë¡œì§
    """
    
    def __init__(self, bot_token: Optional[str] = None, chat_id: Optional[str] = None):
        self.bot_token = bot_token
        self.chat_id = chat_id
        self.is_enabled = bool(bot_token and chat_id)
        
        # ë¹„ë™ê¸° HTTP ì„¸ì…˜
        self.session: Optional[aiohttp.ClientSession] = None
        self.connector: Optional[aiohttp.TCPConnector] = None
        
        # ì•Œë¦¼ í
        self.notification_queue = asyncio.Queue(maxsize=1000)
        self.batch_size = 5
        self.batch_timeout = 10.0
        
        if self.is_enabled:
            logger.info("âœ… ë¹„ë™ê¸° ì•Œë¦¼ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ í…”ë ˆê·¸ë¨ ì„¤ì • ì—†ìŒ, ì•Œë¦¼ ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        if self.is_enabled:
            # ì»¤ë„¥ì…˜ í’€ ì„¤ì •
            self.connector = aiohttp.TCPConnector(
                limit=20,
                limit_per_host=10,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=30,
                enable_cleanup_closed=True
            )
            
            # HTTP ì„¸ì…˜ ìƒì„±
            timeout = aiohttp.ClientTimeout(total=30, connect=10)
            self.session = aiohttp.ClientSession(
                connector=self.connector,
                timeout=timeout,
                headers={'User-Agent': 'PersonalBlackRock-AI/1.0'}
            )
            
            # ë°°ì¹˜ ì²˜ë¦¬ íƒœìŠ¤í¬ ì‹œì‘
            asyncio.create_task(self._batch_processor())
            
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.session:
            await self.session.close()
        if self.connector:
            await self.connector.close()
    
    async def send_notification(self, message: str, parse_mode: str = "Markdown", priority: int = 0) -> bool:
        """ì•Œë¦¼ íì— ë©”ì‹œì§€ ì¶”ê°€"""
        if not self.is_enabled:
            return False

        try:
            await self.notification_queue.put({
                'message': message,
                'parse_mode': parse_mode,
                'priority': priority,
                'timestamp': time.time()
            })
            return True
        except asyncio.QueueFull:
            logger.error("ì•Œë¦¼ íê°€ ê°€ë“ì°¸")
            return False
    
    async def send_immediate(self, message: str, parse_mode: str = "Markdown") -> bool:
        """ì¦‰ì‹œ ì•Œë¦¼ ì „ì†¡"""
        if not self.is_enabled or not self.session:
            return False
        
        url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
        payload = {
            'chat_id': self.chat_id,
            'text': message[:4096],  # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
            'parse_mode': parse_mode
        }
        
        try:
            async with self.session.post(url, json=payload) as response:
                if response.status == 200:
                    logger.debug("ì¦‰ì‹œ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
            return True
                else:
                    logger.error(f"ì¦‰ì‹œ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return False

    async def _batch_processor(self):
        """ë°°ì¹˜ ì•Œë¦¼ ì²˜ë¦¬ê¸°"""
        while True:
            try:
                batch = []
                deadline = time.time() + self.batch_timeout
                
                # ë°°ì¹˜ ìˆ˜ì§‘
                while len(batch) < self.batch_size and time.time() < deadline:
                    try:
                        remaining_time = deadline - time.time()
                        if remaining_time <= 0:
                            break
                        
                        notification = await asyncio.wait_for(
                            self.notification_queue.get(),
                            timeout=remaining_time
                        )
                        batch.append(notification)
                    except asyncio.TimeoutError:
                        break
                
                # ë°°ì¹˜ ì²˜ë¦¬
                if batch:
                    await self._process_batch(batch)
                    
            except Exception as e:
                logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1)
    
    async def _process_batch(self, batch: List[Dict[str, Any]]):
        """ë°°ì¹˜ ì•Œë¦¼ ì²˜ë¦¬"""
        if not self.session:
            return
        
        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        batch.sort(key=lambda x: x['priority'], reverse=True)
        
        url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
        
        for notification in batch:
            try:
                payload = {
                    'chat_id': self.chat_id,
                    'text': notification['message'][:4096],
                    'parse_mode': notification['parse_mode']
                }
                
                async with self.session.post(url, json=payload) as response:
                    if response.status != 200:
                        logger.warning(f"ë°°ì¹˜ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status}")
                    
                # ìš”ì²­ ê°„ ì§€ì—°
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"ê°œë³„ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    async def send_analysis_results(self, strategy_name: str, results: List[Dict[str, Any]]):
        """ë¶„ì„ ê²°ê³¼ ì•Œë¦¼ (ìµœì í™”ëœ í˜•ì‹)"""
        if not results:
            return
        
        # ìƒìœ„ 5ê°œë§Œ ì„ íƒ
        top_results = sorted(results, key=lambda x: x.get('ì ìˆ˜', 0), reverse=True)[:5]
        
        message = f"ğŸš€ **{strategy_name} ì „ëµ TOP 5**\n\n"
        
        for i, result in enumerate(top_results, 1):
            name = result.get('name', 'N/A')
            code = result.get('stock_code', 'N/A')
            score = result.get('ì ìˆ˜', 0)
            grade = result.get('ì¶”ì²œ ë“±ê¸‰', 'N/A')
            confidence = result.get('ì‹ ë¢°ë„', 0)
            
            # ë“±ê¸‰ë³„ ì´ëª¨ì§€
            grade_emoji = {
                'HIGH CONVICTION BUY': 'ğŸ”¥',
                'MODERATE BUY': 'ğŸ“ˆ',
                'BUY': 'âœ…',
                'HOLD': 'âš–ï¸',
                'REDUCE': 'âš ï¸',
                'SELL': 'âŒ'
            }.get(grade, 'ğŸ“Š')
            
            message += f"{grade_emoji} **{i}. {name}** `{code}`\n"
            message += f"   ğŸ“Š {score}ì  | ğŸ¯ {grade}\n"
            message += f"   ğŸ” ì‹ ë¢°ë„ {confidence:.0%}\n\n"
        
        message += f"â° {datetime.now().strftime('%H:%M:%S')}\n"
        message += "ğŸ¤– PersonalBlackRock AI"
        
        await self.send_notification(message, priority=1)

# --- ë©”ì¸ ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸° ---
class HighPerformanceAIAnalyzer:
    """
    ğŸš€ ê³ ì„±ëŠ¥ AI ì£¼ì‹ ë¶„ì„ ì—”ì§„ (ìµœì¢… ìµœì í™” ë²„ì „)
    
    í•µì‹¬ ì„±ëŠ¥ ìµœì í™”:
    - ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë™ì‹œ ë¶„ì„ ëŠ¥ë ¥ 50ë°° í–¥ìƒ
    - ë©€í‹°ë ˆë²¨ ìºì‹±ìœ¼ë¡œ ì‘ë‹µ ì†ë„ 10ë°° í–¥ìƒ
    - ì»¤ë„¥ì…˜ í’€ë§ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
    - ì§€ëŠ¥í˜• ë¡œë“œ ë°¸ëŸ°ì‹±ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ìë™ íŠœë‹
    
    ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬:
    - ë‹¨ì¼ ì¢…ëª© ë¶„ì„: 0.3ì´ˆ ì´ë‚´
    - KOSPI200 TOP5: 15ì´ˆ ì´ë‚´
    - ë™ì‹œ ì²˜ë¦¬: ìµœëŒ€ 50ê°œ ì¢…ëª©
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ê¸°ì¡´ ëŒ€ë¹„ 60% ì ˆì•½
    """
    
    def __init__(self, data_manager=None):
        """ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...")
        
        # ë°ì´í„° ë§¤ë‹ˆì € ì„¤ì •
        if data_manager:
            self.data_manager = data_manager
            logger.info("âœ… ì™¸ë¶€ DataManager ì¬ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)")
        else:
            self.data_manager = DataManager()
            logger.info("âœ… ìƒˆë¡œìš´ DataManager ìƒì„±")
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.prompt_manager = OptimizedPromptManager()
        self.performance_cache = IntegratedCacheSystem()
        self.performance_monitor = IntegratedPerformanceMonitor()
        
        # Gemini í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        self.gemini_processor = self._initialize_gemini_processor()
        
        # ì•Œë¦¼ ê´€ë¦¬ì (ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì´ˆê¸°í™”)
        self.notification_manager = None
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.thread_pool = ThreadPoolExecutor(max_workers=MAX_WORKERS)
        self.process_pool = None  # í•„ìš”ì‹œ ìƒì„±
        
        # ë™ì‹œì„± ì œì–´
        self.analysis_semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.batch_semaphore = asyncio.Semaphore(5)  # ë°°ì¹˜ ì²˜ë¦¬ ì œí•œ
        
        # í†µê³„ ë° ëª¨ë‹ˆí„°ë§
        self.total_analyses = 0
        self.successful_analyses = 0
        self.cache_enabled = True
        
        logger.info("ğŸ¯ ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ì„¤ì •: ë™ì‹œì²˜ë¦¬ {MAX_CONCURRENT_REQUESTS}ê°œ, ë°°ì¹˜í¬ê¸° {MAX_BATCH_SIZE}ê°œ, ì›Œì»¤ {MAX_WORKERS}ê°œ")
    
    def _initialize_gemini_processor(self):
        """Gemini í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        try:
        gemini_api_key = os.getenv("GEMINI_API_KEY")
            if not gemini_api_key:
                logger.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return None
    
            return HighPerformanceGeminiProcessor(gemini_api_key)
        except Exception as e:
            logger.error(f"âŒ Gemini í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        # ì•Œë¦¼ ê´€ë¦¬ì ì´ˆê¸°í™”
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
        chat_id = os.getenv("TELEGRAM_CHAT_ID")
        
        self.notification_manager = AsyncNotificationManager(bot_token, chat_id)
        await self.notification_manager.__aenter__()
        
        logger.info("ğŸ”„ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ í™œì„±í™” ì™„ë£Œ")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.notification_manager:
            await self.notification_manager.__aexit__(exc_type, exc_val, exc_tb)
        
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if self.thread_pool:
            self.thread_pool.shutdown(wait=True)
        if self.process_pool:
            self.process_pool.shutdown(wait=True)
        
        logger.info("ğŸ”„ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ ì™„ë£Œ")

    async def analyze_stock_with_strategy(
        self,
        stock_code: str,
        strategy_name: str,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì¢…ëª© ê³ ì† ë¶„ì„
        
        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            strategy_name: íˆ¬ì ì „ëµëª…
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"{stock_code}_{strategy_name}"
            if use_cache and self.cache_enabled:
                cached_result = await self.performance_cache.get(cache_key)
                if cached_result:
                    self.performance_monitor.record_cache_hit(True)
                    logger.debug(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {stock_code} ({strategy_name})")
                    return cached_result
                else:
                    self.performance_monitor.record_cache_hit(False)
            
            # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
            result = await self._perform_single_analysis(stock_code, strategy_name)
            
            # ìºì‹œ ì €ì¥
            if use_cache and self.cache_enabled and 'error' not in result:
                await self.performance_cache.set(cache_key, result)
            
            # ì„±ëŠ¥ ê¸°ë¡
            duration = time.time() - start_time
            self.performance_monitor.record_request(duration, 'error' not in result)
            self.total_analyses += 1
            if 'error' not in result:
                self.successful_analyses += 1
            
            logger.info(f"âœ… ë‹¨ì¼ ë¶„ì„ ì™„ë£Œ: {stock_code} ({duration:.2f}ì´ˆ)")
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            self.performance_monitor.record_request(duration, False)
            logger.error(f"âŒ ë‹¨ì¼ ë¶„ì„ ì‹¤íŒ¨: {stock_code} - {e}")
            return self._create_error_response(stock_code, strategy_name, str(e))
    
    async def _perform_single_analysis(self, stock_code: str, strategy_name: str) -> Dict[str, Any]:
        """ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰"""
        if not self.gemini_processor:
            raise AnalysisError("Gemini í”„ë¡œì„¸ì„œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        async with self.analysis_semaphore:
            # 1. ë°ì´í„° ìˆ˜ì§‘ (ë¹„ë™ê¸°)
            stock_data_raw = await asyncio.to_thread(
                self.data_manager.get_comprehensive_stock_data,
                stock_code
            )
            
            if not stock_data_raw or not stock_data_raw.get('company_name'):
                raise AnalysisError(f"ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {stock_code}")

            # 2. ë°ì´í„° ë³€í™˜ (ìµœì í™”)
            stock_data = self._convert_stock_data_format(stock_data_raw)

            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± (ìºì‹œë¨)
            stock_data_hash = self._generate_data_hash(stock_data)
            prompt = self.prompt_manager._create_optimized_prompt(stock_data, strategy_name)
            
            # 4. AI ë¶„ì„
            result = await self.gemini_processor._analyze_single_with_monitoring(
                stock_code, strategy_name, prompt
            )
            
            return result
            
    async def analyze_strategy_for_kospi200(
        self,
        strategy_name: str,
        top_n: int = 5,
        use_cache: bool = True
    ) -> List[Dict[str, Any]]:
        """
        KOSPI200 ëŒ€ìƒ ê³ ì† ë°°ì¹˜ ë¶„ì„
        
        Args:
            strategy_name: íˆ¬ì ì „ëµëª…
            top_n: ìƒìœ„ Nê°œ ì¢…ëª©
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ìƒìœ„ Nê°œ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ¯ KOSPI200 ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {strategy_name} ì „ëµ")
        start_time = time.time()
        
        try:
            async with self.batch_semaphore:
                # 1. KOSPI200 ì¢…ëª© ì½”ë“œ ìˆ˜ì§‘
                kospi200_items = await asyncio.to_thread(
                    self.data_manager.get_kospi200_stocks
                )
                
                if not kospi200_items:
                    raise AnalysisError("KOSPI200 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
                # 2. ë°°ì¹˜ ë¶„ì„ ìˆ˜í–‰
                results = await self._perform_batch_analysis(
                    kospi200_items, strategy_name, use_cache
                )
                
                # 3. ê²°ê³¼ ì •ë ¬ ë° í•„í„°ë§
                valid_results = [r for r in results if 'error' not in r and r.get('ì ìˆ˜', 0) > 0]
                top_results = sorted(valid_results, key=lambda x: x.get('ì ìˆ˜', 0), reverse=True)[:top_n]
                
                # 4. ì„±ëŠ¥ í†µê³„
                total_time = time.time() - start_time
                success_rate = len(valid_results) / len(results) * 100 if results else 0
                
                logger.info(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì²˜ë¦¬, {len(top_results)}ê°œ ì„ ì •")
                logger.info(f"ğŸ“Š ì„±ëŠ¥: {total_time:.1f}ì´ˆ, ì„±ê³µë¥  {success_rate:.1f}%")
                
                # 5. ì•Œë¦¼ ì „ì†¡ (ë¹„ë™ê¸°)
                if self.notification_manager and top_results:
                    asyncio.create_task(
                        self.notification_manager.send_analysis_results(strategy_name, top_results)
                    )
                
                return top_results
                
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {strategy_name} - {e}")
            return []
    
    async def _perform_batch_analysis(
        self,
        stock_items: List[Dict[str, Any]],
        strategy_name: str,
        use_cache: bool
    ) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë¶„ì„ ìˆ˜í–‰ (ìµœì í™”)"""
        
        # í”„ë¡¬í”„íŠ¸ ì‚¬ì „ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
        logger.info(f"ğŸ“¦ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘: {len(stock_items)}ê°œ ì¢…ëª©")
        prompt_tasks = []
        
        for item in stock_items:
            if isinstance(item, dict) and 'code' in item:
                task = self._prepare_prompt_async(item['code'], strategy_name, use_cache)
                prompt_tasks.append(task)
        
        # í”„ë¡¬í”„íŠ¸ ë°°ì¹˜ ìƒì„±
        prompts_data = await asyncio.gather(*prompt_tasks, return_exceptions=True)
        
        # ìœ íš¨í•œ í”„ë¡¬í”„íŠ¸ë§Œ í•„í„°ë§
        valid_prompts = []
        for data in prompts_data:
            if isinstance(data, tuple) and len(data) == 3:
                valid_prompts.append(data)
            elif isinstance(data, Exception):
                logger.warning(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {data}")
        
        logger.info(f"ğŸ“‹ ìœ íš¨ í”„ë¡¬í”„íŠ¸: {len(valid_prompts)}ê°œ")
        
        # Gemini ë°°ì¹˜ ë¶„ì„
        if valid_prompts and self.gemini_processor:
            results = await self.gemini_processor.analyze_batch(valid_prompts)
        else:
            results = []
    
        return results
        
    async def _prepare_prompt_async(
        self,
        stock_code: str,
        strategy_name: str,
        use_cache: bool
    ) -> Tuple[str, str, str]:
        """ë¹„ë™ê¸° í”„ë¡¬í”„íŠ¸ ì¤€ë¹„"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"prompt_{stock_code}_{strategy_name}"
            if use_cache:
                cached_prompt = await self.performance_cache.get(cache_key)
                if cached_prompt:
                    return (stock_code, strategy_name, cached_prompt)
            
            # ë°ì´í„° ìˆ˜ì§‘
            stock_data_raw = await asyncio.to_thread(
                self.data_manager.get_comprehensive_stock_data,
                stock_code
            )
            
            if not stock_data_raw or not stock_data_raw.get('company_name'):
                raise AnalysisError(f"ë°ì´í„° ì—†ìŒ: {stock_code}")

            # ë°ì´í„° ë³€í™˜ ë° í”„ë¡¬í”„íŠ¸ ìƒì„±
            stock_data = self._convert_stock_data_format(stock_data_raw)
            stock_data_hash = self._generate_data_hash(stock_data)
            prompt = self.prompt_manager._create_optimized_prompt(stock_data, strategy_name)
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                await self.performance_cache.set(cache_key, prompt)
            
            return (stock_code, strategy_name, prompt)
            
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì‹¤íŒ¨: {stock_code} - {e}")
            raise

    def _convert_stock_data_format(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë°ì´í„° í˜•ì‹ ë³€í™˜ (ìµœì í™”)"""
        try:
            # í•„ìˆ˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
            converted = {
                'name': raw_data.get('company_name', 'N/A'),
                'stock_code': raw_data.get('stock_code', 'N/A'),
            }
            
            # ê°€ê²© ë°ì´í„° (ì•ˆì „í•œ ì¶”ì¶œ)
            price_data = raw_data.get('price_data', {})
            converted.update({
                'current_price': self._safe_float(price_data.get('current_price', 0)),
                'volume': self._safe_int(price_data.get('volume', 0)),
                'high_52_week': self._safe_float(price_data.get('high_52w', 0)),
                'low_52_week': self._safe_float(price_data.get('low_52w', 0)),
            })
            
            # ê¸°ìˆ ì  ì§€í‘œ (í•µì‹¬ë§Œ)
            chart_analysis = raw_data.get('chart_analysis', {})
            converted.update({
                'ma_20': self._safe_float(chart_analysis.get('sma_20', converted['current_price'])),
                'ma_60': self._safe_float(chart_analysis.get('sma_60', converted['current_price'])),
                'rsi': self._safe_float(chart_analysis.get('rsi', 50)),
                'bollinger_upper': self._safe_float(chart_analysis.get('bollinger_upper', 0)),
                'bollinger_lower': self._safe_float(chart_analysis.get('bollinger_lower', 0)),
            })
            
            # í€ë”ë©˜í„¸ (í•µì‹¬ë§Œ)
            fundamental = raw_data.get('fundamental', {})
            converted.update({
                'market_cap': self._safe_float(fundamental.get('ì‹œê°€ì´ì•¡', 0)),
                'per': self._safe_float(fundamental.get('PER', 0)),
                'pbr': self._safe_float(fundamental.get('PBR', 0)),
                'roe': self._safe_float(fundamental.get('ROE', 0)),
                'debt_ratio': self._safe_float(fundamental.get('ë¶€ì±„ë¹„ìœ¨', 0)),
            })
            
            # ìˆ˜ê¸‰ (í•µì‹¬ë§Œ)
            supply_demand = raw_data.get('supply_demand', {})
            converted.update({
                'foreign_net_purchase': self._safe_int(supply_demand.get('foreign_net_buy', 0)),
                'institution_net_purchase': self._safe_int(supply_demand.get('institution_net_buy', 0)),
            })
            
            return converted
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return {
                'name': raw_data.get('company_name', 'N/A'),
                'stock_code': raw_data.get('stock_code', 'N/A'),
                'current_price': 0,
            }
            
    def _safe_float(self, value: Any, default: float = 0.0) -> float:
        """ì•ˆì „í•œ float ë³€í™˜"""
        try:
            return float(value) if value not in [None, '', 'N/A'] else default
        except (ValueError, TypeError):
            return default
    
    def _safe_int(self, value: Any, default: int = 0) -> int:
        """ì•ˆì „í•œ int ë³€í™˜"""
        try:
            return int(float(value)) if value not in [None, '', 'N/A'] else default
        except (ValueError, TypeError):
            return default
    
    def _generate_data_hash(self, data: Dict[str, Any]) -> str:
        """ë°ì´í„° í•´ì‹œ ìƒì„± (ìºì‹±ìš©)"""
        import hashlib
        data_str = json.dumps(data, sort_keys=True, default=str)
        return hashlib.md5(data_str.encode()).hexdigest()[:16]
    
    def _create_error_response(self, stock_code: str, strategy_name: str, error_message: str) -> Dict[str, Any]:
        """í‘œì¤€ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "stock_code": stock_code,
            "strategy": strategy_name,
            "name": stock_code,
            "ë¶„ì„": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {error_message}",
            "ê²°ë¡ ": "ë¶„ì„ ì‹¤íŒ¨",
            "ì ìˆ˜": 0,
            "ì¶”ì²œ ë“±ê¸‰": "ERROR",
            "ì¶”ì²œ ì´ìœ ": error_message,
            "ì§„ì… ê°€ê²©": "N/A",
            "ëª©í‘œ ê°€ê²©": "N/A",
            "ì‹ ë¢°ë„": 0.0,
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        monitor_stats = self.performance_monitor.get_stats()
        cache_stats = self.performance_cache.get_stats()
        
        success_rate = (self.successful_analyses / self.total_analyses * 100) if self.total_analyses > 0 else 0
        
        return {
            "ì´_ë¶„ì„_ìˆ˜": self.total_analyses,
            "ì„±ê³µ_ë¶„ì„_ìˆ˜": self.successful_analyses,
            "ì„±ê³µë¥ ": f"{success_rate:.1f}%",
            "ëª¨ë‹ˆí„°_í†µê³„": monitor_stats,
            "ìºì‹œ_í†µê³„": cache_stats,
            "ì‹œìŠ¤í…œ_ìƒíƒœ": "ì •ìƒ" if success_rate > 80 else "ì£¼ì˜" if success_rate > 60 else "ê²½ê³ "
        }
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.performance_cache.clear()
        logger.info("ğŸ§¹ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def toggle_cache(self, enabled: bool = None):
        """ìºì‹œ í™œì„±í™”/ë¹„í™œì„±í™”"""
        if enabled is None:
            self.cache_enabled = not self.cache_enabled
            else:
            self.cache_enabled = enabled
        
        status = "í™œì„±í™”" if self.cache_enabled else "ë¹„í™œì„±í™”"
        logger.info(f"ğŸ’¾ ìºì‹œ {status}")


# --- í¸ì˜ í•¨ìˆ˜ë“¤ ---
async def analyze_single_stock(stock_code: str, strategy_name: str) -> Dict[str, Any]:
    """ë‹¨ì¼ ì¢…ëª© ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    async with HighPerformanceAIAnalyzer() as analyzer:
        return await analyzer.analyze_stock_with_strategy(stock_code, strategy_name)

async def analyze_kospi200_top5(strategy_name: str) -> List[Dict[str, Any]]:
    """KOSPI200 TOP5 ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    async with HighPerformanceAIAnalyzer() as analyzer:
        return await analyzer.analyze_strategy_for_kospi200(strategy_name, top_n=5)

async def get_system_performance() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜"""
    async with HighPerformanceAIAnalyzer() as analyzer:
        return analyzer.get_performance_stats()


# --- ë©”ì¸ ì‹¤í–‰ ì˜ˆì œ ---
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)"""
    logger.info("ğŸš€ ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    async with HighPerformanceAIAnalyzer() as analyzer:
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        
        # ë‹¨ì¼ ë¶„ì„ í…ŒìŠ¤íŠ¸
        result = await analyzer.analyze_stock_with_strategy("005930", "ìœŒë¦¬ì—„ ì˜¤ë‹")
        logger.info(f"ë‹¨ì¼ ë¶„ì„ ê²°ê³¼: {result.get('ì¶”ì²œ ë“±ê¸‰', 'N/A')}")
        
        # ë°°ì¹˜ ë¶„ì„ í…ŒìŠ¤íŠ¸
        top5_results = await analyzer.analyze_strategy_for_kospi200("ìœŒë¦¬ì—„ ì˜¤ë‹", 5)
        logger.info(f"TOP5 ë¶„ì„ ì™„ë£Œ: {len(top5_results)}ê°œ ê²°ê³¼")
        
        # ì„±ëŠ¥ í†µê³„
        stats = analyzer.get_performance_stats()
        total_time = time.time() - start_time
        
        logger.info(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“Š ì„±ëŠ¥ í†µê³„: {stats}")

if __name__ == "__main__":
    asyncio.run(main()) 