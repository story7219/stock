"""
AI ê¸°ë°˜ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ë° ë¦¬íŒ©í† ë§ ê³„íš ìƒì„±
"""

import os
import ast
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
import google.generativeai as genai

@dataclass
class ModuleAnalysis:
    """ëª¨ë“ˆ ë¶„ì„ ê²°ê³¼"""
    file_path: str
    lines_of_code: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    responsibilities: List[str]
    coupling_score: float
    cohesion_score: float

class CodeStructureAnalyzer:
    """ì½”ë“œ êµ¬ì¡° ë¶„ì„ê¸°"""
    
    def __init__(self):
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.model = genai.GenerativeModel('gemini-1.5-pro')
        self.modules = []
        self.restructure_plan = {}
    
    def analyze_project_structure(self) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ì „ì²´ êµ¬ì¡° ë¶„ì„"""
        python_files = list(Path('.').rglob('*.py'))
        python_files = [f for f in python_files if not str(f).startswith('.git')]
        
        analysis_results = {
            'total_files': len(python_files),
            'modules': [],
            'structure_issues': [],
            'recommendations': [],
            'metrics': {}
        }
        
        # ê° íŒŒì¼ ë¶„ì„
        for file_path in python_files:
            module_analysis = self.analyze_module(str(file_path))
            if module_analysis:
                analysis_results['modules'].append(module_analysis.__dict__)
                self.modules.append(module_analysis)
        
        # êµ¬ì¡°ì  ë¬¸ì œ íƒì§€
        structure_issues = self.detect_structure_issues()
        analysis_results['structure_issues'] = structure_issues
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = self.calculate_structure_metrics()
        analysis_results['metrics'] = metrics
        
        return analysis_results
    
    def analyze_module(self, file_path: str) -> ModuleAnalysis:
        """ê°œë³„ ëª¨ë“ˆ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, ast.Import):
                    imports.extend([alias.name for alias in node.names])
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
            
            # ì±…ì„ ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)
            responsibilities = self.analyze_responsibilities(content, functions, classes)
            
            # ê²°í•©ë„/ì‘ì§‘ë„ ê³„ì‚°
            coupling_score = self.calculate_coupling(imports, len(functions) + len(classes))
            cohesion_score = self.calculate_cohesion(functions, classes, content)
            
            return ModuleAnalysis(
                file_path=file_path,
                lines_of_code=len(content.split('\n')),
                functions=functions,
                classes=classes,
                imports=imports,
                responsibilities=responsibilities,
                coupling_score=coupling_score,
                cohesion_score=cohesion_score
            )
            
        except Exception as e:
            print(f"âŒ ëª¨ë“ˆ ë¶„ì„ ì‹¤íŒ¨ ({file_path}): {e}")
            return None
    
    def analyze_responsibilities(self, content: str, functions: List[str], classes: List[str]) -> List[str]:
        """ëª¨ë“ˆì˜ ì±…ì„ ë¶„ì„"""
        responsibilities = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì±…ì„ ë¶„ë¥˜
        responsibility_keywords = {
            'trading_strategy': ['strategy', 'signal', 'indicator', 'analysis', 'fibonacci', 'scout'],
            'data_collection': ['data', 'fetch', 'download', 'api', 'websocket', 'price'],
            'order_execution': ['order', 'buy', 'sell', 'execute', 'trade', 'position'],
            'portfolio_management': ['portfolio', 'balance', 'asset', 'allocation', 'risk'],
            'logging_monitoring': ['log', 'monitor', 'alert', 'notification', 'telegram'],
            'configuration': ['config', 'setting', 'env', 'parameter'],
            'utility': ['util', 'helper', 'common', 'tool']
        }
        
        content_lower = content.lower()
        all_names = functions + classes
        
        for responsibility, keywords in responsibility_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                responsibilities.append(responsibility)
            
            # í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ì—ì„œë„ ì²´í¬
            if any(any(keyword in name.lower() for keyword in keywords) for name in all_names):
                if responsibility not in responsibilities:
                    responsibilities.append(responsibility)
        
        return responsibilities if responsibilities else ['unknown']
    
    def calculate_coupling(self, imports: List[str], total_entities: int) -> float:
        """ê²°í•©ë„ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
        if total_entities == 0:
            return 0.0
        
        external_imports = len([imp for imp in imports if not imp.startswith('.')])
        return min(1.0, external_imports / max(1, total_entities))
    
    def calculate_cohesion(self, functions: List[str], classes: List[str], content: str) -> float:
        """ì‘ì§‘ë„ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
        if not functions and not classes:
            return 0.0
        
        # ê°„ë‹¨í•œ ì‘ì§‘ë„ ê³„ì‚°: ê³µí†µ í‚¤ì›Œë“œ ë¹„ìœ¨
        all_names = functions + classes
        if not all_names:
            return 0.0
        
        # ê°€ì¥ ë¹ˆë²ˆí•œ í‚¤ì›Œë“œ ì°¾ê¸°
        keywords = {}
        for name in all_names:
            words = name.lower().split('_')
            for word in words:
                keywords[word] = keywords.get(word, 0) + 1
        
        if not keywords:
            return 0.0
        
        max_frequency = max(keywords.values())
        cohesion = max_frequency / len(all_names)
        
        return min(1.0, cohesion)
    
    def detect_structure_issues(self) -> List[Dict[str, Any]]:
        """êµ¬ì¡°ì  ë¬¸ì œ íƒì§€"""
        issues = []
        
        # 1. ê±°ëŒ€í•œ íŒŒì¼ íƒì§€
        for module in self.modules:
            if module.lines_of_code > 500:
                issues.append({
                    'type': 'large_file',
                    'severity': 'high',
                    'file': module.file_path,
                    'description': f"íŒŒì¼ì´ {module.lines_of_code}ì¤„ë¡œ ë„ˆë¬´ í½ë‹ˆë‹¤.",
                    'suggestion': "ê¸°ëŠ¥ë³„ë¡œ ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”."
                })
        
        # 2. ë‹¤ì¤‘ ì±…ì„ ëª¨ë“ˆ íƒì§€
        for module in self.modules:
            if len(module.responsibilities) > 3:
                issues.append({
                    'type': 'multiple_responsibilities',
                    'severity': 'medium',
                    'file': module.file_path,
                    'description': f"ëª¨ë“ˆì´ {len(module.responsibilities)}ê°œì˜ ì±…ì„ì„ ê°€ì§‘ë‹ˆë‹¤.",
                    'responsibilities': module.responsibilities,
                    'suggestion': "ë‹¨ì¼ ì±…ì„ ì›ì¹™ì— ë”°ë¼ ëª¨ë“ˆì„ ë¶„ë¦¬í•˜ì„¸ìš”."
                })
        
        # 3. ë†’ì€ ê²°í•©ë„ íƒì§€
        for module in self.modules:
            if module.coupling_score > 0.7:
                issues.append({
                    'type': 'high_coupling',
                    'severity': 'medium',
                    'file': module.file_path,
                    'description': f"ê²°í•©ë„ê°€ {module.coupling_score:.2f}ë¡œ ë†’ìŠµë‹ˆë‹¤.",
                    'suggestion': "ì˜ì¡´ì„±ì„ ì¤„ì´ê³  ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ëŠìŠ¨í•œ ê²°í•©ì„ ê³ ë ¤í•˜ì„¸ìš”."
                })
        
        # 4. ë‚®ì€ ì‘ì§‘ë„ íƒì§€
        for module in self.modules:
            if module.cohesion_score < 0.3:
                issues.append({
                    'type': 'low_cohesion',
                    'severity': 'medium',
                    'file': module.file_path,
                    'description': f"ì‘ì§‘ë„ê°€ {module.cohesion_score:.2f}ë¡œ ë‚®ìŠµë‹ˆë‹¤.",
                    'suggestion': "ê´€ë ¨ëœ ê¸°ëŠ¥ë“¤ì„ í•¨ê»˜ ê·¸ë£¹í™”í•˜ì„¸ìš”."
                })
        
        return issues
    
    def calculate_structure_metrics(self) -> Dict[str, float]:
        """êµ¬ì¡° ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.modules:
            return {}
        
        total_loc = sum(m.lines_of_code for m in self.modules)
        avg_coupling = sum(m.coupling_score for m in self.modules) / len(self.modules)
        avg_cohesion = sum(m.cohesion_score for m in self.modules) / len(self.modules)
        
        # ì±…ì„ ë¶„ì‚°ë„ ê³„ì‚°
        all_responsibilities = []
        for module in self.modules:
            all_responsibilities.extend(module.responsibilities)
        
        unique_responsibilities = set(all_responsibilities)
        responsibility_distribution = len(unique_responsibilities) / len(self.modules) if self.modules else 0
        
        return {
            'total_lines_of_code': total_loc,
            'average_file_size': total_loc / len(self.modules),
            'average_coupling': avg_coupling,
            'average_cohesion': avg_cohesion,
            'responsibility_distribution': responsibility_distribution,
            'modularity_score': (avg_cohesion - avg_coupling + 1) / 2  # 0-1 ìŠ¤ì¼€ì¼
        }
    
    async def generate_restructure_plan(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """AIë¥¼ í†µí•œ ë¦¬íŒ©í† ë§ ê³„íš ìƒì„±"""
        
        prompt = f"""
ë‹¤ìŒì€ Python ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì˜ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

{json.dumps(analysis_results, ensure_ascii=False, indent=2)}

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ë³„ ëª¨ë“ˆ êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”:

## ëª©í‘œ êµ¬ì¡°:
1. **strategies/** - ë§¤ë§¤ ì „ëµ ëª¨ë“ˆ
   - scout_strategy.py (ì²™í›„ë³‘ ì „ëµ)
   - fibonacci_strategy.py (í”¼ë³´ë‚˜ì¹˜ ì „ëµ)
   - technical_analyzer.py (ê¸°ìˆ ì  ë¶„ì„)

2. **data/** - ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬
   - market_data_collector.py (ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘)
   - websocket_manager.py (ì‹¤ì‹œê°„ ë°ì´í„°)
   - data_validator.py (ë°ì´í„° ê²€ì¦)

3. **trading/** - ì£¼ë¬¸ ì‹¤í–‰ ë° í¬íŠ¸í´ë¦¬ì˜¤
   - order_executor.py (ì£¼ë¬¸ ì‹¤í–‰)
   - portfolio_manager.py (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬)
   - risk_manager.py (ë¦¬ìŠ¤í¬ ê´€ë¦¬)

4. **monitoring/** - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
   - logger.py (ë¡œê¹… ì‹œìŠ¤í…œ)
   - telegram_notifier.py (ì•Œë¦¼)
   - performance_monitor.py (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)

5. **core/** - í•µì‹¬ ì‹œìŠ¤í…œ
   - trader.py (ë©”ì¸ íŠ¸ë ˆì´ë”)
   - config.py (ì„¤ì • ê´€ë¦¬)
   - exceptions.py (ì˜ˆì™¸ ì²˜ë¦¬)

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¦¬íŒ©í† ë§ ê³„íšì„ ì œì‹œí•´ì£¼ì„¸ìš”:

```json
{{
  "restructure_needed": true/false,
  "target_structure": {{
    "í´ë”ëª…/íŒŒì¼ëª…": {{
      "description": "íŒŒì¼ ì„¤ëª…",
      "responsibilities": ["ì±…ì„1", "ì±…ì„2"],
      "source_files": ["í˜„ì¬_íŒŒì¼1.py", "í˜„ì¬_íŒŒì¼2.py"],
      "functions_to_move": ["í•¨ìˆ˜ëª…1", "í•¨ìˆ˜ëª…2"],
      "classes_to_move": ["í´ë˜ìŠ¤ëª…1", "í´ë˜ìŠ¤ëª…2"],
      "interfaces": ["ì œê³µí• _ì¸í„°í˜ì´ìŠ¤1", "ì œê³µí• _ì¸í„°í˜ì´ìŠ¤2"]
    }}
  }},
  "migration_steps": [
    "ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš"
  ],
  "benefits": [
    "ì˜ˆìƒë˜ëŠ” ê°œì„  íš¨ê³¼"
  ]
}}
```

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = await self.model.generate_content_async(prompt)
            plan_text = response.text.strip()
            
            # JSON ì¶”ì¶œ
            if '```json' in plan_text:
                json_start = plan_text.find('```json') + 7
                json_end = plan_text.find('```', json_start)
                plan_text = plan_text[json_start:json_end].strip()
            
            return json.loads(plan_text)
            
        except Exception as e:
            print(f"âŒ ë¦¬íŒ©í† ë§ ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "restructure_needed": False,
                "error": str(e)
            }

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ—ï¸ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ì‹œì‘...")
    
    analyzer = CodeStructureAnalyzer()
    
    # í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„
    analysis_results = analyzer.analyze_project_structure()
    
    # AI ë¦¬íŒ©í† ë§ ê³„íš ìƒì„±
    restructure_plan = await analyzer.generate_restructure_plan(analysis_results)
    
    # ê²°ê³¼ ì €ì¥
    with open('structure_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(f"""# ğŸ—ï¸ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ ë¶„ì„ ê²°ê³¼

- **ì´ íŒŒì¼ ìˆ˜**: {analysis_results['total_files']}ê°œ
- **êµ¬ì¡°ì  ì´ìŠˆ**: {len(analysis_results['structure_issues'])}ê°œ
- **ëª¨ë“ˆí™” ì ìˆ˜**: {analysis_results['metrics'].get('modularity_score', 0):.2f}/1.0

## ğŸ” ë°œê²¬ëœ êµ¬ì¡°ì  ë¬¸ì œ

{chr(10).join([f"- **{issue['type']}** ({issue['severity']}): {issue['description']}" for issue in analysis_results['structure_issues']])}

## ğŸ¯ ë¦¬íŒ©í† ë§ ê³„íš

{json.dumps(restructure_plan, ensure_ascii=False, indent=2)}
""")
    
    with open('restructure_plan.json', 'w', encoding='utf-8') as f:
        json.dump(restructure_plan, f, ensure_ascii=False, indent=2)
    
    with open('analysis_summary.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    
    # ë¦¬íŒ©í† ë§ í•„ìš” ì—¬ë¶€ ì €ì¥
    restructure_needed = restructure_plan.get('restructure_needed', False)
    with open('restructure_needed.txt', 'w') as f:
        f.write(str(restructure_needed).lower())
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ! ë¦¬íŒ©í† ë§ í•„ìš”: {restructure_needed}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main()) 