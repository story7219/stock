"""
ê³ ê¸‰ AI ì½”ë“œ ë¦¬ë·°ì–´
ë‹¤ì¤‘ AI ëª¨ë¸ì„ í™œìš©í•œ ì¢…í•©ì  ì½”ë“œ ë¶„ì„
"""

import os
import sys
import json
import ast
import subprocess
from typing import List, Dict, Any
from pathlib import Path

# AI ëª¨ë¸ imports
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class AdvancedAIReviewer:
    """ê³ ê¸‰ AI ì½”ë“œ ë¦¬ë·°ì–´"""
    
    def __init__(self):
        self.setup_ai_models()
        self.review_results = []
        
    def setup_ai_models(self):
        """AI ëª¨ë¸ ì„¤ì •"""
        if GEMINI_AVAILABLE and os.getenv('GEMINI_API_KEY'):
            genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
            self.gemini_model = genai.GenerativeModel('gemini-1.5-pro')
            print("âœ… Gemini AI ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        else:
            self.gemini_model = None
            print("âš ï¸ Gemini AI ì‚¬ìš© ë¶ˆê°€")
            
        if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
            openai.api_key = os.getenv('OPENAI_API_KEY')
            self.openai_available = True
            print("âœ… OpenAI ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        else:
            self.openai_available = False
            print("âš ï¸ OpenAI ì‚¬ìš© ë¶ˆê°€")
    
    def get_changed_files(self) -> List[str]:
        """ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # Gitì„ í†µí•´ ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                ['git', 'diff', '--name-only', 'HEAD~1', 'HEAD'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                files = [f.strip() for f in result.stdout.split('\n') if f.strip().endswith('.py')]
                return files[:10]  # ìµœëŒ€ 10ê°œ íŒŒì¼ë§Œ ë¶„ì„
            else:
                print("âš ï¸ Git diff ì‹¤í–‰ ì‹¤íŒ¨, ì „ì²´ Python íŒŒì¼ ë¶„ì„")
                return list(Path('.').rglob('*.py'))[:10]
                
        except Exception as e:
            print(f"âŒ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_file_structure(self, file_path: str) -> Dict[str, Any]:
        """íŒŒì¼ êµ¬ì¡° ìƒì„¸ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            analysis = {
                'file_path': file_path,
                'lines_of_code': len(content.split('\n')),
                'classes': [],
                'functions': [],
                'imports': [],
                'complexity_issues': [],
                'code_smells': [],
                'best_practices': []
            }
            
            # AST ë¶„ì„
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    analysis['classes'].append({
                        'name': node.name,
                        'methods': methods,
                        'method_count': len(methods),
                        'line_start': node.lineno,
                        'docstring': ast.get_docstring(node)
                    })
                    
                    # í´ë˜ìŠ¤ í¬ê¸° ì²´í¬
                    if len(methods) > 20:
                        analysis['code_smells'].append({
                            'type': 'large_class',
                            'location': f"Line {node.lineno}",
                            'message': f"í´ë˜ìŠ¤ '{node.name}'ì— {len(methods)}ê°œì˜ ë©”ì„œë“œê°€ ìˆìŠµë‹ˆë‹¤. ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ê³ ë ¤í•˜ì„¸ìš”."
                        })
                
                elif isinstance(node, ast.FunctionDef):
                    complexity = self.calculate_cyclomatic_complexity(node)
                    analysis['functions'].append({
                        'name': node.name,
                        'args_count': len(node.args.args),
                        'line_start': node.lineno,
                        'complexity': complexity,
                        'docstring': ast.get_docstring(node)
                    })
                    
                    # ë³µì¡ë„ ì²´í¬
                    if complexity > 15:
                        analysis['complexity_issues'].append({
                            'function': node.name,
                            'complexity': complexity,
                            'line': node.lineno,
                            'suggestion': 'í•¨ìˆ˜ê°€ ë„ˆë¬´ ë³µì¡í•©ë‹ˆë‹¤. ë” ì‘ì€ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.'
                        })
                    
                    # ë¬¸ì„œí™” ì²´í¬
                    if not ast.get_docstring(node) and not node.name.startswith('_'):
                        analysis['best_practices'].append({
                            'type': 'missing_docstring',
                            'location': f"Line {node.lineno}",
                            'message': f"í•¨ìˆ˜ '{node.name}'ì— docstringì´ ì—†ìŠµë‹ˆë‹¤."
                        })
                
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis['imports'].append(alias.name)
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        analysis['imports'].append(node.module)
            
            # ì¶”ê°€ ì½”ë“œ ìŠ¤ë©œ ê²€ì‚¬
            self.detect_code_smells(content, analysis)
            
            return analysis
            
        except Exception as e:
            return {'error': str(e), 'file_path': file_path}
    
    def calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor, ast.With, ast.AsyncWith)):
                complexity += 1
            elif isinstance(child, ast.Try):
                complexity += 1
                complexity += len(child.handlers)
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
            elif isinstance(child, ast.comprehension):
                complexity += 1
        
        return complexity
    
    def detect_code_smells(self, content: str, analysis: Dict):
        """ì½”ë“œ ìŠ¤ë©œ íƒì§€"""
        lines = content.split('\n')
        
        # ê¸´ ë¼ì¸ ì²´í¬
        for i, line in enumerate(lines, 1):
            if len(line) > 120:
                analysis['code_smells'].append({
                    'type': 'long_line',
                    'location': f"Line {i}",
                    'message': f"ë¼ì¸ì´ {len(line)}ìë¡œ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ê¶Œì¥: 120ì ì´í•˜)"
                })
        
        # TODO/FIXME ì£¼ì„ ì²´í¬
        for i, line in enumerate(lines, 1):
            if 'TODO' in line or 'FIXME' in line:
                analysis['code_smells'].append({
                    'type': 'todo_comment',
                    'location': f"Line {i}",
                    'message': "TODO/FIXME ì£¼ì„ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ìŠˆë¡œ ë“±ë¡í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”."
                })
        
        # í•˜ë“œì½”ë”©ëœ ê°’ ì²´í¬ (ê°„ë‹¨í•œ ë²„ì „)
        import re
        hardcoded_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']'
        ]
        
        for pattern in hardcoded_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                analysis['code_smells'].append({
                    'type': 'hardcoded_secret',
                    'location': f"Line {line_num}",
                    'message': "í•˜ë“œì½”ë”©ëœ ë¹„ë°€ ì •ë³´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                })
    
    async def ai_review_file(self, file_analysis: Dict) -> str:
        """AIë¥¼ í†µí•œ íŒŒì¼ ë¦¬ë·°"""
        if not self.gemini_model:
            return "AI ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        prompt = f"""
ë‹¤ìŒì€ Python ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì˜ íŒŒì¼ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

íŒŒì¼: {file_analysis['file_path']}
ì½”ë“œ ë¼ì¸ ìˆ˜: {file_analysis['lines_of_code']}
í´ë˜ìŠ¤ ìˆ˜: {len(file_analysis.get('classes', []))}
í•¨ìˆ˜ ìˆ˜: {len(file_analysis.get('functions', []))}

ë³µì¡ë„ ì´ìŠˆ: {len(file_analysis.get('complexity_issues', []))}ê°œ
ì½”ë“œ ìŠ¤ë©œ: {len(file_analysis.get('code_smells', []))}ê°œ

ìƒì„¸ ë¶„ì„:
{json.dumps(file_analysis, ensure_ascii=False, indent=2)}

ë‹¤ìŒ ê´€ì ì—ì„œ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:

1. **ì•„í‚¤í…ì²˜ ë° ì„¤ê³„**:
   - ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì¤€ìˆ˜
   - ì˜ì¡´ì„± ê´€ë¦¬
   - ëª¨ë“ˆí™” ìˆ˜ì¤€

2. **ì½”ë“œ í’ˆì§ˆ**:
   - ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì„±
   - ë„¤ì´ë° ì»¨ë²¤ì…˜
   - ì½”ë“œ ì¤‘ë³µ

3. **ì„±ëŠ¥ ë° ìµœì í™”**:
   - ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±
   - ë©”ëª¨ë¦¬ ì‚¬ìš©
   - ë¹„ë™ê¸° ì²˜ë¦¬

4. **ë³´ì•ˆ ë° ì•ˆì •ì„±**:
   - ì—ëŸ¬ í•¸ë“¤ë§
   - ì…ë ¥ ê²€ì¦
   - ë³´ì•ˆ ì·¨ì•½ì 

5. **ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ íŠ¹í™”**:
   - ì‹¤ì‹œê°„ ì²˜ë¦¬ ì í•©ì„±
   - ë°ì´í„° ì •í™•ì„±
   - ë¦¬ìŠ¤í¬ ê´€ë¦¬

êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆê³¼ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = await self.gemini_model.generate_content_async(prompt)
            return response.text
        except Exception as e:
            return f"AI ë¦¬ë·° ìƒì„± ì‹¤íŒ¨: {str(e)}"
    
    async def generate_comprehensive_review(self, file_analyses: List[Dict]) -> str:
        """ì¢…í•©ì ì¸ ë¦¬ë·° ìƒì„±"""
        individual_reviews = []
        
        for analysis in file_analyses:
            if 'error' not in analysis:
                review = await self.ai_review_file(analysis)
                individual_reviews.append({
                    'file': analysis['file_path'],
                    'review': review
                })
        
        # ì „ì²´ í”„ë¡œì íŠ¸ ì¢…í•© ë¶„ì„
        total_lines = sum(a.get('lines_of_code', 0) for a in file_analyses if 'error' not in a)
        total_complexity_issues = sum(len(a.get('complexity_issues', [])) for a in file_analyses if 'error' not in a)
        total_code_smells = sum(len(a.get('code_smells', [])) for a in file_analyses if 'error' not in a)
        
        comprehensive_review = f"""
# ğŸ§  AI ì¢…í•© ì½”ë“œ ë¦¬ë·°

## ğŸ“Š ì „ì²´ ë¶„ì„ ìš”ì•½

- **ë¶„ì„ëœ íŒŒì¼**: {len(file_analyses)}ê°œ
- **ì´ ì½”ë“œ ë¼ì¸**: {total_lines:,}ì¤„
- **ë³µì¡ë„ ì´ìŠˆ**: {total_complexity_issues}ê°œ
- **ì½”ë“œ ìŠ¤ë©œ**: {total_code_smells}ê°œ

## ğŸ“ íŒŒì¼ë³„ ìƒì„¸ ë¦¬ë·°

"""
        
        for review_data in individual_reviews:
            comprehensive_review += f"""
### ğŸ“„ {review_data['file']}

{review_data['review']}

---
"""
        
        # ì „ì²´ í”„ë¡œì íŠ¸ ê¶Œì¥ì‚¬í•­
        if self.gemini_model:
            try:
                project_summary_prompt = f"""
ë‹¤ìŒì€ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì˜ ì „ì²´ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

- ì´ {len(file_analyses)}ê°œ íŒŒì¼ ë¶„ì„
- ì´ {total_lines:,}ì¤„ì˜ ì½”ë“œ
- {total_complexity_issues}ê°œì˜ ë³µì¡ë„ ì´ìŠˆ
- {total_code_smells}ê°œì˜ ì½”ë“œ ìŠ¤ë©œ

ì „ì²´ í”„ë¡œì íŠ¸ ê´€ì ì—ì„œ ë‹¤ìŒì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

1. **ìš°ì„ ìˆœìœ„ ê°œì„  ì‚¬í•­** (ìƒìœ„ 3ê°œ)
2. **ì•„í‚¤í…ì²˜ ê°œì„  ë°©í–¥**
3. **ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸**
4. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ ë°©ì•ˆ**
5. **ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°•í™”**

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
                
                project_recommendations = await self.gemini_model.generate_content_async(project_summary_prompt)
                comprehensive_review += f"""

## ğŸ¯ ì „ì²´ í”„ë¡œì íŠ¸ ê¶Œì¥ì‚¬í•­

{project_recommendations.text}
"""
            except Exception as e:
                comprehensive_review += f"\nâš ï¸ ì „ì²´ í”„ë¡œì íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}\n"
        
        return comprehensive_review

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  ê³ ê¸‰ AI ì½”ë“œ ë¦¬ë·° ì‹œì‘...")
    
    reviewer = AdvancedAIReviewer()
    
    # ë³€ê²½ëœ íŒŒì¼ ë¶„ì„
    changed_files = reviewer.get_changed_files()
    
    if not changed_files:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ë¶„ì„í•  íŒŒì¼: {len(changed_files)}ê°œ")
    
    # ê° íŒŒì¼ ë¶„ì„
    file_analyses = []
    for file_path in changed_files:
        print(f"ğŸ” ë¶„ì„ ì¤‘: {file_path}")
        analysis = reviewer.analyze_file_structure(file_path)
        file_analyses.append(analysis)
    
    # ì¢…í•© ë¦¬ë·° ìƒì„±
    print("ğŸ¤– AI ë¦¬ë·° ìƒì„± ì¤‘...")
    comprehensive_review = await reviewer.generate_comprehensive_review(file_analyses)
    
    # ê²°ê³¼ ì €ì¥
    with open('ai_review_results.md', 'w', encoding='utf-8') as f:
        f.write(comprehensive_review)
    
    print("âœ… AI ì½”ë“œ ë¦¬ë·° ì™„ë£Œ!")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main()) 