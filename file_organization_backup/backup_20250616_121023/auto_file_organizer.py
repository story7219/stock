"""
ìë™ íŒŒì¼ ì •ë¦¬ ë„êµ¬
- ì¤‘ë³µ íŒŒì¼ ì œê±°
- ì¹´í…Œê³ ë¦¬ë³„ í†µí•©
- ë°±ì—… ìƒì„±
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import ast

class AutoFileOrganizer:
    """ìë™ íŒŒì¼ ì •ë¦¬ê¸°"""
    
    def __init__(self):
        self.backup_dir = Path("file_organization_backup")
        self.backup_dir.mkdir(exist_ok=True)
        
    def create_backup(self) -> str:
        """ì „ì²´ ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"backup_{timestamp}"
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ ë°±ì—…
        shutil.copytree(".", backup_path, 
                       ignore=shutil.ignore_patterns('__pycache__', '*.pyc', '.git'))
        
        print(f"ğŸ’¾ ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_path}")
        return str(backup_path)
    
    def organize_files_by_category(self, analysis: Dict[str, any]):
        """ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ì •ë¦¬"""
        print("ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        directories = {
            'íŠ¸ë ˆì´ë”© ë¡œì§': 'trading',
            'ë¶„ì„ ë„êµ¬': 'analyzers', 
            'API ì—°ë™': 'api',
            'ë´‡/ì•Œë¦¼': 'bots',
            'ì½”ë“œ í’ˆì§ˆ': 'quality',
            'ìœ í‹¸ë¦¬í‹°': 'utils',
            'í…ŒìŠ¤íŠ¸': 'tests',
            'ì„¤ì •': 'config'
        }
        
        for category, files in analysis['file_categories'].items():
            if category in directories and len(files) > 1:
                dir_name = directories[category]
                dir_path = Path(dir_name)
                dir_path.mkdir(exist_ok=True)
                
                print(f"ğŸ“‚ {category} íŒŒì¼ë“¤ì„ {dir_name}/ ë””ë ‰í† ë¦¬ë¡œ ì´ë™...")
                
                for file_path in files:
                    file_name = Path(file_path).name
                    if file_name != 'main.py':  # ë©”ì¸ íŒŒì¼ì€ ë£¨íŠ¸ì— ìœ ì§€
                        try:
                            shutil.move(file_path, dir_path / file_name)
                            print(f"  âœ… {file_name} â†’ {dir_name}/")
                        except Exception as e:
                            print(f"  âŒ {file_name} ì´ë™ ì‹¤íŒ¨: {e}")
    
    def merge_similar_files(self, analysis: Dict[str, any]):
        """ìœ ì‚¬í•œ íŒŒì¼ë“¤ ë³‘í•©"""
        print("ğŸ”„ ìœ ì‚¬í•œ íŒŒì¼ë“¤ ë³‘í•© ì¤‘...")
        
        for suggestion in analysis['integration_suggestions']:
            if suggestion['type'] == 'ì†Œí˜• íŒŒì¼ í†µí•©':
                self.merge_small_files(suggestion['files'], suggestion['suggested_name'])
            elif suggestion['type'] == 'ì¹´í…Œê³ ë¦¬ í†µí•©':
                self.merge_category_files(suggestion['files'], suggestion['suggested_name'])
    
    def merge_small_files(self, files: List[str], target_name: str):
        """ì‘ì€ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•©"""
        print(f"ğŸ“¦ ì‘ì€ íŒŒì¼ë“¤ì„ {target_name}ìœ¼ë¡œ ë³‘í•©...")
        
        merged_content = []
        merged_content.append(f'"""\n{target_name} - í†µí•©ëœ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\nìƒì„±ì¼: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n"""')
        merged_content.append("")
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_name = Path(file_path).name
                merged_content.append(f"# ===== {file_name}ì—ì„œ ê°€ì ¸ì˜¨ ì½”ë“œ =====")
                merged_content.append(content)
                merged_content.append("")
                
                # ì›ë³¸ íŒŒì¼ ì‚­ì œ
                os.remove(file_path)
                print(f"  âœ… {file_name} ë³‘í•© ì™„ë£Œ")
                
            except Exception as e:
                print(f"  âŒ {Path(file_path).name} ë³‘í•© ì‹¤íŒ¨: {e}")
        
        # ë³‘í•©ëœ íŒŒì¼ ì €ì¥
        with open(target_name, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        
        print(f"ğŸ’¾ {target_name} ìƒì„± ì™„ë£Œ")
    
    def remove_duplicate_files(self, duplicate_groups: List[List[str]]):
        """ì¤‘ë³µ íŒŒì¼ ì œê±°"""
        print("ğŸ—‘ï¸ ì¤‘ë³µ íŒŒì¼ ì œê±° ì¤‘...")
        
        for group in duplicate_groups:
            if len(group) > 1:
                # ê°€ì¥ ìµœê·¼ íŒŒì¼ ìœ ì§€, ë‚˜ë¨¸ì§€ ì‚­ì œ
                files_with_time = [(f, os.path.getmtime(f)) for f in group]
                files_with_time.sort(key=lambda x: x[1], reverse=True)
                
                keep_file = files_with_time[0][0]
                remove_files = [f[0] for f in files_with_time[1:]]
                
                print(f"ğŸ“ ì¤‘ë³µ ê·¸ë£¹: {[Path(f).name for f in group]}")
                print(f"  âœ… ìœ ì§€: {Path(keep_file).name}")
                
                for remove_file in remove_files:
                    try:
                        os.remove(remove_file)
                        print(f"  ğŸ—‘ï¸ ì‚­ì œ: {Path(remove_file).name}")
                    except Exception as e:
                        print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨ {Path(remove_file).name}: {e}")
    
    def create_init_files(self):
        """__init__.py íŒŒì¼ ìƒì„±"""
        print("ğŸ“ __init__.py íŒŒì¼ ìƒì„± ì¤‘...")
        
        directories = ['trading', 'analyzers', 'api', 'bots', 'quality', 'utils', 'tests', 'config']
        
        for dir_name in directories:
            dir_path = Path(dir_name)
            if dir_path.exists() and dir_path.is_dir():
                init_file = dir_path / '__init__.py'
                if not init_file.exists():
                    with open(init_file, 'w', encoding='utf-8') as f:
                        f.write(f'"""{dir_name} ëª¨ë“ˆ"""\n')
                    print(f"  âœ… {dir_name}/__init__.py ìƒì„±")
    
    def update_imports(self):
        """import ë¬¸ ì—…ë°ì´íŠ¸"""
        print("ğŸ”„ import ë¬¸ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        # ëª¨ë“  Python íŒŒì¼ì—ì„œ import ë¬¸ ìˆ˜ì •
        for py_file in Path('.').rglob('*.py'):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ê°„ë‹¨í•œ import ê²½ë¡œ ìˆ˜ì • (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
                updated_content = self.fix_imports(content, py_file)
                
                if updated_content != content:
                    with open(py_file, 'w', encoding='utf-8') as f:
                        f.write(updated_content)
                    print(f"  âœ… {py_file} import ì—…ë°ì´íŠ¸")
                    
            except Exception as e:
                print(f"  âŒ {py_file} import ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def fix_imports(self, content: str, file_path: Path) -> str:
        """import ë¬¸ ìˆ˜ì •"""
        # ê¸°ë³¸ì ì¸ import ê²½ë¡œ ìˆ˜ì •
        # ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ì´ í•„ìš”
        
        lines = content.splitlines()
        updated_lines = []
        
        for line in lines:
            # ìƒëŒ€ importë¥¼ ì ˆëŒ€ importë¡œ ë³€ê²½í•˜ëŠ” ë“±ì˜ ì‘ì—…
            if line.strip().startswith('from ') or line.strip().startswith('import '):
                # ì—¬ê¸°ì„œ ì‹¤ì œ import ê²½ë¡œ ìˆ˜ì • ë¡œì§ êµ¬í˜„
                updated_lines.append(line)
            else:
                updated_lines.append(line)
        
        return '\n'.join(updated_lines)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        if not Path('project_structure_analysis.json').exists():
            print("âŒ ë¨¼ì € file_structure_analyzer.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
            return
        
        with open('project_structure_analysis.json', 'r', encoding='utf-8') as f:
            analysis = json.load(f)
        
        organizer = AutoFileOrganizer()
        
        print("ğŸš€ ìë™ íŒŒì¼ ì •ë¦¬ ì‹œì‘")
        print("="*50)
        
        # 1. ë°±ì—… ìƒì„±
        backup_path = organizer.create_backup()
        
        # 2. ì¤‘ë³µ íŒŒì¼ ì œê±°
        if analysis['duplicate_groups']:
            organizer.remove_duplicate_files(analysis['duplicate_groups'])
        
        # 3. ìœ ì‚¬í•œ íŒŒì¼ ë³‘í•©
        if analysis['integration_suggestions']:
            organizer.merge_similar_files(analysis)
        
        # 4. ì¹´í…Œê³ ë¦¬ë³„ ì •ë¦¬
        organizer.organize_files_by_category(analysis)
        
        # 5. __init__.py íŒŒì¼ ìƒì„±
        organizer.create_init_files()
        
        # 6. import ë¬¸ ì—…ë°ì´íŠ¸
        organizer.update_imports()
        
        print("\nğŸ‰ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ’¾ ë°±ì—… ìœ„ì¹˜: {backup_path}")
        print("ğŸ“‹ ì •ë¦¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main() 