#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ ë„êµ¬
=====================================

íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œì˜ ì½”ë“œ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ ê²€ì‚¬í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
GitHub Actions CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ 
ì½”ë“œ í’ˆì§ˆ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.

ì£¼ìš” ê²€ì‚¬ í•­ëª©:
1. ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬ (PEP8, Black, isort)
2. ì •ì  ë¶„ì„ (pylint, flake8, mypy)
3. ë³´ì•ˆ ê²€ì‚¬ (bandit)
4. ë³µì¡ë„ ë¶„ì„ (mccabe)
5. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (pytest-cov)
6. íˆ¬ì ì‹œìŠ¤í…œ íŠ¹í™” ê²€ì‚¬
7. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
8. ë¬¸ì„œí™” í’ˆì§ˆ ê²€ì‚¬
"""

import os
import sys
import subprocess
import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class QualityResult:
    """í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼"""
    tool_name: str
    passed: bool
    score: float
    issues: List[Dict[str, Any]] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    execution_time: float = 0.0
    output: str = ""


@dataclass
class QualityReport:
    """ì „ì²´ í’ˆì§ˆ ë¦¬í¬íŠ¸"""
    overall_score: float
    passed: bool
    results: List[QualityResult] = field(default_factory=list)
    summary: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    execution_time: float = 0.0


class InvestmentSystemQualityChecker:
    """íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ í’ˆì§ˆ ê²€ì‚¬ê¸°"""
    
    def __init__(self, project_root: Optional[Path] = None):
        self.project_root = project_root or Path(__file__).parent.parent.parent
        self.src_path = self.project_root / "src"
        self.config_path = self.project_root / "config"
        
        # í’ˆì§ˆ ê¸°ì¤€ ì„¤ì •
        self.quality_standards = {
            'pylint_min_score': 8.0,
            'coverage_min_percent': 80.0,
            'complexity_max': 10,
            'line_length_max': 88,
            'function_length_max': 50,
            'class_length_max': 200
        }
        
        # ê²€ì‚¬í•  Python íŒŒì¼ë“¤
        self.python_files = self._get_python_files()
        
        # íˆ¬ì ì‹œìŠ¤í…œ íŠ¹í™” ê²€ì‚¬ ê·œì¹™
        self.investment_rules = {
            'required_modules': [
                'yfinance', 'pandas', 'numpy', 'ta',
                'google-generativeai', 'aiohttp'
            ],
            'required_functions': {
                'strategy': ['analyze', 'get_strategy_type'],
                'data_collector': ['collect_market_data', 'get_stock_data'],
                'ai_analyzer': ['analyze_recommendations'],
            },
            'security_patterns': [
                r'api_key\s*=\s*["\'][^"\']+["\']',
                r'password\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']'
            ]
        }
    
    def _get_python_files(self) -> List[Path]:
        """ê²€ì‚¬í•  Python íŒŒì¼ ëª©ë¡ ìƒì„±"""
        python_files = []
        
        # src ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  Python íŒŒì¼
        if self.src_path.exists():
            python_files.extend(self.src_path.rglob('*.py'))
        
        # ë£¨íŠ¸ì˜ ì£¼ìš” Python íŒŒì¼ë“¤
        main_files = ['main.py', 'config.py', 'setup.py']
        for file_name in main_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                python_files.append(file_path)
        
        # í…ŒìŠ¤íŠ¸ ì œì™¸, ê°€ìƒí™˜ê²½ ì œì™¸
        return [
            f for f in python_files 
            if not any(exclude in str(f) for exclude in [
                '__pycache__', '.pyc', 'test_', 'tests/', 
                'venv/', '.venv/', '.git/'
            ])
        ]
    
    async def run_quality_checks(self) -> QualityReport:
        """ì „ì²´ í’ˆì§ˆ ê²€ì‚¬ ì‹¤í–‰"""
        start_time = time.time()
        results = []
        
        logger.info("ğŸ” íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘...")
        
        # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ íƒœìŠ¤í¬ ëª©ë¡
        tasks = [
            self._run_pylint(),
            self._run_flake8(),
            self._run_black_check(),
            self._run_isort_check(),
            self._run_mypy(),
            self._run_bandit(),
            self._run_complexity_check(),
            self._run_investment_specific_checks(),
            self._run_documentation_check(),
            self._run_performance_check()
        ]
        
        # ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=5) as executor:
            task_results = await asyncio.gather(*[
                asyncio.get_event_loop().run_in_executor(executor, task)
                for task in tasks
            ], return_exceptions=True)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for i, result in enumerate(task_results):
            if isinstance(result, Exception):
                logger.error(f"ê²€ì‚¬ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {result}")
                continue
            if result:
                results.append(result)
        
        # í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê²€ì‚¬ (ë³„ë„ ì‹¤í–‰)
        coverage_result = await self._run_coverage_check()
        if coverage_result:
            results.append(coverage_result)
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(results)
        passed = overall_score >= 70.0
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(results)
        
        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary = self._generate_summary(results)
        
        execution_time = time.time() - start_time
        
        report = QualityReport(
            overall_score=overall_score,
            passed=passed,
            results=results,
            summary=summary,
            recommendations=recommendations,
            execution_time=execution_time
        )
        
        logger.info(f"âœ… í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ - ì „ì²´ ì ìˆ˜: {overall_score:.1f}/100")
        return report
    
    def _run_pylint(self) -> QualityResult:
        """Pylint ì •ì  ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            # pylint ì„¤ì • íŒŒì¼ ìƒì„±
            pylintrc_content = """
[MASTER]
disable=C0114,C0115,C0116,R0903,R0913,W0613,C0103

[FORMAT]
max-line-length=88

[DESIGN]
max-args=10
max-locals=20
max-returns=6
max-branches=15
"""
            
            pylintrc_path = self.project_root / '.pylintrc'
            with open(pylintrc_path, 'w') as f:
                f.write(pylintrc_content)
            
            # Pylint ì‹¤í–‰
            cmd = ['python', '-m', 'pylint'] + [str(f) for f in self.python_files[:5]]  # ì²˜ìŒ 5ê°œ íŒŒì¼ë§Œ
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            # ì ìˆ˜ ì¶”ì¶œ
            score = 0.0
            if result.stdout:
                for line in result.stdout.split('\n'):
                    if 'Your code has been rated at' in line:
                        score_str = line.split('rated at ')[1].split('/')[0]
                        score = float(score_str)
                        break
            
            passed = score >= self.quality_standards['pylint_min_score']
            
            # ì •ë¦¬
            if pylintrc_path.exists():
                pylintrc_path.unlink()
            
            return QualityResult(
                tool_name="Pylint",
                passed=passed,
                score=score * 10,  # 100ì  ë§Œì ìœ¼ë¡œ ë³€í™˜
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            logger.error(f"Pylint ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return QualityResult(
                tool_name="Pylint",
                passed=False,
                score=0.0,
                execution_time=time.time() - start_time,
                warnings=[f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _run_flake8(self) -> QualityResult:
        """Flake8 ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            cmd = ['python', '-m', 'flake8', '--max-line-length=88', '--ignore=E203,W503'] + [str(f) for f in self.python_files[:10]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            issues = []
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        issues.append({'message': line, 'type': 'style'})
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 2)  # ì´ìŠˆ 1ê°œë‹¹ 2ì  ê°ì 
            
            return QualityResult(
                tool_name="Flake8",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Flake8",
                passed=False,
                score=0.0,
                execution_time=time.time() - start_time,
                warnings=[f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _run_black_check(self) -> QualityResult:
        """Black ì½”ë“œ í¬ë§·íŒ… ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            cmd = ['python', '-m', 'black', '--check', '--line-length=88'] + [str(f) for f in self.python_files[:10]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            passed = result.returncode == 0
            score = 100.0 if passed else 70.0
            
            issues = []
            if not passed and result.stdout:
                issues.append({'message': 'Black í¬ë§·íŒ…ì´ í•„ìš”í•œ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤', 'type': 'formatting'})
            
            return QualityResult(
                tool_name="Black",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Black",
                passed=True,  # Blackì´ ì—†ì–´ë„ í†µê³¼
                score=80.0,
                execution_time=time.time() - start_time,
                warnings=[f"Black ë¯¸ì„¤ì¹˜: {str(e)}"]
            )
    
    def _run_isort_check(self) -> QualityResult:
        """isort import ì •ë ¬ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            cmd = ['python', '-m', 'isort', '--check-only', '--profile=black'] + [str(f) for f in self.python_files[:10]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            passed = result.returncode == 0
            score = 100.0 if passed else 80.0
            
            return QualityResult(
                tool_name="isort",
                passed=passed,
                score=score,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="isort",
                passed=True,  # isortê°€ ì—†ì–´ë„ í†µê³¼
                score=80.0,
                execution_time=time.time() - start_time,
                warnings=[f"isort ë¯¸ì„¤ì¹˜: {str(e)}"]
            )
    
    def _run_mypy(self) -> QualityResult:
        """MyPy íƒ€ì… ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            cmd = ['python', '-m', 'mypy', '--ignore-missing-imports'] + [str(f) for f in self.python_files[:5]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            issues = []
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    if line.strip() and 'error:' in line:
                        issues.append({'message': line, 'type': 'type'})
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 5)  # íƒ€ì… ì˜¤ë¥˜ 1ê°œë‹¹ 5ì  ê°ì 
            
            return QualityResult(
                tool_name="MyPy",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="MyPy",
                passed=True,  # MyPyê°€ ì—†ì–´ë„ í†µê³¼
                score=70.0,
                execution_time=time.time() - start_time,
                warnings=[f"MyPy ë¯¸ì„¤ì¹˜: {str(e)}"]
            )
    
    def _run_bandit(self) -> QualityResult:
        """Bandit ë³´ì•ˆ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            cmd = ['python', '-m', 'bandit', '-r'] + [str(f) for f in self.python_files[:10]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            issues = []
            if result.stdout:
                # JSON ì¶œë ¥ íŒŒì‹± ì‹œë„
                try:
                    bandit_output = json.loads(result.stdout)
                    for issue in bandit_output.get('results', []):
                        issues.append({
                            'message': issue.get('issue_text', ''),
                            'type': 'security',
                            'severity': issue.get('issue_severity', 'LOW')
                        })
                except json.JSONDecodeError:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì‹±
                    for line in result.stdout.split('\n'):
                        if 'Issue:' in line:
                            issues.append({'message': line, 'type': 'security'})
            
            passed = len([i for i in issues if i.get('severity') in ['HIGH', 'MEDIUM']]) == 0
            score = max(0, 100 - len(issues) * 10)  # ë³´ì•ˆ ì´ìŠˆ 1ê°œë‹¹ 10ì  ê°ì 
            
            return QualityResult(
                tool_name="Bandit",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Bandit",
                passed=True,  # Banditì´ ì—†ì–´ë„ í†µê³¼
                score=80.0,
                execution_time=time.time() - start_time,
                warnings=[f"Bandit ë¯¸ì„¤ì¹˜: {str(e)}"]
            )
    
    def _run_complexity_check(self) -> QualityResult:
        """ì½”ë“œ ë³µì¡ë„ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            # mccabeë¥¼ ì‚¬ìš©í•œ ë³µì¡ë„ ê²€ì‚¬
            cmd = ['python', '-m', 'flake8', '--select=C901', '--max-complexity=10'] + [str(f) for f in self.python_files[:10]]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            issues = []
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        issues.append({'message': line, 'type': 'complexity'})
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 15)  # ë³µì¡ë„ ì´ìŠˆ 1ê°œë‹¹ 15ì  ê°ì 
            
            return QualityResult(
                tool_name="Complexity",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Complexity",
                passed=True,
                score=80.0,
                execution_time=time.time() - start_time,
                warnings=[f"ë³µì¡ë„ ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _run_investment_specific_checks(self) -> QualityResult:
        """íˆ¬ì ì‹œìŠ¤í…œ íŠ¹í™” ê²€ì‚¬"""
        start_time = time.time()
        
        issues = []
        warnings = []
        
        try:
            # í•„ìˆ˜ ëª¨ë“ˆ ê²€ì‚¬
            requirements_file = self.project_root / 'requirements.txt'
            if requirements_file.exists():
                with open(requirements_file, 'r') as f:
                    requirements = f.read()
                
                for module in self.investment_rules['required_modules']:
                    if module not in requirements:
                        issues.append({
                            'message': f'í•„ìˆ˜ ëª¨ë“ˆ ëˆ„ë½: {module}',
                            'type': 'dependency'
                        })
            else:
                warnings.append('requirements.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤')
            
            # íˆ¬ì ì „ëµ íŒŒì¼ ê²€ì‚¬
            strategy_files = [f for f in self.python_files if 'strategy' in str(f).lower()]
            for strategy_file in strategy_files:
                with open(strategy_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for func in self.investment_rules['required_functions']['strategy']:
                    if f'def {func}' not in content:
                        issues.append({
                            'message': f'{strategy_file.name}ì— {func} ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤',
                            'type': 'missing_method'
                        })
            
            # ë°ì´í„° ìˆ˜ì§‘ê¸° ê²€ì‚¬
            collector_files = [f for f in self.python_files if 'collector' in str(f).lower() or 'data' in str(f).lower()]
            for collector_file in collector_files:
                with open(collector_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'try:' not in content or 'except:' not in content:
                    issues.append({
                        'message': f'{collector_file.name}ì— ì˜ˆì™¸ ì²˜ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤',
                        'type': 'missing_exception'
                    })
            
            # API í‚¤ ë³´ì•ˆ ê²€ì‚¬
            for file_path in self.python_files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern in self.investment_rules['security_patterns']:
                    import re
                    if re.search(pattern, content):
                        issues.append({
                            'message': f'{file_path.name}ì— í•˜ë“œì½”ë”©ëœ ì¸ì¦ ì •ë³´ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤',
                            'type': 'security'
                        })
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 10)
            
            return QualityResult(
                tool_name="Investment System Check",
                passed=passed,
                score=score,
                issues=issues,
                warnings=warnings,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Investment System Check",
                passed=False,
                score=0.0,
                execution_time=time.time() - start_time,
                warnings=[f"ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _run_documentation_check(self) -> QualityResult:
        """ë¬¸ì„œí™” í’ˆì§ˆ ê²€ì‚¬"""
        start_time = time.time()
        
        issues = []
        
        try:
            total_functions = 0
            documented_functions = 0
            
            for file_path in self.python_files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                # í•¨ìˆ˜ ì •ì˜ ì°¾ê¸°
                functions = re.findall(r'def\s+(\w+)\s*\([^)]*\):', content)
                total_functions += len(functions)
                
                # docstringì´ ìˆëŠ” í•¨ìˆ˜ ì°¾ê¸°
                for func in functions:
                    func_pattern = rf'def\s+{func}\s*\([^)]*\):\s*""".*?"""'
                    if re.search(func_pattern, content, re.DOTALL):
                        documented_functions += 1
            
            if total_functions > 0:
                doc_ratio = documented_functions / total_functions
                if doc_ratio < 0.5:
                    issues.append({
                        'message': f'ë¬¸ì„œí™” ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤: {doc_ratio:.1%}',
                        'type': 'documentation'
                    })
            
            # README íŒŒì¼ ê²€ì‚¬
            readme_files = ['README.md', 'README.rst', 'README.txt']
            has_readme = any((self.project_root / readme).exists() for readme in readme_files)
            
            if not has_readme:
                issues.append({
                    'message': 'README íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤',
                    'type': 'documentation'
                })
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 20)
            
            return QualityResult(
                tool_name="Documentation",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Documentation",
                passed=True,
                score=70.0,
                execution_time=time.time() - start_time,
                warnings=[f"ë¬¸ì„œí™” ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _run_performance_check(self) -> QualityResult:
        """ì„±ëŠ¥ ê²€ì‚¬"""
        start_time = time.time()
        
        issues = []
        
        try:
            for file_path in self.python_files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ì„±ëŠ¥ ì´ìŠˆ íŒ¨í„´ ê²€ì‚¬
                import re
                
                # ë¹„íš¨ìœ¨ì  ë£¨í”„
                if re.search(r'for.*in.*range\(len\(', content):
                    issues.append({
                        'message': f'{file_path.name}ì— ë¹„íš¨ìœ¨ì ì¸ ë£¨í”„ê°€ ìˆìŠµë‹ˆë‹¤',
                        'type': 'performance'
                    })
                
                # pandas iterrows ì‚¬ìš©
                if '.iterrows()' in content:
                    issues.append({
                        'message': f'{file_path.name}ì—ì„œ pandas iterrows() ì‚¬ìš©ì„ í”¼í•˜ì„¸ìš”',
                        'type': 'performance'
                    })
                
                # ë™ê¸° HTTP ìš”ì²­ in ë¹„ë™ê¸° í•¨ìˆ˜
                if re.search(r'async\s+def.*\n.*requests\.', content, re.MULTILINE):
                    issues.append({
                        'message': f'{file_path.name}ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ ë‚´ ë™ê¸° HTTP ìš”ì²­',
                        'type': 'performance'
                    })
            
            passed = len(issues) == 0
            score = max(0, 100 - len(issues) * 15)
            
            return QualityResult(
                tool_name="Performance",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Performance",
                passed=True,
                score=80.0,
                execution_time=time.time() - start_time,
                warnings=[f"ì„±ëŠ¥ ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}"]
            )
    
    async def _run_coverage_check(self) -> Optional[QualityResult]:
        """í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            # pytestê°€ ìˆëŠ”ì§€ í™•ì¸
            test_files = list(self.project_root.rglob('test_*.py'))
            if not test_files:
                return QualityResult(
                    tool_name="Coverage",
                    passed=True,
                    score=60.0,
                    execution_time=time.time() - start_time,
                    warnings=["í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"]
                )
            
            # pytest-cov ì‹¤í–‰
            cmd = ['python', '-m', 'pytest', '--cov=src', '--cov-report=term-missing']
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
            
            coverage_percent = 0.0
            if result.stdout:
                import re
                match = re.search(r'TOTAL.*?(\d+)%', result.stdout)
                if match:
                    coverage_percent = float(match.group(1))
            
            passed = coverage_percent >= self.quality_standards['coverage_min_percent']
            score = min(100.0, coverage_percent * 1.2)  # ì»¤ë²„ë¦¬ì§€ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜
            
            issues = []
            if not passed:
                issues.append({
                    'message': f'í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤: {coverage_percent}%',
                    'type': 'coverage'
                })
            
            return QualityResult(
                tool_name="Coverage",
                passed=passed,
                score=score,
                issues=issues,
                execution_time=time.time() - start_time,
                output=result.stdout
            )
            
        except Exception as e:
            return QualityResult(
                tool_name="Coverage",
                passed=True,
                score=50.0,
                execution_time=time.time() - start_time,
                warnings=[f"ì»¤ë²„ë¦¬ì§€ ì¸¡ì • ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _calculate_overall_score(self, results: List[QualityResult]) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        if not results:
            return 0.0
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        weights = {
            'Pylint': 0.2,
            'Flake8': 0.15,
            'Black': 0.1,
            'isort': 0.05,
            'MyPy': 0.15,
            'Bandit': 0.2,
            'Complexity': 0.1,
            'Investment System Check': 0.25,
            'Documentation': 0.1,
            'Performance': 0.15,
            'Coverage': 0.2
        }
        
        total_score = 0.0
        total_weight = 0.0
        
        for result in results:
            weight = weights.get(result.tool_name, 0.1)
            total_score += result.score * weight
            total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def _generate_recommendations(self, results: List[QualityResult]) -> List[str]:
        """ê°œì„  ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        for result in results:
            if not result.passed:
                if result.tool_name == "Pylint":
                    recommendations.append("ğŸ” Pylint ê²½ê³ ë¥¼ ìˆ˜ì •í•˜ì—¬ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”")
                elif result.tool_name == "Flake8":
                    recommendations.append("ğŸ“ PEP8 ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ë”°ë¼ ì½”ë“œë¥¼ ì •ë¦¬í•˜ì„¸ìš”")
                elif result.tool_name == "Black":
                    recommendations.append("âš« Blackì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ í¬ë§·íŒ…ì„ ì¼ê´€ì„± ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”")
                elif result.tool_name == "Bandit":
                    recommendations.append("ğŸ”’ ë³´ì•ˆ ì·¨ì•½ì ì„ ìˆ˜ì •í•˜ì„¸ìš”")
                elif result.tool_name == "Complexity":
                    recommendations.append("ğŸ§© ë³µì¡í•œ í•¨ìˆ˜ë¥¼ ë” ì‘ì€ í•¨ìˆ˜ë¡œ ë¶„í• í•˜ì„¸ìš”")
                elif result.tool_name == "Investment System Check":
                    recommendations.append("ğŸ’° íˆ¬ì ì‹œìŠ¤í…œ íŠ¹í™” ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±ì‹œí‚¤ì„¸ìš”")
                elif result.tool_name == "Coverage":
                    recommendations.append("ğŸ§ª í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ 80% ì´ìƒìœ¼ë¡œ ë†’ì´ì„¸ìš”")
        
        # ì¼ë°˜ì ì¸ ì¶”ì²œì‚¬í•­
        recommendations.extend([
            "ğŸ“ ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ì™€ docstringì„ ì¶”ê°€í•˜ì„¸ìš”",
            "ğŸš€ ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•˜ì„¸ìš”",
            "ğŸ” API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ì„¸ìš”",
            "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ì— ìºì‹±ì„ ì ìš©í•˜ì„¸ìš”",
            "âš¡ ì—ëŸ¬ í•¸ë“¤ë§ê³¼ ì¬ì‹œë„ ë¡œì§ì„ êµ¬í˜„í•˜ì„¸ìš”"
        ])
        
        return recommendations
    
    def _generate_summary(self, results: List[QualityResult]) -> Dict[str, Any]:
        """ìš”ì•½ ì •ë³´ ìƒì„±"""
        total_issues = sum(len(r.issues) for r in results)
        total_warnings = sum(len(r.warnings) for r in results)
        passed_tools = len([r for r in results if r.passed])
        
        return {
            'total_tools': len(results),
            'passed_tools': passed_tools,
            'failed_tools': len(results) - passed_tools,
            'total_issues': total_issues,
            'total_warnings': total_warnings,
            'python_files_checked': len(self.python_files),
            'execution_time': sum(r.execution_time for r in results)
        }
    
    def generate_report(self, report: QualityReport) -> str:
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        lines = [
            "ğŸ” **íˆ¬ì ë¶„ì„ ì‹œìŠ¤í…œ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼**",
            "=" * 50,
            "",
            f"ğŸ“Š **ì „ì²´ ì ìˆ˜: {report.overall_score:.1f}/100**",
            f"âœ… **í†µê³¼ ì—¬ë¶€: {'PASS' if report.passed else 'FAIL'}**",
            f"â±ï¸ **ì‹¤í–‰ ì‹œê°„: {report.execution_time:.2f}ì´ˆ**",
            f"ğŸ“ **ê²€ì‚¬ íŒŒì¼ ìˆ˜: {report.summary.get('python_files_checked', 0)}ê°œ**",
            "",
            "## ğŸ“‹ ê²€ì‚¬ ë„êµ¬ë³„ ê²°ê³¼",
            ""
        ]
        
        for result in report.results:
            status = "âœ… PASS" if result.passed else "âŒ FAIL"
            lines.append(f"### {result.tool_name} - {status} ({result.score:.1f}/100)")
            
            if result.issues:
                lines.append("**ì´ìŠˆ:**")
                for issue in result.issues[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    lines.append(f"- {issue.get('message', issue)}")
                if len(result.issues) > 5:
                    lines.append(f"- ... ë° {len(result.issues) - 5}ê°œ ì¶”ê°€ ì´ìŠˆ")
            
            if result.warnings:
                lines.append("**ê²½ê³ :**")
                for warning in result.warnings[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    lines.append(f"- {warning}")
            
            lines.append("")
        
        lines.extend([
            "## ğŸ’¡ ê°œì„  ì¶”ì²œì‚¬í•­",
            ""
        ])
        
        for rec in report.recommendations[:10]:  # ìµœëŒ€ 10ê°œ
            lines.append(f"- {rec}")
        
        lines.extend([
            "",
            "## ğŸ“ˆ ìš”ì•½ í†µê³„",
            "",
            f"- ì´ ê²€ì‚¬ ë„êµ¬: {report.summary.get('total_tools', 0)}ê°œ",
            f"- í†µê³¼í•œ ë„êµ¬: {report.summary.get('passed_tools', 0)}ê°œ",
            f"- ì‹¤íŒ¨í•œ ë„êµ¬: {report.summary.get('failed_tools', 0)}ê°œ",
            f"- ì´ ì´ìŠˆ ìˆ˜: {report.summary.get('total_issues', 0)}ê°œ",
            f"- ì´ ê²½ê³  ìˆ˜: {report.summary.get('total_warnings', 0)}ê°œ",
            "",
            "*ğŸ¤– ìë™ í’ˆì§ˆ ê²€ì‚¬ ì‹œìŠ¤í…œì´ ìƒì„±í•œ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.*"
        ])
        
        return "\n".join(lines)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        checker = InvestmentSystemQualityChecker()
        report = await checker.run_quality_checks()
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥
        report_text = checker.generate_report(report)
        print(report_text)
        
        # íŒŒì¼ë¡œ ì €ì¥
        report_file = checker.project_root / 'quality_report.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        logger.info(f"í’ˆì§ˆ ë¦¬í¬íŠ¸ê°€ {report_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # GitHub Actionsìš© ì¶œë ¥
        if os.getenv('GITHUB_ACTIONS'):
            print(f"::set-output name=score::{report.overall_score}")
            print(f"::set-output name=passed::{'true' if report.passed else 'false'}")
        
        return 0 if report.passed else 1
        
    except Exception as e:
        logger.error(f"í’ˆì§ˆ ê²€ì‚¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
