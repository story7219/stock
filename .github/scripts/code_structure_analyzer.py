#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: code_structure_analyzer.py
ëª¨ë“ˆ: ì½”ë“œ êµ¬ì¡° ë¶„ì„ê¸°
ëª©ì : í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„, ì˜ì¡´ì„± ë§¤í•‘, í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°

Author: GitHub Actions
Created: 2025-01-06
Version: 1.0.0

Dependencies:
    - Python 3.11+
    - ast
    - pathlib
    - json

Performance:
    - ë¶„ì„ ì‹œê°„: < 60ì´ˆ
    - ë©”ëª¨ë¦¬ì‚¬ìš©ëŸ‰: < 200MB
    - ì²˜ë¦¬ìš©ëŸ‰: 1000+ files/minute

Security:
    - íŒŒì¼ ì ‘ê·¼ ê²€ì¦
    - AST íŒŒì‹± ì•ˆì „ì„±
    - ë©”ëª¨ë¦¬ ì œí•œ

License: MIT
"""

from __future__ import annotations

import ast
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Set, Tuple

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class CodeStructureAnalyzer:
    """ì½”ë“œ êµ¬ì¡° ë¶„ì„ê¸°"""

    def __init__(self, project_root: str = "."):
        """ì´ˆê¸°í™” ë©”ì„œë“œ. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•˜ê³ 
        ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if not isinstance(project_root, str):
            raise TypeError("project_rootì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        self.project_root = Path(project_root)
        self.analysis_result: Dict[str, Any] = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "modules": {},
            "dependencies": {},
            "metrics": {},
            "issues": [],
            "recommendations": [],
            "total_files": 0,
            "total_lines": 0,
            "complexity_score": 0.0,
            "maintainability_index": 0.0
        }
        
        logger.info(f"ğŸ—ï¸ ì½”ë“œ êµ¬ì¡° ë¶„ì„ê¸° ì´ˆê¸°í™”(í”„ë¡œì íŠ¸: {self.project_root})")

    def analyze_file_structure(self) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        try:
            total_files = 0
            total_lines = 0
            file_types = {}
            
            for root, dirs, files in os.walk(str(self.project_root)):
                # ì œì™¸í•  ë””ë ‰í† ë¦¬ í•„í„°ë§
                dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', 'venv', 'node_modules', '.pytest_cache'}]
                
                for file in files:
                    file_path = Path(root) / file
                    total_files += 1
                    
                    # íŒŒì¼ í™•ì¥ìë³„ ë¶„ë¥˜
                    ext = file_path.suffix.lower()
                    if ext not in file_types:
                        file_types[ext] = 0
                    file_types[ext] += 1
                    
                    # ë¼ì¸ ìˆ˜ ê³„ì‚° (í…ìŠ¤íŠ¸ íŒŒì¼ë§Œ)
                    if ext in {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.md', '.txt', '.json', '.yaml', '.yml'}:
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                lines = len(f.readlines())
                                total_lines += lines
                        except Exception as e:
                            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path} - {e}")
            
            self.analysis_result.update({
                "total_files": total_files,
                "total_lines": total_lines,
                "file_types": file_types
            })
            
            logger.info(f"íŒŒì¼ êµ¬ì¡° ë¶„ì„ ì™„ë£Œ: {total_files}ê°œ íŒŒì¼, {total_lines}ì¤„")
            return self.analysis_result
            
        except Exception as e:
            logger.error(f"íŒŒì¼ êµ¬ì¡° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self.analysis_result

    def analyze_python_modules(self) -> Dict[str, Any]:
        """Python ëª¨ë“ˆ ë¶„ì„"""
        try:
            python_files = list(self.project_root.rglob("*.py"))
            modules_info = {}
            
            for py_file in python_files:
                if "venv" not in str(py_file) and "__pycache__" not in str(py_file):
                    try:
                        module_info = self._analyze_single_module(py_file)
                        modules_info[str(py_file.relative_to(self.project_root))] = module_info
                    except Exception as e:
                        logger.warning(f"ëª¨ë“ˆ ë¶„ì„ ì‹¤íŒ¨: {py_file} - {e}")
            
            self.analysis_result["modules"] = modules_info
            logger.info(f"Python ëª¨ë“ˆ ë¶„ì„ ì™„ë£Œ: {len(modules_info)}ê°œ ëª¨ë“ˆ")
            return modules_info
            
        except Exception as e:
            logger.error(f"Python ëª¨ë“ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

    def _analyze_single_module(self, file_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë“ˆ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # ê¸°ë³¸ ì •ë³´
            module_info = {
                "file_path": str(file_path.relative_to(self.project_root)),
                "lines": len(content.splitlines()),
                "classes": [],
                "functions": [],
                "imports": [],
                "complexity": 0,
                "has_docstring": False,
                "has_type_hints": False
            }
            
            # í´ë˜ìŠ¤ ë¶„ì„
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_info = {
                        "name": node.name,
                        "methods": len([n for n in node.body if isinstance(n, ast.FunctionDef)]),
                        "has_docstring": ast.get_docstring(node) is not None,
                        "bases": [base.id for base in node.bases if isinstance(base, ast.Name)]
                    }
                    module_info["classes"].append(class_info)
                
                elif isinstance(node, ast.FunctionDef):
                    func_info = {
                        "name": node.name,
                        "args": len(node.args.args),
                        "has_docstring": ast.get_docstring(node) is not None,
                        "has_type_hints": self._has_type_hints(node),
                        "complexity": self._calculate_complexity(node)
                    }
                    module_info["functions"].append(func_info)
                    module_info["complexity"] += func_info["complexity"]
                
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            module_info["imports"].append(alias.name)
                    else:
                        module_info["imports"].append(node.module or "")
            
            # ëª¨ë“ˆ ë ˆë²¨ docstring í™•ì¸
            module_info["has_docstring"] = ast.get_docstring(tree) is not None
            
            return module_info
            
        except Exception as e:
            logger.error(f"ëª¨ë“ˆ ë¶„ì„ ì‹¤íŒ¨: {file_path} - {e}")
            return {"error": str(e)}

    def _has_type_hints(self, func_node: ast.FunctionDef) -> bool:
        """í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        # ë°˜í™˜ íƒ€ì… íŒíŠ¸ í™•ì¸
        if func_node.returns is not None:
            return True
        
        # ë§¤ê°œë³€ìˆ˜ íƒ€ì… íŒíŠ¸ í™•ì¸
        for arg in func_node.args.args:
            if arg.annotation is not None:
                return True
        
        return False

    def _calculate_complexity(self, node: ast.AST) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor, ast.AsyncWith)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity

    def analyze_dependencies(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ë¶„ì„"""
        try:
            dependencies = {
                "internal": {},
                "external": {},
                "circular": []
            }
            
            # ë‚´ë¶€ ì˜ì¡´ì„± ë¶„ì„
            python_files = list(self.project_root.rglob("*.py"))
            for py_file in python_files:
                if "venv" not in str(py_file) and "__pycache__" not in str(py_file):
                    module_name = py_file.stem
                    deps = self._extract_dependencies(py_file)
                    dependencies["internal"][module_name] = deps
            
            # ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
            dependencies["circular"] = self._detect_circular_dependencies(dependencies["internal"])
            
            self.analysis_result["dependencies"] = dependencies
            logger.info(f"ì˜ì¡´ì„± ë¶„ì„ ì™„ë£Œ: {len(dependencies['internal'])}ê°œ ëª¨ë“ˆ")
            return dependencies
            
        except Exception as e:
            logger.error(f"ì˜ì¡´ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

    def _extract_dependencies(self, file_path: Path) -> List[str]:
        """íŒŒì¼ì—ì„œ ì˜ì¡´ì„± ì¶”ì¶œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            deps = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ImportFrom):
                    if node.module:
                        deps.append(node.module)
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        deps.append(alias.name)
            
            return list(set(deps))
            
        except Exception as e:
            logger.warning(f"ì˜ì¡´ì„± ì¶”ì¶œ ì‹¤íŒ¨: {file_path} - {e}")
            return []

    def _detect_circular_dependencies(self, dependencies: Dict[str, List[str]]) -> List[List[str]]:
        """ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€"""
        circular = []
        
        def has_cycle(node: str, visited: Set[str], path: List[str]) -> bool:
            if node in visited:
                if node in path:
                    cycle_start = path.index(node)
                    circular.append(path[cycle_start:] + [node])
                return False
            
            visited.add(node)
            path.append(node)
            
            for dep in dependencies.get(node, []):
                if dep in dependencies:  # ë‚´ë¶€ ëª¨ë“ˆë§Œ í™•ì¸
                    has_cycle(dep, visited, path)
            
            path.pop()
            return False
        
        for module in dependencies:
            has_cycle(module, set(), [])
        
        return circular

    def calculate_metrics(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            metrics = {
                "code_coverage": 0.0,
                "test_coverage": 0.0,
                "documentation_coverage": 0.0,
                "complexity_score": 0.0,
                "maintainability_index": 0.0
            }
            
            # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
            total_complexity = 0
            total_functions = 0
            
            for module_info in self.analysis_result["modules"].values():
                if isinstance(module_info, dict) and "complexity" in module_info:
                    total_complexity += module_info["complexity"]
                    total_functions += len(module_info.get("functions", []))
            
            if total_functions > 0:
                metrics["complexity_score"] = total_complexity / total_functions
            
            # ìœ ì§€ë³´ìˆ˜ì„± ì§€ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
            total_lines = self.analysis_result.get("total_lines", 0)
            if total_lines > 0:
                # ë³µì¡ë„ê°€ ë‚®ê³  ë¬¸ì„œí™”ê°€ ì˜ ë˜ì–´ìˆì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
                doc_coverage = self._calculate_documentation_coverage()
                metrics["documentation_coverage"] = doc_coverage
                metrics["maintainability_index"] = max(0, 100 - metrics["complexity_score"] * 10 + doc_coverage * 20)
            
            self.analysis_result["metrics"] = metrics
            logger.info(f"ë©”íŠ¸ë¦­ ê³„ì‚° ì™„ë£Œ: ë³µì¡ë„={metrics['complexity_score']:.2f}, ìœ ì§€ë³´ìˆ˜ì„±={metrics['maintainability_index']:.2f}")
            return metrics
            
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

    def _calculate_documentation_coverage(self) -> float:
        """ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        try:
            total_modules = len(self.analysis_result["modules"])
            documented_modules = 0
            
            for module_info in self.analysis_result["modules"].values():
                if isinstance(module_info, dict) and module_info.get("has_docstring", False):
                    documented_modules += 1
            
            return documented_modules / total_modules if total_modules > 0 else 0.0
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0

    def generate_recommendations(self) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            # ë³µì¡ë„ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
            complexity_score = self.analysis_result["metrics"].get("complexity_score", 0)
            if complexity_score > 10:
                recommendations.append("í•¨ìˆ˜ì˜ ìˆœí™˜ ë³µì¡ë„ê°€ ë†’ìŠµë‹ˆë‹¤. í•¨ìˆ˜ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            # ë¬¸ì„œí™” ê´€ë ¨ ê¶Œì¥ì‚¬í•­
            doc_coverage = self.analysis_result["metrics"].get("documentation_coverage", 0)
            if doc_coverage < 0.5:
                recommendations.append("ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤. ëª¨ë“ˆê³¼ í•¨ìˆ˜ì— docstringì„ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            # ìˆœí™˜ ì˜ì¡´ì„± ê´€ë ¨ ê¶Œì¥ì‚¬í•­
            circular_deps = self.analysis_result["dependencies"].get("circular", [])
            if circular_deps:
                recommendations.append(f"ìˆœí™˜ ì˜ì¡´ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤: {len(circular_deps)}ê°œ")
            
            # íƒ€ì… íŒíŠ¸ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
            modules_without_types = sum(1 for m in self.analysis_result["modules"].values() 
                                      if isinstance(m, dict) and not m.get("has_type_hints", False))
            if modules_without_types > 0:
                recommendations.append("íƒ€ì… íŒíŠ¸ê°€ ì—†ëŠ” ëª¨ë“ˆì´ ìˆìŠµë‹ˆë‹¤. íƒ€ì… ì•ˆì „ì„±ì„ ìœ„í•´ íƒ€ì… íŒíŠ¸ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            self.analysis_result["recommendations"] = recommendations
            logger.info(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì™„ë£Œ: {len(recommendations)}ê°œ")
            return recommendations
            
        except Exception as e:
            logger.error(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def run_full_analysis(self) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        try:
            logger.info("ğŸ” ì „ì²´ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ì‹œì‘")
            
            # 1. íŒŒì¼ êµ¬ì¡° ë¶„ì„
            self.analyze_file_structure()
            
            # 2. Python ëª¨ë“ˆ ë¶„ì„
            self.analyze_python_modules()
            
            # 3. ì˜ì¡´ì„± ë¶„ì„
            self.analyze_dependencies()
            
            # 4. ë©”íŠ¸ë¦­ ê³„ì‚°
            self.calculate_metrics()
            
            # 5. ê¶Œì¥ì‚¬í•­ ìƒì„±
            self.generate_recommendations()
            
            logger.info("âœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ")
            return self.analysis_result
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def save_analysis_result(self, output_path: str = "code_analysis_result.json") -> bool:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_result, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        analyzer = CodeStructureAnalyzer()
        result = analyzer.run_full_analysis()
        
        if "error" not in result:
            analyzer.save_analysis_result()
            print("âœ… ì½”ë“œ êµ¬ì¡° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {result['total_files']}")
            print(f"ğŸ“Š ì´ ë¼ì¸ ìˆ˜: {result['total_lines']}")
            print(f"ğŸ“Š Python ëª¨ë“ˆ ìˆ˜: {len(result['modules'])}")
            print(f"ğŸ“Š ë³µì¡ë„ ì ìˆ˜: {result['metrics']['complexity_score']:.2f}")
            print(f"ğŸ“Š ìœ ì§€ë³´ìˆ˜ì„± ì§€ìˆ˜: {result['metrics']['maintainability_index']:.2f}")
        else:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
            
    except Exception as e:
        logger.error(f"ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()

