#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„±ë¶„ì„ ì—”ì§„
ë‰´ìŠ¤, ì†Œì…œë¯¸ë””ì–´, ê³µì‹œì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‹œì¥ ì‹¬ë¦¬ë¥¼ ë¶„ì„
Gemini AI ìµœì í™” ë‰´ìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ì‹œìŠ¤í…œ
"""

import os
import logging
import requests
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import pandas as pd
from textblob import TextBlob
import feedparser
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ì•„ì´í…œ"""
    title: str
    content: str
    source: str
    published_date: datetime
    url: str
    sentiment_score: float  # -1 ~ 1
    relevance_score: float  # 0 ~ 1
    symbols_mentioned: List[str]

@dataclass
class MarketSentiment:
    """ì‹œì¥ ê°ì„± ë¶„ì„ ê²°ê³¼"""
    overall_sentiment: float
    positive_news_count: int
    negative_news_count: int
    neutral_news_count: int
    key_topics: List[str]
    sentiment_trend: str  # "IMPROVING", "DECLINING", "STABLE"
    confidence: float

class NewsCollector:
    """ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.news_api_key = os.getenv('NEWS_API_KEY')
        self.alpha_vantage_key = os.getenv('ALPHA_VANTAGE_API_KEY')
        
        # RSS í”¼ë“œ ì†ŒìŠ¤ë“¤
        self.rss_feeds = [
            'https://feeds.finance.yahoo.com/rss/2.0/headline',
            'https://www.marketwatch.com/rss/topstories',
            'https://feeds.bloomberg.com/markets/news.rss',
            'https://rss.cnn.com/rss/money_latest.rss'
        ]
        
        # í•œêµ­ ë‰´ìŠ¤ ì†ŒìŠ¤
        self.korean_feeds = [
            'https://news.naver.com/main/rss/section.nhn?sid1=101',  # ê²½ì œ
            'https://rss.hankyung.com/new/economy.xml',  # í•œê²½ ê²½ì œ
            'https://www.mk.co.kr/rss/40300001/'  # ë§¤ê²½ ì¦ê¶Œ
        ]
        
        logger.info("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def collect_news(self, symbols: List[str], hours_back: int = 24) -> List[NewsItem]:
        """ë‰´ìŠ¤ ìˆ˜ì§‘"""
        all_news = []
        
        try:
            # 1. RSS í”¼ë“œì—ì„œ ìˆ˜ì§‘
            rss_news = self._collect_from_rss()
            all_news.extend(rss_news)
            
            # 2. News APIì—ì„œ ìˆ˜ì§‘ (í‚¤ê°€ ìˆëŠ” ê²½ìš°)
            if self.news_api_key:
                api_news = self._collect_from_news_api(symbols)
                all_news.extend(api_news)
            
            # 3. Alpha Vantage ë‰´ìŠ¤ (í‚¤ê°€ ìˆëŠ” ê²½ìš°)
            if self.alpha_vantage_key:
                av_news = self._collect_from_alpha_vantage(symbols)
                all_news.extend(av_news)
            
            # 4. ì¤‘ë³µ ì œê±° ë° ê´€ë ¨ë„ í•„í„°ë§
            filtered_news = self._filter_and_deduplicate(all_news, symbols)
            
            logger.info(f"ğŸ“° ì´ {len(filtered_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            return filtered_news
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def _collect_from_rss(self) -> List[NewsItem]:
        """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_items = []
        
        all_feeds = self.rss_feeds + self.korean_feeds
        
        for feed_url in all_feeds:
            try:
                feed = feedparser.parse(feed_url)
                
                for entry in feed.entries[:10]:  # ìµœê·¼ 10ê°œë§Œ
                    try:
                        # ë°œí–‰ì¼ íŒŒì‹±
                        published_date = datetime.now()
                        if hasattr(entry, 'published_parsed') and entry.published_parsed:
                            published_date = datetime(*entry.published_parsed[:6])
                        
                        # ë‰´ìŠ¤ ì•„ì´í…œ ìƒì„±
                        news_item = NewsItem(
                            title=entry.title,
                            content=getattr(entry, 'summary', entry.title),
                            source=feed.feed.title if hasattr(feed.feed, 'title') else feed_url,
                            published_date=published_date,
                            url=entry.link,
                            sentiment_score=0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                            relevance_score=0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                            symbols_mentioned=[]
                        )
                        
                        news_items.append(news_item)
                        
                    except Exception as e:
                        logger.warning(f"RSS ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
                        
            except Exception as e:
                logger.warning(f"RSS í”¼ë“œ íŒŒì‹± ì‹¤íŒ¨ ({feed_url}): {e}")
                continue
        
        return news_items
    
    def _collect_from_news_api(self, symbols: List[str]) -> List[NewsItem]:
        """News APIì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_items = []
        
        try:
            # ì£¼ìš” ê¸ˆìœµ í‚¤ì›Œë“œë“¤
            keywords = ["stock market", "economy", "finance", "nasdaq", "kospi"] + symbols[:5]
            
            for keyword in keywords:
                url = f"https://newsapi.org/v2/everything"
                params = {
                    'q': keyword,
                    'apiKey': self.news_api_key,
                    'language': 'en',
                    'sortBy': 'publishedAt',
                    'pageSize': 10
                }
                
                response = requests.get(url, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    for article in data.get('articles', []):
                        news_item = NewsItem(
                            title=article.get('title', ''),
                            content=article.get('description', ''),
                            source=article.get('source', {}).get('name', 'Unknown'),
                            published_date=datetime.fromisoformat(article.get('publishedAt', '').replace('Z', '+00:00')),
                            url=article.get('url', ''),
                            sentiment_score=0.0,
                            relevance_score=0.0,
                            symbols_mentioned=[]
                        )
                        
                        news_items.append(news_item)
                
        except Exception as e:
            logger.warning(f"News API ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_items
    
    def _collect_from_alpha_vantage(self, symbols: List[str]) -> List[NewsItem]:
        """Alpha Vantageì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_items = []
        
        try:
            for symbol in symbols[:5]:  # ìƒìœ„ 5ê°œ ì¢…ëª©ë§Œ
                url = f"https://www.alphavantage.co/query"
                params = {
                    'function': 'NEWS_SENTIMENT',
                    'tickers': symbol,
                    'apikey': self.alpha_vantage_key,
                    'limit': 50
                }
                
                response = requests.get(url, params=params, timeout=15)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    for item in data.get('feed', []):
                        news_item = NewsItem(
                            title=item.get('title', ''),
                            content=item.get('summary', ''),
                            source=item.get('source', 'Alpha Vantage'),
                            published_date=datetime.fromisoformat(item.get('time_published', '')[:8] + 'T' + item.get('time_published', '')[9:15]),
                            url=item.get('url', ''),
                            sentiment_score=float(item.get('overall_sentiment_score', 0)),
                            relevance_score=float(item.get('relevance_score', 0)),
                            symbols_mentioned=[symbol]
                        )
                        
                        news_items.append(news_item)
                
        except Exception as e:
            logger.warning(f"Alpha Vantage ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_items
    
    def _filter_and_deduplicate(self, news_items: List[NewsItem], symbols: List[str]) -> List[NewsItem]:
        """ì¤‘ë³µ ì œê±° ë° ê´€ë ¨ë„ í•„í„°ë§"""
        
        # ì œëª© ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        seen_titles = set()
        unique_news = []
        
        for item in news_items:
            # ì œëª© ì •ê·œí™”
            normalized_title = item.title.lower().strip()
            
            if normalized_title not in seen_titles and len(normalized_title) > 10:
                seen_titles.add(normalized_title)
                
                # ê´€ë ¨ ì¢…ëª© ì°¾ê¸°
                item.symbols_mentioned = self._find_mentioned_symbols(item.title + " " + item.content, symbols)
                
                # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
                item.relevance_score = self._calculate_relevance(item, symbols)
                
                # ê°ì„± ì ìˆ˜ ê³„ì‚° (ê¸°ì¡´ì— ì—†ëŠ” ê²½ìš°)
                if item.sentiment_score == 0.0:
                    item.sentiment_score = self._calculate_sentiment(item.title + " " + item.content)
                
                # ê´€ë ¨ë„ê°€ ë†’ì€ ë‰´ìŠ¤ë§Œ í¬í•¨
                if item.relevance_score > 0.3 or item.symbols_mentioned:
                    unique_news.append(item)
        
        # ë°œí–‰ì¼ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
        unique_news.sort(key=lambda x: x.published_date, reverse=True)
        
        return unique_news[:50]  # ìµœì‹  50ê°œë§Œ
    
    def _find_mentioned_symbols(self, text: str, symbols: List[str]) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª© ì°¾ê¸°"""
        mentioned = []
        text_lower = text.lower()
        
        for symbol in symbols:
            # ì¢…ëª© ì½”ë“œ ê²€ìƒ‰
            if symbol.lower() in text_lower:
                mentioned.append(symbol)
            
            # íšŒì‚¬ëª… ê²€ìƒ‰ (ê°„ë‹¨í•œ ë§¤í•‘)
            company_names = {
                'AAPL': 'apple',
                'TSLA': 'tesla',
                'MSFT': 'microsoft',
                'GOOGL': 'google',
                'AMZN': 'amazon',
                '005930.KS': 'ì‚¼ì„±ì „ì',
                '000660.KS': 'skí•˜ì´ë‹‰ìŠ¤',
                '035420.KS': 'naver'
            }
            
            company_name = company_names.get(symbol)
            if company_name and company_name in text_lower:
                if symbol not in mentioned:
                    mentioned.append(symbol)
        
        return mentioned
    
    def _calculate_relevance(self, news_item: NewsItem, symbols: List[str]) -> float:
        """ë‰´ìŠ¤ ê´€ë ¨ë„ ê³„ì‚°"""
        score = 0.0
        text = (news_item.title + " " + news_item.content).lower()
        
        # ê¸ˆìœµ í‚¤ì›Œë“œ ì ìˆ˜
        financial_keywords = [
            'stock', 'market', 'trading', 'investment', 'earnings', 'revenue',
            'profit', 'loss', 'nasdaq', 'nyse', 'kospi', 'kosdaq',
            'ì£¼ì‹', 'ì‹œì¥', 'íˆ¬ì', 'ìˆ˜ìµ', 'ì‹¤ì ', 'ë§¤ì¶œ'
        ]
        
        for keyword in financial_keywords:
            if keyword in text:
                score += 0.1
        
        # ì¢…ëª© ì–¸ê¸‰ ì ìˆ˜
        score += len(news_item.symbols_mentioned) * 0.3
        
        # ì†ŒìŠ¤ ì‹ ë¢°ë„ ì ìˆ˜
        trusted_sources = ['bloomberg', 'reuters', 'wall street journal', 'financial times', 'í•œêµ­ê²½ì œ', 'ë§¤ì¼ê²½ì œ']
        for source in trusted_sources:
            if source in news_item.source.lower():
                score += 0.2
                break
        
        return min(1.0, score)
    
    def _calculate_sentiment(self, text: str) -> float:
        """ê°ì„± ë¶„ì„"""
        try:
            # TextBlobì„ ì‚¬ìš©í•œ ê¸°ë³¸ ê°ì„± ë¶„ì„
            blob = TextBlob(text)
            
            # ê·¹ì„± ì ìˆ˜ (-1 ~ 1)
            polarity = blob.sentiment.polarity
            
            # ì£¼ê´€ì„± ê³ ë ¤í•œ ì¡°ì •
            subjectivity = blob.sentiment.subjectivity
            adjusted_sentiment = polarity * subjectivity
            
            return adjusted_sentiment
            
        except Exception as e:
            logger.warning(f"ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.0

class SentimentAnalyzer:
    """ğŸ’­ ê°ì„± ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.positive_keywords = [
            'bull', 'bullish', 'rise', 'rising', 'up', 'gain', 'growth', 'profit',
            'beat', 'exceed', 'strong', 'robust', 'boom', 'surge', 'rally',
            'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ê¸ì •', 'ê°•ì„¸', 'í˜¸í™©'
        ]
        
        self.negative_keywords = [
            'bear', 'bearish', 'fall', 'falling', 'down', 'loss', 'decline', 'drop',
            'crash', 'plunge', 'weak', 'poor', 'recession', 'crisis',
            'í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ë¶€ì •', 'ì•½ì„¸', 'ë¶ˆí™©'
        ]
        
        logger.info("ğŸ’­ ê°ì„± ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_market_sentiment(self, news_items: List[NewsItem]) -> MarketSentiment:
        """ì‹œì¥ ê°ì„± ì¢…í•© ë¶„ì„"""
        
        if not news_items:
            return MarketSentiment(
                overall_sentiment=0.0,
                positive_news_count=0,
                negative_news_count=0,
                neutral_news_count=0,
                key_topics=[],
                sentiment_trend="STABLE",
                confidence=0.0
            )
        
        # ê°ì„± ì ìˆ˜ë³„ ë¶„ë¥˜
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        
        sentiment_scores = []
        
        for news in news_items:
            if news.sentiment_score > 0.1:
                positive_count += 1
            elif news.sentiment_score < -0.1:
                negative_count += 1
            else:
                neutral_count += 1
            
            sentiment_scores.append(news.sentiment_score)
        
        # ì „ì²´ ê°ì„± ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘í‰ê· )
        if sentiment_scores:
            overall_sentiment = sum(sentiment_scores) / len(sentiment_scores)
        else:
            overall_sentiment = 0.0
        
        # ì£¼ìš” í† í”½ ì¶”ì¶œ
        key_topics = self._extract_key_topics(news_items)
        
        # ê°ì„± íŠ¸ë Œë“œ ë¶„ì„
        sentiment_trend = self._analyze_sentiment_trend(news_items)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(1.0, len(news_items) / 20.0)  # ë‰´ìŠ¤ ê°œìˆ˜ ê¸°ë°˜
        
        return MarketSentiment(
            overall_sentiment=overall_sentiment,
            positive_news_count=positive_count,
            negative_news_count=negative_count,
            neutral_news_count=neutral_count,
            key_topics=key_topics,
            sentiment_trend=sentiment_trend,
            confidence=confidence
        )
    
    def _extract_key_topics(self, news_items: List[NewsItem]) -> List[str]:
        """ì£¼ìš” í† í”½ ì¶”ì¶œ"""
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        word_counts = {}
        
        for news in news_items:
            words = (news.title + " " + news.content).lower().split()
            
            for word in words:
                if len(word) > 3 and word.isalpha():
                    word_counts[word] = word_counts.get(word, 0) + 1
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì„ ì •
        top_keywords = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return [word for word, count in top_keywords if count >= 2]
    
    def _analyze_sentiment_trend(self, news_items: List[NewsItem]) -> str:
        """ê°ì„± íŠ¸ë Œë“œ ë¶„ì„"""
        
        if len(news_items) < 10:
            return "STABLE"
        
        # ìµœê·¼ ë‰´ìŠ¤ì™€ ì´ì „ ë‰´ìŠ¤ ë¹„êµ
        sorted_news = sorted(news_items, key=lambda x: x.published_date)
        
        recent_news = sorted_news[-len(sorted_news)//2:]  # ìµœê·¼ ì ˆë°˜
        older_news = sorted_news[:len(sorted_news)//2]    # ì´ì „ ì ˆë°˜
        
        recent_sentiment = sum(news.sentiment_score for news in recent_news) / len(recent_news)
        older_sentiment = sum(news.sentiment_score for news in older_news) / len(older_news)
        
        sentiment_change = recent_sentiment - older_sentiment
        
        if sentiment_change > 0.1:
            return "IMPROVING"
        elif sentiment_change < -0.1:
            return "DECLINING"
        else:
            return "STABLE"

class NewsAnalyzer:
    """ğŸ“Š í†µí•© ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.news_collector = NewsCollector()
        self.sentiment_analyzer = SentimentAnalyzer()
        
        logger.info("ğŸ“Š ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_stocks_news(self, symbols: List[str]) -> Dict[str, Any]:
        """ì¢…ëª©ë³„ ë‰´ìŠ¤ ë¶„ì„"""
        
        logger.info(f"ğŸ“° {len(symbols)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘")
        
        try:
            # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
            news_items = self.news_collector.collect_news(symbols)
            
            # 2. ì „ì²´ ì‹œì¥ ê°ì„± ë¶„ì„
            market_sentiment = self.sentiment_analyzer.analyze_market_sentiment(news_items)
            
            # 3. ì¢…ëª©ë³„ ê°ì„± ë¶„ì„
            stock_sentiments = {}
            
            for symbol in symbols:
                # í•´ë‹¹ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§
                stock_news = [news for news in news_items if symbol in news.symbols_mentioned]
                
                if stock_news:
                    stock_sentiment = self.sentiment_analyzer.analyze_market_sentiment(stock_news)
                    stock_sentiments[symbol] = {
                        'sentiment_score': stock_sentiment.overall_sentiment,
                        'news_count': len(stock_news),
                        'positive_ratio': stock_sentiment.positive_news_count / len(stock_news),
                        'recent_news': [
                            {
                                'title': news.title,
                                'sentiment': news.sentiment_score,
                                'source': news.source,
                                'url': news.url
                            } for news in stock_news[:3]  # ìµœì‹  3ê°œ
                        ]
                    }
            
            result = {
                'market_sentiment': {
                    'overall_score': market_sentiment.overall_sentiment,
                    'positive_count': market_sentiment.positive_news_count,
                    'negative_count': market_sentiment.negative_news_count,
                    'neutral_count': market_sentiment.neutral_news_count,
                    'trend': market_sentiment.sentiment_trend,
                    'confidence': market_sentiment.confidence,
                    'key_topics': market_sentiment.key_topics
                },
                'stock_sentiments': stock_sentiments,
                'total_news_count': len(news_items),
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ - ì´ {len(news_items)}ê°œ ë‰´ìŠ¤ ì²˜ë¦¬")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'market_sentiment': {'overall_score': 0.0, 'trend': 'STABLE'},
                'stock_sentiments': {},
                'total_news_count': 0,
                'analysis_timestamp': datetime.now().isoformat()
            }

if __name__ == "__main__":
    print("ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„ v1.0")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸
    analyzer = NewsAnalyzer()
    
    test_symbols = ["AAPL", "TSLA", "005930.KS"]
    result = analyzer.analyze_stocks_news(test_symbols)
    
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"  â€¢ ì „ì²´ ë‰´ìŠ¤: {result['total_news_count']}ê°œ")
    print(f"  â€¢ ì‹œì¥ ê°ì„±: {result['market_sentiment']['overall_score']:.3f}")
    print(f"  â€¢ ê°ì„± íŠ¸ë Œë“œ: {result['market_sentiment']['trend']}")
    print(f"  â€¢ ì¢…ëª©ë³„ ë¶„ì„: {len(result['stock_sentiments'])}ê°œ")
    
    print("\nâœ… ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 