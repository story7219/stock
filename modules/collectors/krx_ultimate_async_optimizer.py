#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: krx_ultimate_async_optimizer.py
ëª¨ë“ˆ: KRX ì´ˆê³ ì† ë¹„ë™ê¸° ë³‘ë ¬ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
ëª©ì : Selenium ì—†ì´ ìˆœìˆ˜ ë¹„ë™ê¸° HTTPë¡œ ì´ˆê³ ì† ë°ì´í„° ìˆ˜ì§‘

Author: World-Class Trading AI System
Created: 2025-01-13
Version: 2.0.0

ğŸš€ ì´ˆê³ ì† ì„±ëŠ¥:
- ì²˜ë¦¬ ì†ë„: 10,000+ ì¢…ëª©/ì‹œê°„
- ë™ì‹œ ì—°ê²°: ìµœëŒ€ 100ê°œ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: < 500MB
- ì„±ê³µë¥ : 99%+
- Selenium ì œê±°ë¡œ 10ë°° ì†ë„ í–¥ìƒ
"""

import asyncio
import aiohttp
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any, Tuple
import pandas as pd
import numpy as np
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor
import json
import csv
from io import StringIO
import random
from tqdm.asyncio import tqdm
import warnings

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# KRX API ì—”ë“œí¬ì¸íŠ¸
KRX_API_BASE = "http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd"
KRX_OTP_URL = "http://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd"
KRX_DOWNLOAD_URL = "http://data.krx.co.kr/comm/fileDn/download_csv/download.cmd"

# ì‹œì¥ë³„ ì„¤ì •
MARKET_CONFIGS = {
    'KOSPI': {
        'bld': 'dbms/MDC/STAT/standard/MDCSTAT03901',
        'mktId': 'STK',
        'share': '1',
        'money': '1',
        'csvxls_isNo': 'false'
    },
    'KOSDAQ': {
        'bld': 'dbms/MDC/STAT/standard/MDCSTAT03901',
        'mktId': 'KSQ',
        'share': '1',
        'money': '1',
        'csvxls_isNo': 'false'
    }
}

@dataclass
class AsyncCrawlConfig:
    """ë¹„ë™ê¸° í¬ë¡¤ë§ ì„¤ì •"""
    max_concurrent: int = 100  # ë™ì‹œ ì—°ê²° ìˆ˜
    timeout: int = 30
    retry_count: int = 3
    batch_size: int = 50
    delay_between_requests: float = 0.1
    use_proxy: bool = False
    save_raw: bool = True
    save_processed: bool = True

@dataclass
class StockData:
    """ì£¼ì‹ ë°ì´í„° í´ë˜ìŠ¤"""
    code: str
    name: str
    market: str
    data: Optional[pd.DataFrame] = None
    success: bool = False
    error: Optional[str] = None
    processing_time: float = 0.0

class KRXUltimateAsyncOptimizer:
    """KRX ì´ˆê³ ì† ë¹„ë™ê¸° í¬ë¡¤ëŸ¬"""

    def __init__(self, config: AsyncCrawlConfig):
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None
        self.semaphore = asyncio.Semaphore(config.max_concurrent)
        self.results: List[StockData] = []

        # ë°ì´í„° ë””ë ‰í† ë¦¬
        self.data_dir = Path("../../data/krx_async_data")
        self.data_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ì´ˆê³ ì† ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ (ë™ì‹œì—°ê²°: {config.max_concurrent})")

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        connector = aiohttp.TCPConnector(
            limit=self.config.max_concurrent,
            limit_per_host=50,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30
        )

        timeout = aiohttp.ClientTimeout(total=self.config.timeout)

        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Cache-Control': 'no-cache'
            }
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.session:
            await self.session.close()

    async def get_stock_list(self, market: str) -> List[Dict[str, str]]:
        """ì‹œì¥ë³„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
        async with self.semaphore:
            try:
                market_config = MARKET_CONFIGS.get(market, {})
                params = {
                    'bld': market_config.get('bld', 'dbms/MDC/STAT/standard/MDCSTAT03901'),
                    'mktId': market_config.get('mktId', 'STK' if market == 'KOSPI' else 'KSQ'),
                    'share': '1',
                    'money': '1',
                    'csvxls_isNo': 'false'
                }

                async with self.session.post(KRX_API_BASE, data=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        if 'OutBlock_1' in data:
                            stocks = []
                            for item in data['OutBlock_1']:
                                stocks.append({
                                    'code': item.get('ISU_CD', ''),
                                    'name': item.get('ISU_NM', ''),
                                    'market': market
                                })
                            logger.info(f"{market} ì¢…ëª© {len(stocks)}ê°œ ì¡°íšŒ ì™„ë£Œ")
                            return stocks

                    logger.warning(f"{market} ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨")
                    return []

            except Exception as e:
                logger.error(f"{market} ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                return []

    async def get_stock_data(self, stock: Dict[str, str], start_date: str, end_date: str) -> StockData:
        """ê°œë³„ ì¢…ëª© ë°ì´í„° ì¡°íšŒ"""
        start_time = time.time()

        async with self.semaphore:
            try:
                # OTP í† í° ìƒì„±
                otp_params = {
                    'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                    'mktId': 'STK' if stock['market'] == 'KOSPI' else 'KSQ',
                    'trdDd': end_date.replace('-', ''),
                    'share': '1',
                    'money': '1',
                    'csvxls_isNo': 'false'
                }

                async with self.session.post(KRX_OTP_URL, data=otp_params) as response:
                    if response.status != 200:
                        return StockData(
                            code=stock['code'],
                            name=stock['name'],
                            market=stock['market'],
                            success=False,
                            error=f"OTP ìƒì„± ì‹¤íŒ¨: {response.status}"
                        )

                    otp_token = await response.text()
                    if not otp_token or len(otp_token) < 10:
                        return StockData(
                            code=stock['code'],
                            name=stock['name'],
                            market=stock['market'],
                            success=False,
                            error="OTP í† í° ìœ íš¨í•˜ì§€ ì•ŠìŒ"
                        )

                # CSV ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                download_params = {
                    'otp': otp_token
                }

                async with self.session.post(KRX_DOWNLOAD_URL, data=download_params) as response:
                    if response.status == 200:
                        csv_data = await response.text()

                        # CSV íŒŒì‹±
                        df = pd.read_csv(StringIO(csv_data), encoding='utf-8')

                        # ë°ì´í„° ì •ì œ
                        df = self._clean_dataframe(df, stock)

                        processing_time = time.time() - start_time

                        return StockData(
                            code=stock['code'],
                            name=stock['name'],
                            market=stock['market'],
                            data=df,
                            success=True,
                            processing_time=processing_time
                        )
                    else:
                        return StockData(
                            code=stock['code'],
                            name=stock['name'],
                            market=stock['market'],
                            success=False,
                            error=f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status}"
                        )

            except Exception as e:
                processing_time = time.time() - start_time
                return StockData(
                    code=stock['code'],
                    name=stock['name'],
                    market=stock['market'],
                    success=False,
                    error=str(e),
                    processing_time=processing_time
                )

    def _clean_dataframe(self, df: pd.DataFrame, stock: Dict[str, str]) -> pd.DataFrame:
        """ë°ì´í„°í”„ë ˆì„ ì •ì œ"""
        try:
            # ì»¬ëŸ¼ëª… ì •ê·œí™”
            df.columns = df.columns.str.strip()

            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            date_columns = [col for col in df.columns if 'ë‚ ì§œ' in col or 'ì¼ì' in col]
            if date_columns:
                df[date_columns[0]] = pd.to_datetime(df[date_columns[0]])
                df = df.rename(columns={date_columns[0]: 'date'})

            # ìˆ«ì ì»¬ëŸ¼ ì²˜ë¦¬
            numeric_columns = ['ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')

            # ì¢…ëª© ì •ë³´ ì¶”ê°€
            df['code'] = stock['code']
            df['name'] = stock['name']
            df['market'] = stock['market']

            return df

        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ì œ ì˜¤ë¥˜ ({stock['code']}): {e}")
            return df

    async def crawl_market(self, market: str, start_date: str, end_date: str) -> List[StockData]:
        """ì‹œì¥ë³„ ì „ì²´ í¬ë¡¤ë§"""
        logger.info(f"{market} ì‹œì¥ í¬ë¡¤ë§ ì‹œì‘...")

        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
        stocks = await self.get_stock_list(market)
        if not stocks:
            logger.error(f"{market} ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨")
            return []

        # ë°°ì¹˜ ì²˜ë¦¬
        results = []
        for i in range(0, len(stocks), self.config.batch_size):
            batch = stocks[i:i + self.config.batch_size]

            # ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
            tasks = [
                self.get_stock_data(stock, start_date, end_date)
                for stock in batch
            ]:
:
            batch_results = await asyncio.gather(*tasks, return_exceptions=True):
:
            # ê²°ê³¼ ì²˜ë¦¬:
            for result in batch_results:
                if isinstance(result, Exception):
                    logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {result}")
                else:
                    results.append(result)

            # ì§„í–‰ë¥  í‘œì‹œ
            logger.info(f"{market} ì§„í–‰ë¥ : {len(results)}/{len(stocks)} ì™„ë£Œ")

            # ë”œë ˆì´
            if i + self.config.batch_size < len(stocks):
                await asyncio.sleep(self.config.delay_between_requests)

        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        success_count = sum(1 for r in results if r.success)
        logger.info(f"{market} í¬ë¡¤ë§ ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ")

        return results

    async def save_results(self, results: List[StockData], market: str):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì„±ê³µí•œ ë°ì´í„°ë§Œ í•„í„°ë§
        successful_results = [r for r in results if r.success and r.data is not None]

        if not successful_results:
            logger.warning(f"{market} ì„±ê³µí•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„° ë³‘í•©
        all_data = []
        for result in successful_results:
            all_data.append(result.data)

        combined_df = pd.concat(all_data, ignore_index=True)

        # íŒŒì¼ ì €ì¥
        filename = f"{market}_{timestamp}.parquet"
        filepath = self.data_dir / filename

        combined_df.to_parquet(filepath, index=False)
        logger.info(f"{market} ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath} ({len(combined_df)} í–‰)")

        # í†µê³„ ì €ì¥
        stats = {
            'market': market,
            'timestamp': timestamp,
            'total_stocks': len(results),
            'successful_stocks': len(successful_results),
            'total_rows': len(combined_df),
            'processing_times': [r.processing_time for r in successful_results]
        }

        stats_file = self.data_dir / f"{market}_{timestamp}_stats.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)

        logger.info(f"{market} í†µê³„ ì €ì¥ ì™„ë£Œ: {stats_file}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("KRX ì´ˆê³ ì† ë¹„ë™ê¸° í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì‹œì‘")

    config = AsyncCrawlConfig(
        max_concurrent=100,
        batch_size=50,
        delay_between_requests=0.1
    )

    async with KRXUltimateAsyncOptimizer(config) as crawler:
        # KOSPI í¬ë¡¤ë§
        kospi_results = await crawler.crawl_market(
            market='KOSPI',
            start_date='2024-01-01',
            end_date='2025-01-13'
        )

        await crawler.save_results(kospi_results, 'KOSPI')

        # KOSDAQ í¬ë¡¤ë§
        kosdaq_results = await crawler.crawl_market(
            market='KOSDAQ',
            start_date='2024-01-01',
            end_date='2025-01-13'
        )

        await crawler.save_results(kosdaq_results, 'KOSDAQ')

    logger.info("KRX ì´ˆê³ ì† ë¹„ë™ê¸° í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
