#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: find_krx_recent_data.py
ëª©ì : ìµœê·¼ ë‚ ì§œë¶€í„° ì‹œì‘í•´ì„œ KRXì—ì„œ ì‹¤ì œë¡œ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆëŠ” ë‚ ì§œ ì°¾ê¸°
"""

import asyncio
import aiohttp
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class KRXRecentDataFinder:
    """KRX ìµœê·¼ ë°ì´í„° ë‚ ì§œ ì°¾ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_url = "http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd"
        self.session = None
        
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            connector=aiohttp.TCPConnector(limit=10, limit_per_host=5)
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.session:
            await self.session.close()
    
    async def test_date_for_data(self, date_str: str, data_type: str = "stock") -> Tuple[bool, Dict]:
        """íŠ¹ì • ë‚ ì§œì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
        try:
            if data_type == "stock":
                params = {
                    'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                    'mktId': 'STK',
                    'trdDd': date_str,
                    'share': '1',
                    'money': '1',
                    'csvxls_isNo': 'false'
                }
            elif data_type == "etf":
                params = {
                    'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                    'mktId': 'ETF',
                    'trdDd': date_str,
                    'share': '1',
                    'money': '1',
                    'csvxls_isNo': 'false'
                }
            elif data_type == "index":
                params = {
                    'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                    'mktId': 'IDX',
                    'trdDd': date_str,
                    'share': '1',
                    'money': '1',
                    'csvxls_isNo': 'false'
                }
            else:
                return False, {}
            
            async with self.session.post(self.base_url, data=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get('OutBlock_1') and len(data['OutBlock_1']) > 0:
                        return True, data
                    else:
                        return False, data
                else:
                    return False, {}
                    
        except Exception as e:
            logger.error(f"ë‚ ì§œ {date_str} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False, {}
    
    async def find_recent_data(self, days_back: int = 30) -> Dict:
        """ìµœê·¼ Nì¼ë¶€í„° ì‹œì‘í•´ì„œ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ì°¾ê¸°"""
        logger.info(f"ìµœê·¼ {days_back}ì¼ë¶€í„° ë°ì´í„° ê²€ìƒ‰ ì‹œì‘...")
        
        current_date = datetime.now()
        found_data = []
        
        for i in range(days_back):
            test_date = current_date - timedelta(days=i)
            date_str = test_date.strftime("%Y%m%d")
            
            logger.info(f"í…ŒìŠ¤íŠ¸ ë‚ ì§œ: {test_date.strftime('%Y-%m-%d')}")
            
            for data_type in ["stock", "etf", "index"]:
                has_data, data = await self.test_date_for_data(date_str, data_type)
                
                if has_data:
                    logger.info(f"âœ… {test_date.strftime('%Y-%m-%d')} {data_type} ë°ì´í„° ë°œê²¬!")
                    found_data.append({
                        'date': test_date,
                        'date_str': date_str,
                        'data_type': data_type,
                        'data_count': len(data.get('OutBlock_1', [])),
                        'sample_data': data
                    })
                    break
            
            await asyncio.sleep(0.5)  # API ì œí•œ ë°©ì§€
        
        return found_data
    
    async def find_earliest_from_recent(self, start_date: datetime, days_to_search: int = 365) -> Dict:
        """íŠ¹ì • ë‚ ì§œë¶€í„° ê³¼ê±°ë¡œ ê²€ìƒ‰í•´ì„œ ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì°¾ê¸°"""
        logger.info(f"{start_date.strftime('%Y-%m-%d')}ë¶€í„° {days_to_search}ì¼ ì „ê¹Œì§€ ê²€ìƒ‰...")
        
        earliest_found = None
        
        for i in range(days_to_search):
            test_date = start_date - timedelta(days=i)
            date_str = test_date.strftime("%Y%m%d")
            
            if i % 10 == 0:  # 10ì¼ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                logger.info(f"ê²€ìƒ‰ ì§„í–‰: {test_date.strftime('%Y-%m-%d')}")
            
            for data_type in ["stock", "etf", "index"]:
                has_data, data = await self.test_date_for_data(date_str, data_type)
                
                if has_data:
                    logger.info(f"âœ… {test_date.strftime('%Y-%m-%d')} {data_type} ë°ì´í„° ë°œê²¬!")
                    if earliest_found is None or test_date < earliest_found['date']:
                        earliest_found = {
                            'date': test_date,
                            'date_str': date_str,
                            'data_type': data_type,
                            'data_count': len(data.get('OutBlock_1', [])),
                            'sample_data': data
                        }
                    break
            
            await asyncio.sleep(0.3)  # API ì œí•œ ë°©ì§€
        
        return earliest_found

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("KRX ìµœê·¼ ë°ì´í„° ë‚ ì§œ ì°¾ê¸° ì‹œì‘...")
    
    async with KRXRecentDataFinder() as finder:
        # 1ë‹¨ê³„: ìµœê·¼ 30ì¼ ë°ì´í„° ê²€ìƒ‰
        logger.info("=== 1ë‹¨ê³„: ìµœê·¼ 30ì¼ ë°ì´í„° ê²€ìƒ‰ ===")
        recent_data = await finder.find_recent_data(30)
        
        if recent_data:
            logger.info(f"ìµœê·¼ ë°ì´í„° ë°œê²¬: {len(recent_data)}ê°œ")
            
            # ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì°¾ê¸°
            earliest_recent = min(recent_data, key=lambda x: x['date'])
            logger.info(f"ìµœê·¼ ë°ì´í„° ì¤‘ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ: {earliest_recent['date'].strftime('%Y-%m-%d')} ({earliest_recent['data_type']})")
            
            # 2ë‹¨ê³„: í•´ë‹¹ ë‚ ì§œë¶€í„° ê³¼ê±°ë¡œ ë” ê²€ìƒ‰
            logger.info("=== 2ë‹¨ê³„: ê³¼ê±° ë°ì´í„° ìƒì„¸ ê²€ìƒ‰ ===")
            earliest_data = await finder.find_earliest_from_recent(earliest_recent['date'], 365)
            
            if earliest_data:
                logger.info(f"ğŸ‰ ìµœì¢… ê²°ê³¼: {earliest_data['date'].strftime('%Y-%m-%d')} ({earliest_data['data_type']}) - {earliest_data['data_count']}ê°œ ë°ì´í„°")
                
                # ê²°ê³¼ ì €ì¥
                result_data = {
                    'earliest_date': earliest_data['date'].strftime('%Y-%m-%d'),
                    'earliest_date_str': earliest_data['date_str'],
                    'data_type': earliest_data['data_type'],
                    'data_count': earliest_data['data_count'],
                    'recent_data_found': len(recent_data),
                    'search_completed_at': datetime.now().isoformat()
                }
                
                with open('krx_earliest_data_result.json', 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                logger.info("ê²°ê³¼ê°€ krx_earliest_data_result.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return earliest_data
            else:
                logger.warning("ê³¼ê±° ë°ì´í„° ê²€ìƒ‰ì—ì„œ ë” ì˜¤ë˜ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return earliest_recent
        else:
            logger.warning("ìµœê·¼ 30ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return None

if __name__ == "__main__":
    asyncio.run(main()) 