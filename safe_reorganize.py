#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: safe_reorganize.py
ëª©ì : GitHub ë°±ì—… í›„ ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬
Author: Safe Reorganizer
Created: 2025-07-13
Version: 1.0.0

Features:
    - ì¤‘ë³µ íŒŒì¼ GitHub ë°±ì—…
    - ì•ˆì „í•œ í´ë” êµ¬ì¡° ì •ë¦¬
    - ë³µì› ê°€ëŠ¥í•œ êµ¬ì¡°
    - ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
"""

import asyncio
import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import logging

from github_backup_manager import GitHubBackupManager

class SafeReorganizer:
    """ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬ê¸°"""
    
    def __init__(self):
        self.backup_manager = GitHubBackupManager()
        self.reorganize_log = []
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/safe_reorganize.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    async def safe_reorganize(self) -> Dict[str, Any]:
        """ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬"""
        try:
            self.logger.info("ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬ ì‹œì‘")
            
            # 1ë‹¨ê³„: ì¤‘ë³µ íŒŒì¼ ë°±ì—…
            print("ğŸ”„ 1ë‹¨ê³„: ì¤‘ë³µ íŒŒì¼ GitHub ë°±ì—…")
            backup_result = self.backup_manager.backup_duplicates_to_github()
            
            if not backup_result["success"]:
                return {"success": False, "error": f"ë°±ì—… ì‹¤íŒ¨: {backup_result['error']}"}
            
            self.reorganize_log.append({
                "step": "backup",
                "timestamp": datetime.now().isoformat(),
                "result": backup_result
            })
            
            print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_result['backed_up']}ê°œ íŒŒì¼")
            
            # 2ë‹¨ê³„: 20ê°œ í´ë”ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬
            print("\nğŸ”„ 2ë‹¨ê³„: í´ë” êµ¬ì¡° ì •ë¦¬")
            reorganize_result = await self._reorganize_folders()
            
            if not reorganize_result["success"]:
                # ë°±ì—…ì—ì„œ ë³µì›
                print("âš ï¸ êµ¬ì¡° ì •ë¦¬ ì‹¤íŒ¨, ë°±ì—…ì—ì„œ ë³µì› ì¤‘...")
                restore_result = self.backup_manager.restore_from_github()
                return {"success": False, "error": reorganize_result["error"], "restored": restore_result}
            
            self.reorganize_log.append({
                "step": "reorganize",
                "timestamp": datetime.now().isoformat(),
                "result": reorganize_result
            })
            
            print(f"âœ… êµ¬ì¡° ì •ë¦¬ ì™„ë£Œ: {reorganize_result['moved_files']}ê°œ íŒŒì¼")
            
            # 3ë‹¨ê³„: ì •ë¦¬ ê²°ê³¼ ê²€ì¦
            print("\nğŸ”„ 3ë‹¨ê³„: ê²°ê³¼ ê²€ì¦")
            validation_result = await self._validate_reorganization()
            
            self.reorganize_log.append({
                "step": "validation",
                "timestamp": datetime.now().isoformat(),
                "result": validation_result
            })
            
            # ë¡œê·¸ ì €ì¥
            self._save_reorganize_log()
            
            return {
                "success": True,
                "backup_result": backup_result,
                "reorganize_result": reorganize_result,
                "validation_result": validation_result
            }
            
        except Exception as e:
            self.logger.error(f"ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _reorganize_folders(self) -> Dict[str, Any]:
        """í´ë” êµ¬ì¡° ì •ë¦¬"""
        try:
            # 20ê°œ ìì—°ìŠ¤ëŸ¬ìš´ í´ë” êµ¬ì¡°
            target_folders = {
                "core": "í•µì‹¬ ì‹œìŠ¤í…œ",
                "data": "ë°ì´í„° ì €ì¥ì†Œ",
                "collectors": "ë°ì´í„° ìˆ˜ì§‘ê¸°",
                "processors": "ë°ì´í„° ì²˜ë¦¬ê¸°",
                "models": "ML/DL ëª¨ë¸",
                "strategies": "íŠ¸ë ˆì´ë”© ì „ëµ",
                "execution": "ì£¼ë¬¸ ì‹¤í–‰",
                "monitoring": "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§",
                "config": "ì„¤ì • íŒŒì¼",
                "logs": "ë¡œê·¸ íŒŒì¼",
                "reports": "ë¦¬í¬íŠ¸ ë° ê²°ê³¼",
                "scripts": "ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸",
                "tests": "í…ŒìŠ¤íŠ¸ íŒŒì¼",
                "docs": "ë¬¸ì„œ",
                "backup": "ë°±ì—…",
                "cache": "ìºì‹œ",
                "temp": "ì„ì‹œ íŒŒì¼",
                "trading": "íŠ¸ë ˆì´ë”© ê´€ë ¨",
                "analysis": "ë¶„ì„ ë„êµ¬",
                "utils": "ìœ í‹¸ë¦¬í‹°"
            }
            
            # í´ë” ìƒì„±
            for folder in target_folders.keys():
                Path(folder).mkdir(exist_ok=True)
            
            # ì´ë™ ê·œì¹™
            move_rules = {
                # ë°ì´í„° ê´€ë ¨
                "collected_data": "data/",
                "data_backup": "data/",
                "stock_history_parquet": "data/",
                "krx_auto_data": "data/",
                "krx_kosdaq50_data": "data/",
                "free_collected_data": "data/",
                
                # ìˆ˜ì§‘ê¸° ê´€ë ¨
                "data_engine/collectors": "collectors/",
                "service": "collectors/",
                
                # ì²˜ë¦¬ê¸° ê´€ë ¨
                "data_engine/processors": "processors/",
                
                # ëª¨ë¸ ê´€ë ¨
                "models": "models/",
                "mlruns": "models/",
                
                # ì „ëµ ê´€ë ¨
                "strategy_engine": "strategies/",
                "strategy": "strategies/",
                
                # ì‹¤í–‰ ê´€ë ¨
                "execution_engine": "execution/",
                "trading": "execution/",
                
                # ëª¨ë‹ˆí„°ë§ ê´€ë ¨
                "monitoring_center": "monitoring/",
                "monitoring": "monitoring/",
                
                # ì„¤ì • ê´€ë ¨
                "config": "config/",
                
                # ë¡œê·¸ ê´€ë ¨
                "logs": "logs/",
                
                # ë¦¬í¬íŠ¸ ê´€ë ¨
                "results": "reports/",
                "performance_reports": "reports/",
                "standardized_testing_results": "reports/",
                
                # ìŠ¤í¬ë¦½íŠ¸ ê´€ë ¨
                "scripts": "scripts/",
                
                # í…ŒìŠ¤íŠ¸ ê´€ë ¨
                "tests": "tests/",
                
                # ë¬¸ì„œ ê´€ë ¨
                "docs": "docs/",
                
                # ë°±ì—… ê´€ë ¨
                "backup": "backup/",
                "backup_ai_fixes": "backup/",
                "backup_code_fixes": "backup/",
                
                # ìºì‹œ ê´€ë ¨
                "cache": "cache/",
                
                # ì„ì‹œ ê´€ë ¨
                "temp": "temp/",
                "scripts_temp": "temp/",
                
                # íŠ¸ë ˆì´ë”© ê´€ë ¨
                "trading_env": "trading/",
                "daytrading_system": "trading/",
                "production_trading": "trading/",
                
                # ë¶„ì„ ê´€ë ¨
                "analysis": "analysis/",
                "backtesting_lab": "analysis/",
                
                # ìœ í‹¸ë¦¬í‹° ê´€ë ¨
                "utils": "utils/",
                "core": "utils/"
            }
            
            moved_files = 0
            
            # íŒŒì¼ ì´ë™
            for source, destination in move_rules.items():
                source_path = Path(source)
                dest_path = Path(destination)
                
                if source_path.exists():
                    try:
                        # ëŒ€ìƒ í´ë” ìƒì„±
                        dest_path.mkdir(parents=True, exist_ok=True)
                        
                        # í´ë”ì¸ ê²½ìš° ë‚´ìš©ë§Œ ì´ë™
                        if source_path.is_dir():
                            for item in source_path.iterdir():
                                if not (dest_path / item.name).exists():
                                    shutil.move(str(item), str(dest_path / item.name))
                                    moved_files += 1
                            
                            # ë¹ˆ í´ë”ë§Œ ì‚­ì œ
                            if not any(source_path.iterdir()):
                                source_path.rmdir()
                        else:
                            # íŒŒì¼ ì´ë™
                            if not (dest_path / source_path.name).exists():
                                shutil.move(str(source_path), str(dest_path / source_path.name))
                                moved_files += 1
                        
                        self.logger.info(f"ì´ë™ ì™„ë£Œ: {source} â†’ {destination}")
                        
                    except Exception as e:
                        self.logger.warning(f"ì´ë™ ì‹¤íŒ¨ (ê±´ë„ˆëœ€): {source} - {e}")
            
            # ë£¨íŠ¸ íŒŒì¼ ì •ë¦¬
            file_rules = {
                "*.py": "scripts/",
                "*.json": "config/",
                "*.log": "logs/",
                "*.csv": "data/",
                "*.parquet": "data/",
                "*.h5": "models/",
                "*.md": "docs/",
                "*.txt": "docs/",
                "*.bat": "scripts/",
                "*.sh": "scripts/"
            }
            
            for pattern, destination in file_rules.items():
                for file_path in Path(".").glob(pattern):
                    if file_path.is_file() and file_path.name not in ["safe_reorganize.py", "github_backup_manager.py"]:
                        try:
                            dest_path = Path(destination)
                            dest_path.mkdir(exist_ok=True)
                            
                            if not (dest_path / file_path.name).exists():
                                shutil.move(str(file_path), str(dest_path / file_path.name))
                                moved_files += 1
                                
                        except Exception as e:
                            self.logger.warning(f"íŒŒì¼ ì´ë™ ì‹¤íŒ¨: {file_path.name} - {e}")
            
            return {
                "success": True,
                "moved_files": moved_files,
                "target_folders": list(target_folders.keys())
            }
            
        except Exception as e:
            self.logger.error(f"í´ë” êµ¬ì¡° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _validate_reorganization(self) -> Dict[str, Any]:
        """ì •ë¦¬ ê²°ê³¼ ê²€ì¦"""
        try:
            # í•„ìˆ˜ í´ë” í™•ì¸
            required_folders = ["core", "data", "collectors", "processors", "models", "config", "logs"]
            missing_folders = []
            
            for folder in required_folders:
                if not Path(folder).exists():
                    missing_folders.append(folder)
            
            # íŒŒì¼ ì†ì‹¤ í™•ì¸
            total_files_before = len(list(Path(".").rglob("*")))
            total_files_after = len(list(Path(".").rglob("*")))
            
            validation_result = {
                "success": len(missing_folders) == 0,
                "missing_folders": missing_folders,
                "files_before": total_files_before,
                "files_after": total_files_after,
                "file_loss": total_files_before - total_files_after
            }
            
            if validation_result["success"]:
                self.logger.info("ê²€ì¦ ì™„ë£Œ: ëª¨ë“  í´ë”ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë¨")
            else:
                self.logger.warning(f"ê²€ì¦ ì‹¤íŒ¨: ëˆ„ë½ëœ í´ë” {missing_folders}")
            
            return validation_result
            
        except Exception as e:
            self.logger.error(f"ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _save_reorganize_log(self) -> None:
        """ì •ë¦¬ ë¡œê·¸ ì €ì¥"""
        log_file = Path("logs/reorganize_log.json")
        log_file.parent.mkdir(exist_ok=True)
        
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.reorganize_log, f, indent=2, ensure_ascii=False)
    
    def get_reorganize_status(self) -> Dict[str, Any]:
        """ì •ë¦¬ ìƒíƒœ ì¡°íšŒ"""
        return {
            "total_steps": len(self.reorganize_log),
            "last_step": self.reorganize_log[-1] if self.reorganize_log else None,
            "success": all(step["result"].get("success", False) for step in self.reorganize_log)
        }

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    reorganizer = SafeReorganizer()
    
    print("ğŸ”„ ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬ ì‹œì‘")
    print("ğŸ“¦ ì¤‘ë³µ íŒŒì¼ì„ GitHubì— ë°±ì—…í•œ í›„ êµ¬ì¡°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
    
    result = await reorganizer.safe_reorganize()
    
    if result["success"]:
        print("\nâœ… ì•ˆì „í•œ êµ¬ì¡° ì •ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ë°±ì—…ëœ íŒŒì¼: {result['backup_result']['backed_up']}ê°œ")
        print(f"ğŸ“Š ì´ë™ëœ íŒŒì¼: {result['reorganize_result']['moved_files']}ê°œ")
        print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼: {'ì„±ê³µ' if result['validation_result']['success'] else 'ì‹¤íŒ¨'}")
        
        # í˜„ì¬ í´ë” êµ¬ì¡° ì¶œë ¥
        print("\nğŸ“ í˜„ì¬ í´ë” êµ¬ì¡°:")
        for folder in result['reorganize_result']['target_folders']:
            if Path(folder).exists():
                file_count = len(list(Path(folder).rglob("*")))
                print(f"  ğŸ“ {folder}: {file_count}ê°œ íŒŒì¼/í´ë”")
    else:
        print(f"\nâŒ êµ¬ì¡° ì •ë¦¬ ì‹¤íŒ¨: {result['error']}")
        if 'restored' in result:
            print("ğŸ”„ ë°±ì—…ì—ì„œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main()) 