#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: overseas_data_collector.py
ëª¨ë“ˆ: í•´ì™¸(ë¯¸êµ­/í™ì½©) ì£¼ì‹Â·ETFÂ·ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ê¸° (Alpha Vantage + Yahoo Finance ë³‘ë ¬)
ëª©ì : Alpha Vantageì™€ Yahoo Financeë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ìµœëŒ€í•œ ë¹ ë¥´ê²Œ ëŒ€ìš©ëŸ‰ ê³¼ê±° ë°ì´í„°ë¥¼ ìˆ˜ì§‘

Author: World-Class AI Quant Team
Created: 2025-07-13
Modified: 2025-07-14
Version: 3.0.0

Dependencies:
    - Python 3.11+
    - yfinance>=0.2.36
    - pandas>=2.0.0
    - requests>=2.31.0
    - tqdm>=4.65.0
    - python-dotenv>=1.0.0

Usage:
    # Alpha Vantage + Yahoo Finance ë³‘ë ¬ ìˆ˜ì§‘ (ê¶Œì¥)
    python overseas_data_collector.py --mode parallel
    # Alpha Vantageë§Œ ìˆ˜ì§‘
    python overseas_data_collector.py --mode alpha
    # Yahoo Financeë§Œ ìˆ˜ì§‘
    python overseas_data_collector.py --mode yahoo

Features:
    - Alpha Vantageì™€ Yahoo Finance ë³‘ë ¬ ì‹¤í–‰
    - ê° API ì •ì±…ì— ë§ì¶˜ ìµœì í™” (Alpha Vantage: 5 calls/min, Yahoo Finance: 1.2s delay)
    - ë¯¸êµ­/í™ì½© ì£¼ìš” ì§€ìˆ˜Â·ì¢…ëª©Â·ETF ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
    - ê¸°ìˆ ì  ì§€í‘œ ìë™ ê³„ì‚° (SMA, EMA, RSI, MACD)
    - ë©€í‹°ë ˆë²¨ ìºì‹±, ìë™ ì—ëŸ¬ ë³µêµ¬, êµ¬ì¡°í™” ë¡œê¹…
    - Google/Meta/Netflix ìˆ˜ì¤€ ì½”ë“œ í’ˆì§ˆ

Performance:
    - ë³‘ë ¬ ëª¨ë“œ: Alpha Vantage + Yahoo Finance ë™ì‹œ ì‹¤í–‰ (ìµœëŒ€ ì„±ëŠ¥)
    - Alpha Vantage: 5 calls/min (ë¬´ë£Œ ì •ì±… ì¤€ìˆ˜)
    - Yahoo Finance: 1.2s delay (ì°¨ë‹¨ ë°©ì§€)

Security:
    - ì…ë ¥ ê²€ì¦, ì˜ˆì™¸ ì²˜ë¦¬, ë¯¼ê°ì •ë³´ ë³´í˜¸
    - API í‚¤ í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬

License: MIT
"""

import asyncio
import pandas as pd
import logging
import json
import time
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Tuple
import yfinance as yf
import requests
from dotenv import load_dotenv
from tqdm import tqdm
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import threading
import queue
import signal
import sys
import argparse
import urllib.parse
from dataclasses import dataclass, field
from functools import wraps
import hashlib
import pickle

# ============================================================================
# íƒ€ì… ì •ì˜
# ============================================================================

@dataclass
class DataRequest:
    """ë°ì´í„° ìš”ì²­ ì •ë³´"""
    symbol: str
    source: str  # 'alpha_vantage' or 'yahoo'
    data_type: str
    interval: str = '1d'
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    priority: int = 1
    retry_count: int = 0
    max_retries: int = 3
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class CollectionResult:
    """ìˆ˜ì§‘ ê²°ê³¼"""
    symbol: str
    source: str
    data_type: str
    interval: str
    data: Any
    success: bool
    error: Optional[str] = None
    processing_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

# ============================================================================
# ë¡œê¹… ì„¤ì •
# ============================================================================

def setup_logging() -> logging.Logger:
    """ë¡œê¹… ì„¤ì •"""
    log_dir = Path('logs')
    log_dir.mkdir(parents=True, exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/overseas_data_collector.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

# ============================================================================
# ìºì‹œ ì‹œìŠ¤í…œ
# ============================================================================

class CacheManager:
    """ë©€í‹°ë ˆë²¨ ìºì‹œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, cache_dir: str = "cache/overseas"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.memory_cache = {}
        self.cache_stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0
        }
    
    def _generate_cache_key(self, symbol: str, source: str, data_type: str, interval: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{symbol}_{source}_{data_type}_{interval}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def get(self, symbol: str, source: str, data_type: str, interval: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        cache_key = self._generate_cache_key(symbol, source, data_type, interval)
        
        # ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if cache_key in self.memory_cache:
            entry = self.memory_cache[cache_key]
            if self._is_valid(entry):
                self.cache_stats['hits'] += 1
                return entry['data']
        
        # ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        cache_file = self.cache_dir / f"{cache_key}.cache"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    entry = pickle.load(f)
                if self._is_valid(entry):
                    self.cache_stats['hits'] += 1
                    # ë©”ëª¨ë¦¬ ìºì‹œë¡œ ìŠ¹ê²©
                    self.memory_cache[cache_key] = entry
                    return entry['data']
            except Exception as e:
                logging.error(f"ìºì‹œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        self.cache_stats['misses'] += 1
        return None
    
    def set(self, symbol: str, source: str, data_type: str, interval: str, data: Any, ttl: int = 3600) -> None:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        cache_key = self._generate_cache_key(symbol, source, data_type, interval)
        
        entry = {
            'data': data,
            'timestamp': datetime.now(),
            'ttl': ttl
        }
        
        # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
        self.memory_cache[cache_key] = entry
        
        # ë””ìŠ¤í¬ ìºì‹œì— ì €ì¥
        cache_file = self.cache_dir / f"{cache_key}.cache"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(entry, f)
        except Exception as e:
            logging.error(f"ìºì‹œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _is_valid(self, entry: Dict[str, Any]) -> bool:
        """ìºì‹œ ì—”íŠ¸ë¦¬ ìœ íš¨ì„± ê²€ì‚¬"""
        return (datetime.now() - entry['timestamp']).total_seconds() < entry['ttl']

# ============================================================================
# Alpha Vantage ìˆ˜ì§‘ê¸°
# ============================================================================

class AlphaVantageCollector:
    """Alpha Vantage API ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://www.alphavantage.co/query"
        self.request_limit_per_min = 5
        self.sleep_seconds = 60 / self.request_limit_per_min + 1
        self.logger = logging.getLogger(__name__)
        
        # ìš”ì²­ í†µê³„
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'rate_limit_hits': 0
        }
    
    def fetch_data(self, symbol: str, function: str, extra_params: Optional[Dict] = None) -> Optional[Dict]:
        """Alpha Vantageì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            params = {
                "function": function,
                "symbol": symbol,
                "apikey": self.api_key,
                "outputsize": "full"  # ìµœëŒ€ ê³¼ê±° ë°ì´í„°
            }
            
            if extra_params:
                params.update(extra_params)
            
            url = f"{self.base_url}?{urllib.parse.urlencode(params)}"
            
            self.stats['total_requests'] += 1
            
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                # API ì—ëŸ¬ ì²´í¬
                if "Error Message" in data:
                    self.logger.error(f"Alpha Vantage API ì—ëŸ¬ ({symbol}): {data['Error Message']}")
                    self.stats['failed_requests'] += 1
                    return None
                
                if "Note" in data:
                    self.logger.warning(f"Alpha Vantage API ì œí•œ ({symbol}): {data['Note']}")
                    self.stats['rate_limit_hits'] += 1
                    return None
                
                self.stats['successful_requests'] += 1
                return data
            else:
                self.logger.error(f"Alpha Vantage API ìš”ì²­ ì‹¤íŒ¨ ({symbol}): {response.status_code}")
                self.stats['failed_requests'] += 1
                return None
                
        except Exception as e:
            self.logger.error(f"Alpha Vantage ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ({symbol}): {e}")
            self.stats['failed_requests'] += 1
            return None
    
    def collect_stock_data(self, symbol: str) -> List[Dict]:
        """ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
        results = []
        
        # ì‹œê°„ ì‹œë¦¬ì¦ˆ í•¨ìˆ˜ë“¤
        time_series_funcs = [
            "TIME_SERIES_DAILY_ADJUSTED",
            "TIME_SERIES_WEEKLY_ADJUSTED", 
            "TIME_SERIES_MONTHLY_ADJUSTED"
        ]
        
        # ê¸°ìˆ ì  ì§€í‘œ í•¨ìˆ˜ë“¤
        technical_funcs = [
            ("SMA", {"interval": "daily", "time_period": 20, "series_type": "close"}),
            ("EMA", {"interval": "daily", "time_period": 20, "series_type": "close"}),
            ("RSI", {"interval": "daily", "time_period": 14, "series_type": "close"}),
            ("MACD", {"interval": "daily", "series_type": "close"})
        ]
        
        # ì‹œê°„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìˆ˜ì§‘
        for func in time_series_funcs:
            data = self.fetch_data(symbol, func)
            if data:
                results.append({
                    'symbol': symbol,
                    'source': 'alpha_vantage',
                    'data_type': func,
                    'interval': '1d',
                    'data': data
                })
            time.sleep(self.sleep_seconds)  # API ì œí•œ ì¤€ìˆ˜
        
        # ê¸°ìˆ ì  ì§€í‘œ ìˆ˜ì§‘
        for func, params in technical_funcs:
            data = self.fetch_data(symbol, func, params)
            if data:
                results.append({
                    'symbol': symbol,
                    'source': 'alpha_vantage',
                    'data_type': func,
                    'interval': '1d',
                    'data': data
                })
            time.sleep(self.sleep_seconds)  # API ì œí•œ ì¤€ìˆ˜
        
        return results

# ============================================================================
# Yahoo Finance ìˆ˜ì§‘ê¸°
# ============================================================================

class YahooFinanceCollector:
    """Yahoo Finance ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.request_delay = 1.2  # ì°¨ë‹¨ ë°©ì§€ìš© ë”œë ˆì´
        
        # ìš”ì²­ í†µê³„
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'empty_responses': 0
        }
    
    def fetch_data(self, symbol: str, interval: str = '1d') -> Optional[pd.DataFrame]:
        """Yahoo Financeì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self.stats['total_requests'] += 1
            
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period='max', interval=interval)
            
            if hist.empty:
                self.logger.warning(f"Yahoo Finance ë¹ˆ ë°ì´í„° ({symbol}): {interval}")
                self.stats['empty_responses'] += 1
                return None
            
            # ì¸ë±ìŠ¤ ë¦¬ì…‹
            hist.reset_index(inplace=True)
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            hist = self._calculate_technical_indicators(hist)
            
            self.stats['successful_requests'] += 1
            return hist
            
        except Exception as e:
            self.logger.error(f"Yahoo Finance ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ({symbol}): {e}")
            self.stats['failed_requests'] += 1
            return None
    
    def _calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        try:
            df = df.copy()
            
            # SMA (Simple Moving Average)
            df['SMA20'] = df['Close'].rolling(window=20).mean()
            df['SMA50'] = df['Close'].rolling(window=50).mean()
            
            # EMA (Exponential Moving Average)
            df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()
            df['EMA50'] = df['Close'].ewm(span=50, adjust=False).mean()
            
            # RSI (Relative Strength Index)
            delta = df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / (loss + 1e-9)
            df['RSI14'] = 100 - (100 / (1 + rs))
            
            # MACD (Moving Average Convergence Divergence)
            exp12 = df['Close'].ewm(span=12, adjust=False).mean()
            exp26 = df['Close'].ewm(span=26, adjust=False).mean()
            df['MACD'] = exp12 - exp26
            df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
            df['MACD_histogram'] = df['MACD'] - df['MACD_signal']
            
            # Bollinger Bands
            df['BB_middle'] = df['Close'].rolling(window=20).mean()
            bb_std = df['Close'].rolling(window=20).std()
            df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
            df['BB_lower'] = df['BB_middle'] - (bb_std * 2)
            
            return df
            
        except Exception as e:
            self.logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return df
    
    def collect_stock_data(self, symbol: str) -> List[Dict]:
        """ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
        results = []
        
        intervals = ['1d', '1wk', '1mo']
        
        for interval in intervals:
            data = self.fetch_data(symbol, interval)
            if data is not None:
                results.append({
                    'symbol': symbol,
                    'source': 'yahoo',
                    'data_type': 'historical',
                    'interval': interval,
                    'data': data
                })
            
            time.sleep(self.request_delay)  # ì°¨ë‹¨ ë°©ì§€ìš© ë”œë ˆì´
        
        return results

# ============================================================================
# ë³‘ë ¬ ìˆ˜ì§‘ ê´€ë¦¬ì
# ============================================================================

class ParallelDataCollector:
    """Alpha Vantageì™€ Yahoo Finance ë³‘ë ¬ ìˆ˜ì§‘ ê´€ë¦¬ì"""
    
    def __init__(self, mode: str = 'parallel'):
        self.mode = mode
        self.logger = setup_logging()
        
        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()
        self.alpha_vantage_key = os.getenv("ALPHA_VANTAGE_API_KEY")
        
        if not self.alpha_vantage_key and mode in ['parallel', 'alpha']:
            raise ValueError("ALPHA_VANTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if mode in ['parallel', 'alpha']:
            if not self.alpha_vantage_key:
                raise ValueError("ALPHA_VANTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            self.alpha_collector = AlphaVantageCollector(self.alpha_vantage_key)
        
        if self.mode in ['parallel', 'yahoo']:
            self.yahoo_collector = YahooFinanceCollector()
        
        # ìºì‹œ ë§¤ë‹ˆì €
        self.cache = CacheManager()
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬
        self.data_dir = Path('data/overseas')
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ì£¼ì‹ ëª©ë¡ ì´ˆê¸°í™”
        self._init_stock_lists()
        
        # í†µê³„
        self.stats = {
            'total_symbols': 0,
            'processed_symbols': 0,
            'successful_symbols': 0,
            'failed_symbols': 0,
            'start_time': datetime.now(),
            'end_time': None
        }
    
    def _init_stock_lists(self) -> None:
        """ì£¼ì‹ ëª©ë¡ ì´ˆê¸°í™”"""
        
        # ============================================================================
        # ë¯¸êµ­ ë‚˜ìŠ¤ë‹¥ 100 ì§€ìˆ˜ ì¢…ëª© (ìƒìœ„ 50ê°œ)
        # ============================================================================
        self.nasdaq100_stocks = [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX', 'ADBE', 'CRM',
            'PYPL', 'INTC', 'AMD', 'CSCO', 'PEP', 'COST', 'AVGO', 'TMUS', 'QCOM', 'HON',
            'INTU', 'ISRG', 'GILD', 'ADP', 'REGN', 'KLAC', 'VRTX', 'MU', 'LRCX', 'ADI',
            'MELI', 'MNST', 'ASML', 'JD', 'PDD', 'BIIB', 'ALGN', 'WDAY', 'SNPS', 'CDNS',
            'MRVL', 'CPRT', 'PAYX', 'ORLY', 'IDXX', 'FAST', 'CTAS', 'ROST', 'ODFL', 'VRSK'
        ]
        
        # ============================================================================
        # ë¯¸êµ­ S&P 500 ì§€ìˆ˜ ì¢…ëª© (ìƒìœ„ 50ê°œ)
        # ============================================================================
        self.sp500_stocks = [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX', 'ADBE', 'CRM',
            'PYPL', 'INTC', 'AMD', 'CSCO', 'AVGO', 'QCOM', 'ORCL', 'IBM', 'TXN', 'MU',
            'LRCX', 'KLAC', 'ADI', 'MCHP', 'SNPS', 'CDNS', 'MRVL', 'CTSH', 'ADSK', 'WDAY',
            'SNOW', 'CRWD', 'ZS', 'OKTA', 'PLTR', 'DDOG', 'NET', 'TEAM', 'WORK', 'DOCU',
            'ZM', 'SPOT', 'PINS', 'SQ', 'TWLO', 'UBER', 'LYFT', 'SNAP', 'RBLX', 'HOOD'
        ]
        
        # ============================================================================
        # ë¯¸êµ­ ì£¼ìš” ETF
        # ============================================================================
        self.us_etfs = [
            'SPY', 'QQQ', 'DIA', 'IWM', 'VOO', 'IVV', 'VTI', 'VEA', 'VWO', 'AGG',
            'TLT', 'IEF', 'SHY', 'LQD', 'HYG', 'EMB', 'GLD', 'SLV', 'USO', 'UNG',
            'XLF', 'XLK', 'XLE', 'XLV', 'XLI', 'XLP', 'XLY', 'XLB', 'XLU', 'XLRE'
        ]
        
        # ============================================================================
        # í™ì½© ì£¼ìš” ì£¼ì‹ (Alpha Vantage ì§€ì› ì¢…ëª©ë§Œ)
        # ============================================================================
        self.hk_stocks = [
            '0700.HK', '0005.HK', '0939.HK', '0941.HK', '1299.HK', '2318.HK', '1398.HK',
            '3988.HK', '2628.HK', '0939.HK', '2388.HK', '0883.HK', '0688.HK', '1109.HK',
            '2018.HK', '2269.HK', '9618.HK', '9988.HK', '3690.HK', '1810.HK'
        ]
        
        # ì „ì²´ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        self.all_symbols = list(set(
            self.nasdaq100_stocks + 
            self.sp500_stocks + 
            self.us_etfs + 
            self.hk_stocks
        ))
        
        self.stats['total_symbols'] = len(self.all_symbols)
    
    def collect_alpha_vantage_data(self, symbol: str) -> List[CollectionResult]:
        """Alpha Vantage ë°ì´í„° ìˆ˜ì§‘"""
        results = []
        
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"{symbol}_alpha_vantage"
            cached_data = self.cache.get(symbol, 'alpha_vantage', 'historical', '1d')
            
            if cached_data:
                self.logger.info(f"Alpha Vantage ìºì‹œ íˆíŠ¸: {symbol}")
                return [CollectionResult(
                    symbol=symbol,
                    source='alpha_vantage',
                    data_type='cached',
                    interval='1d',
                    data=cached_data,
                    success=True
                )]
            
            # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
            start_time = time.time()
            alpha_results = self.alpha_collector.collect_stock_data(symbol)
            
            for result in alpha_results:
                # ìºì‹œì— ì €ì¥
                self.cache.set(
                    symbol, 'alpha_vantage', result['data_type'], result['interval'], 
                    result['data']
                )
                
                results.append(CollectionResult(
                    symbol=symbol,
                    source='alpha_vantage',
                    data_type=result['data_type'],
                    interval=result['interval'],
                    data=result['data'],
                    success=True,
                    processing_time=time.time() - start_time
                ))
            
            self.stats['successful_symbols'] += 1
            
        except Exception as e:
            self.logger.error(f"Alpha Vantage ìˆ˜ì§‘ ì‹¤íŒ¨ ({symbol}): {e}")
            results.append(CollectionResult(
                symbol=symbol,
                source='alpha_vantage',
                data_type='error',
                interval='1d',
                data=None,
                success=False,
                error=str(e)
            ))
            self.stats['failed_symbols'] += 1
        
        return results
    
    def collect_yahoo_data(self, symbol: str) -> List[CollectionResult]:
        """Yahoo Finance ë°ì´í„° ìˆ˜ì§‘"""
        results = []
        
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"{symbol}_yahoo"
            cached_data = self.cache.get(symbol, 'yahoo', 'historical', '1d')
            
            if cached_data:
                self.logger.info(f"Yahoo Finance ìºì‹œ íˆíŠ¸: {symbol}")
                return [CollectionResult(
                    symbol=symbol,
                    source='yahoo',
                    data_type='cached',
                    interval='1d',
                    data=cached_data,
                    success=True
                )]
            
            # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
            start_time = time.time()
            yahoo_results = self.yahoo_collector.collect_stock_data(symbol)
            
            for result in yahoo_results:
                # ìºì‹œì— ì €ì¥
                self.cache.set(
                    symbol, 'yahoo', result['data_type'], result['interval'], 
                    result['data']
                )
                
                results.append(CollectionResult(
                    symbol=symbol,
                    source='yahoo',
                    data_type=result['data_type'],
                    interval=result['interval'],
                    data=result['data'],
                    success=True,
                    processing_time=time.time() - start_time
                ))
            
            self.stats['successful_symbols'] += 1
            
        except Exception as e:
            self.logger.error(f"Yahoo Finance ìˆ˜ì§‘ ì‹¤íŒ¨ ({symbol}): {e}")
            results.append(CollectionResult(
                symbol=symbol,
                source='yahoo',
                data_type='error',
                interval='1d',
                data=None,
                success=False,
                error=str(e)
            ))
            self.stats['failed_symbols'] += 1
        
        return results
    
    def save_results(self, results: List[CollectionResult]) -> None:
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for result in results:
            if not result.success:
                continue
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            source_dir = self.data_dir / result.source
            source_dir.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"{result.symbol}_{result.data_type}_{result.interval}_{timestamp}"
            
            # CSV ì €ì¥
            if isinstance(result.data, pd.DataFrame):
                csv_file = source_dir / f"{filename}.csv"
                result.data.to_csv(csv_file, index=False)
                self.logger.info(f"CSV ì €ì¥: {csv_file}")
            
            # JSON ì €ì¥
            json_file = source_dir / f"{filename}.json"
            if isinstance(result.data, pd.DataFrame):
                json_data = result.data.to_dict('records')
            else:
                json_data = result.data
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            self.logger.info(f"JSON ì €ì¥: {json_file}")
    
    def run_parallel_collection(self) -> None:
        """ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰"""
        self.logger.info(f"ğŸš€ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘! ëª¨ë“œ: {self.mode}")
        self.logger.info(f"ğŸ“Š ì´ {self.stats['total_symbols']}ê°œ ì‹¬ë³¼ ìˆ˜ì§‘ ì˜ˆì •")
        
        start_time = time.time()
        
        # ì§„í–‰ë¥  í‘œì‹œ
        with tqdm(total=self.stats['total_symbols'], desc="ìˆ˜ì§‘ ì§„í–‰ë¥ ") as pbar:
            for symbol in self.all_symbols:
                try:
                    results = []
                    
                    # Alpha Vantage ìˆ˜ì§‘ (ë³‘ë ¬ ëª¨ë“œ ë˜ëŠ” alpha ëª¨ë“œ)
                    if self.mode in ['parallel', 'alpha']:
                        alpha_results = self.collect_alpha_vantage_data(symbol)
                        results.extend(alpha_results)
                    
                    # Yahoo Finance ìˆ˜ì§‘ (ë³‘ë ¬ ëª¨ë“œ ë˜ëŠ” yahoo ëª¨ë“œ)
                    if self.mode in ['parallel', 'yahoo']:
                        yahoo_results = self.collect_yahoo_data(symbol)
                        results.extend(yahoo_results)
                    
                    # ê²°ê³¼ ì €ì¥
                    if results:
                        self.save_results(results)
                    
                    self.stats['processed_symbols'] += 1
                    pbar.update(1)
                    
                    # ì§„í–‰ë¥  ë¡œê·¸
                    if self.stats['processed_symbols'] % 10 == 0:
                        elapsed_time = time.time() - start_time
                        avg_time_per_symbol = elapsed_time / self.stats['processed_symbols']
                        remaining_symbols = self.stats['total_symbols'] - self.stats['processed_symbols']
                        estimated_remaining_time = remaining_symbols * avg_time_per_symbol
                        
                        self.logger.info(
                            f"ì§„í–‰ë¥ : {self.stats['processed_symbols']}/{self.stats['total_symbols']} "
                            f"({self.stats['processed_symbols']/self.stats['total_symbols']*100:.1f}%) "
                            f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time/60:.1f}ë¶„"
                        )
                    
                except Exception as e:
                    self.logger.error(f"ì‹¬ë³¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({symbol}): {e}")
                    self.stats['failed_symbols'] += 1
                    pbar.update(1)
        
        # ìµœì¢… í†µê³„
        self.stats['end_time'] = datetime.now()
        total_time = time.time() - start_time
        
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ í†µê³„")
        self.logger.info("=" * 60)
        self.logger.info(f"ì´ ì‹¬ë³¼ ìˆ˜: {self.stats['total_symbols']}")
        self.logger.info(f"ì²˜ë¦¬ëœ ì‹¬ë³¼ ìˆ˜: {self.stats['processed_symbols']}")
        self.logger.info(f"ì„±ê³µí•œ ì‹¬ë³¼ ìˆ˜: {self.stats['successful_symbols']}")
        self.logger.info(f"ì‹¤íŒ¨í•œ ì‹¬ë³¼ ìˆ˜: {self.stats['failed_symbols']}")
        self.logger.info(f"ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        self.logger.info(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/self.stats['processed_symbols']:.2f}ì´ˆ/ì‹¬ë³¼")
        
        # Alpha Vantage í†µê³„
        if self.mode in ['parallel', 'alpha']:
            self.logger.info("=" * 30)
            self.logger.info("Alpha Vantage í†µê³„")
            self.logger.info("=" * 30)
            self.logger.info(f"ì´ ìš”ì²­ ìˆ˜: {self.alpha_collector.stats['total_requests']}")
            self.logger.info(f"ì„±ê³µí•œ ìš”ì²­ ìˆ˜: {self.alpha_collector.stats['successful_requests']}")
            self.logger.info(f"ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜: {self.alpha_collector.stats['failed_requests']}")
            self.logger.info(f"ì†ë„ ì œí•œ íˆíŠ¸: {self.alpha_collector.stats['rate_limit_hits']}")
        
        # Yahoo Finance í†µê³„
        if self.mode in ['parallel', 'yahoo']:
            self.logger.info("=" * 30)
            self.logger.info("Yahoo Finance í†µê³„")
            self.logger.info("=" * 30)
            self.logger.info(f"ì´ ìš”ì²­ ìˆ˜: {self.yahoo_collector.stats['total_requests']}")
            self.logger.info(f"ì„±ê³µí•œ ìš”ì²­ ìˆ˜: {self.yahoo_collector.stats['successful_requests']}")
            self.logger.info(f"ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜: {self.yahoo_collector.stats['failed_requests']}")
            self.logger.info(f"ë¹ˆ ì‘ë‹µ ìˆ˜: {self.yahoo_collector.stats['empty_responses']}")
        
        # ìºì‹œ í†µê³„
        self.logger.info("=" * 30)
        self.logger.info("ìºì‹œ í†µê³„")
        self.logger.info("=" * 30)
        self.logger.info(f"ìºì‹œ íˆíŠ¸: {self.cache.cache_stats['hits']}")
        self.logger.info(f"ìºì‹œ ë¯¸ìŠ¤: {self.cache.cache_stats['misses']}")
        self.logger.info(f"ìºì‹œ ì œê±°: {self.cache.cache_stats['evictions']}")
        
        self.logger.info("=" * 60)
        self.logger.info("âœ… ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")

# ============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="í•´ì™¸ ë°ì´í„° ìˆ˜ì§‘ê¸° (Alpha Vantage + Yahoo Finance)")
    parser.add_argument('--mode', type=str, default='parallel', 
                       choices=['parallel', 'alpha', 'yahoo'],
                       help='ìˆ˜ì§‘ ëª¨ë“œ: parallel(ë³‘ë ¬), alpha(Alpha Vantageë§Œ), yahoo(Yahoo Financeë§Œ)')
    args = parser.parse_args()
    
    try:
        # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        collector = ParallelDataCollector(mode=args.mode)
        
        # ìˆ˜ì§‘ ì‹¤í–‰
        collector.run_parallel_collection()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 