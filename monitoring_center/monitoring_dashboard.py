#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¼ëª…: monitoring_dashboard.py
ëª¨ë“ˆ: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
ëª©ì : ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ë° í’ˆì§ˆ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

Author: AI Assistant
Created: 2025-01-27
Modified: 2025-01-27
Version: 1.0.0

Dependencies:
    - prometheus_client
    - grafana_api
    - streamlit
    - plotly
    - dash
"""

from __future__ import annotations

import asyncio
import json
import logging
import os
import threading
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

try:
    import dash
    import plotly.express as px
    import plotly.graph_objects as go
    import streamlit as st
    from dash import dcc, html, Input, Output, callback
    from dash.dependencies import Input, Output
    from plotly.subplots import make_subplots
    from prometheus_client import start_http_server, Counter, Gauge, Histogram, Summary
    from prometheus_client.core import REGISTRY
except ImportError:
    pass

import numpy as np
import pandas as pd
import psutil
import redis.asyncio as redis
import requests
from sqlalchemy import create_engine, text

# ëª¨ë‹ˆí„°ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

try:
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

try:
    DASH_AVAILABLE = True
except ImportError:
    DASH_AVAILABLE = False

# ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('monitoring.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
if PROMETHEUS_AVAILABLE:
    # ì¹´ìš´í„° (ëˆ„ì  ê°’)
    DATA_COLLECTION_COUNTER = Counter(
        'trading_data_collected_total',
        'Total number of data records collected',
        ['source', 'data_type']
    )

    DATA_PROCESSING_COUNTER = Counter(
        'trading_data_processed_total',
        'Total number of data records processed',
        ['processing_type']
    )

    ERROR_COUNTER = Counter(
        'trading_errors_total',
        'Total number of errors',
        ['error_type', 'component']
    )

    # ê²Œì´ì§€ (í˜„ì¬ ê°’)
    DATA_QUALITY_SCORE = Gauge(
        'trading_data_quality_score',
        'Current data quality score',
        ['source']
    )

    SYSTEM_UPTIME = Gauge(
        'trading_system_uptime_seconds',
        'System uptime in seconds'
    )

    MEMORY_USAGE = Gauge(
        'trading_memory_usage_bytes',
        'Memory usage in bytes'
    )

    CPU_USAGE = Gauge(
        'trading_cpu_usage_percent',
        'CPU usage percentage'
    )

    # íˆìŠ¤í† ê·¸ë¨ (ë¶„í¬)
    DATA_COLLECTION_DURATION = Histogram(
        'trading_data_collection_duration_seconds',
        'Data collection duration in seconds',
        ['source']
    )

    DATA_PROCESSING_DURATION = Histogram(
        'trading_data_processing_duration_seconds',
        'Data processing duration in seconds',
        ['processing_type']
    )

    # ì„œë¨¸ë¦¬ (ë¶„ìœ„ìˆ˜)
    API_RESPONSE_TIME = Summary(
        'trading_api_response_time_seconds',
        'API response time in seconds',
        ['api_endpoint']
    )

@dataclass
class MonitoringConfig:
    """ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    # Prometheus ì„¤ì •
    prometheus_port: int = 8000
    metrics_interval_seconds: int = 30

    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    postgres_url: str = "postgresql://user:pass@localhost:5432/trading_data"
    redis_url: str = "redis://localhost:6379/0"

    # ì•Œë¦¼ ì„¤ì •
    alert_thresholds: Dict[str, float] = field(default_factory=lambda: {
        'data_quality_min': 80.0,
        'system_uptime_min': 99.0,
        'memory_usage_max': 85.0,
        'cpu_usage_max': 80.0,
        'error_rate_max': 5.0
    })

    # ëŒ€ì‹œë³´ë“œ ì„¤ì •
    dashboard_refresh_interval: int = 60  # ì´ˆ
    max_data_points: int = 1000

class PrometheusMetricsCollector:
    """Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""

    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.start_time = datetime.now()

        if PROMETHEUS_AVAILABLE:
            # Prometheus HTTP ì„œë²„ ì‹œì‘
            start_http_server(config.prometheus_port)
            logger.info(f"Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘: http://localhost:{config.prometheus_port}")

    def record_data_collection(self, source: str, data_type: str, count: int, duration: float):
        """ë°ì´í„° ìˆ˜ì§‘ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if PROMETHEUS_AVAILABLE:
            DATA_COLLECTION_COUNTER.labels(source=source, data_type=data_type).inc(count)
            DATA_COLLECTION_DURATION.labels(source=source).observe(duration)

    def record_data_processing(self, processing_type: str, count: int, duration: float):
        """ë°ì´í„° ì²˜ë¦¬ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if PROMETHEUS_AVAILABLE:
            DATA_PROCESSING_COUNTER.labels(processing_type=processing_type).inc(count)
            DATA_PROCESSING_DURATION.labels(processing_type=processing_type).observe(duration)

    def record_error(self, error_type: str, component: str):
        """ì—ëŸ¬ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if PROMETHEUS_AVAILABLE:
            ERROR_COUNTER.labels(error_type=error_type, component=component).inc()

    def update_data_quality(self, source: str, score: float):
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸"""
        if PROMETHEUS_AVAILABLE:
            DATA_QUALITY_SCORE.labels(source=source).set(score)

    def update_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if PROMETHEUS_AVAILABLE:
            # ì‹œìŠ¤í…œ ê°€ë™ ì‹œê°„
            uptime = (datetime.now() - self.start_time).total_seconds()
            SYSTEM_UPTIME.set(uptime)

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory = psutil.virtual_memory()
            MEMORY_USAGE.set(memory.used)

            # CPU ì‚¬ìš©ëŸ‰
            cpu_percent = psutil.cpu_percent(interval=1)
            CPU_USAGE.set(cpu_percent)

    def record_api_response_time(self, endpoint: str, duration: float):
        """API ì‘ë‹µ ì‹œê°„ ê¸°ë¡"""
        if PROMETHEUS_AVAILABLE:
            API_RESPONSE_TIME.labels(api_endpoint=endpoint).observe(duration)

class DataQualityMonitor:
    """ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°"""

    def __init__(self, config: MonitoringConfig, metrics_collector: PrometheusMetricsCollector):
        self.config = config
        self.metrics_collector = metrics_collector
        self.engine = create_engine(config.postgres_url)
        self.redis_client = redis.from_url(config.redis_url, decode_responses=True)

    async def check_data_completeness(self) -> Dict[str, float]:
        """ë°ì´í„° ì™„ì „ì„± ê²€ì‚¬"""
        try:
            # PostgreSQLì—ì„œ ë°ì´í„° ì™„ì „ì„± í™•ì¸
            query = """
            SELECT
                symbol,
                COUNT(*) as total_records,
                COUNT(CASE WHEN close IS NOT NULL THEN 1 END) as non_null_close,
                COUNT(CASE WHEN volume IS NOT NULL THEN 1 END) as non_null_volume
            FROM ohlcv_data
            WHERE collected_at >= NOW() - INTERVAL '7 days'
            GROUP BY symbol
            """

            df = pd.read_sql(query, self.engine)

            completeness_scores = {}
            for _, row in df.iterrows():
                symbol = row['symbol']
                total = row['total_records']
                close_complete = row['non_null_close']
                volume_complete = row['non_null_volume']

                # ì™„ì „ì„± ì ìˆ˜ ê³„ì‚°
                close_score = (close_complete / total) * 100 if total > 0 else 0
                volume_score = (volume_complete / total) * 100 if total > 0 else 0
                overall_score = (close_score + volume_score) / 2

                completeness_scores[symbol] = overall_score

                # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.metrics_collector.update_data_quality(f"{symbol}_completeness", overall_score)

            return completeness_scores

        except Exception as e:
            logger.error(f"ë°ì´í„° ì™„ì „ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            self.metrics_collector.record_error("data_completeness_check", "database")
            return {}

    async def check_data_accuracy(self) -> Dict[str, float]:
        """ë°ì´í„° ì •í™•ì„± ê²€ì‚¬"""
        try:
            # ë¹„ì •ìƒì ì¸ ê°€ê²© ë³€ë™ í™•ì¸
            query = """
            SELECT
                symbol,
                COUNT(*) as total_records,
                COUNT(CASE WHEN close < 0 THEN 1 END) as negative_prices,
                COUNT(CASE WHEN close > 1000000 THEN 1 END) as extreme_prices,
                COUNT(CASE WHEN ABS(close - LAG(close) OVER (PARTITION BY symbol ORDER BY collected_at)) / LAG(close) OVER (PARTITION BY symbol ORDER BY collected_at) > 0.5 THEN 1 END) as extreme_changes
            FROM ohlcv_data
            WHERE collected_at >= NOW() - INTERVAL '7 days'
            GROUP BY symbol
            """

            df = pd.read_sql(query, self.engine)

            accuracy_scores = {}
            for _, row in df.iterrows():
                symbol = row['symbol']
                total = row['total_records']
                negative = row['negative_prices']
                extreme = row['extreme_prices']
                extreme_changes = row['extreme_changes']

                # ì •í™•ì„± ì ìˆ˜ ê³„ì‚°
                accuracy_score = 100
                if total > 0:
                    accuracy_score -= (negative / total) * 50  # ìŒìˆ˜ ê°€ê²©
                    accuracy_score -= (extreme / total) * 30   # ê·¹ë‹¨ì  ê°€ê²©
                    accuracy_score -= (extreme_changes / total) * 20  # ê·¹ë‹¨ì  ë³€ë™

                accuracy_scores[symbol] = max(0, accuracy_score)

                # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.metrics_collector.update_data_quality(f"{symbol}_accuracy", accuracy_score)

            return accuracy_scores

        except Exception as e:
            logger.error(f"ë°ì´í„° ì •í™•ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            self.metrics_collector.record_error("data_accuracy_check", "database")
            return {}

    async def check_data_timeliness(self) -> Dict[str, float]:
        """ë°ì´í„° ì ì‹œì„± ê²€ì‚¬"""
        try:
            # ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„ í™•ì¸
            query = """
            SELECT
                symbol,
                MAX(collected_at) as latest_collection,
                NOW() - MAX(collected_at) as time_difference
            FROM ohlcv_data
            GROUP BY symbol
            """

            df = pd.read_sql(query, self.engine)

            timeliness_scores = {}
            for _, row in df.iterrows():
                symbol = row['symbol']
                time_diff = row['time_difference']

                # ì ì‹œì„± ì ìˆ˜ ê³„ì‚° (5ë¶„ ì´ë‚´: 100ì , 1ì‹œê°„ ì´ë‚´: 80ì , 1ì¼ ì´ë‚´: 60ì )
                if time_diff.total_seconds() <= 300:  # 5ë¶„
                    timeliness_score = 100
                elif time_diff.total_seconds() <= 3600:  # 1ì‹œê°„
                    timeliness_score = 80
                elif time_diff.total_seconds() <= 86400:  # 1ì¼
                    timeliness_score = 60
                else:
                    timeliness_score = 0

                timeliness_scores[symbol] = timeliness_score

                # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.metrics_collector.update_data_quality(f"{symbol}_timeliness", timeliness_score)

            return timeliness_scores

        except Exception as e:
            logger.error(f"ë°ì´í„° ì ì‹œì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            self.metrics_collector.record_error("data_timeliness_check", "database")
            return {}

    async def generate_quality_report(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")

        # ê° í’ˆì§ˆ ì§€í‘œ ìˆ˜ì§‘
        completeness_scores = await self.check_data_completeness()
        accuracy_scores = await self.check_data_accuracy()
        timeliness_scores = await self.check_data_timeliness()

        # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        all_symbols = set(completeness_scores.keys()) | set(accuracy_scores.keys()) | set(timeliness_scores.keys())

        overall_scores = {}
        for symbol in all_symbols:
            completeness = completeness_scores.get(symbol, 0)
            accuracy = accuracy_scores.get(symbol, 0)
            timeliness = timeliness_scores.get(symbol, 0)

            # ê°€ì¤‘ í‰ê·  (ì™„ì „ì„± 40%, ì •í™•ì„± 40%, ì ì‹œì„± 20%)
            overall_score = (completeness * 0.4) + (accuracy * 0.4) + (timeliness * 0.2)
            overall_scores[symbol] = overall_score

            # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.metrics_collector.update_data_quality(symbol, overall_score)

        # ì•Œë¦¼ í™•ì¸
        alerts = []
        for symbol, score in overall_scores.items():
            if score < self.config.alert_thresholds['data_quality_min']:
                alerts.append(f"ì¢…ëª© {symbol} í’ˆì§ˆ ì ìˆ˜ ë‚®ìŒ: {score:.1f}")

        report = {
            'timestamp': datetime.now().isoformat(),
            'completeness_scores': completeness_scores,
            'accuracy_scores': accuracy_scores,
            'timeliness_scores': timeliness_scores,
            'overall_scores': overall_scores,
            'average_score': np.mean(list(overall_scores.values())) if overall_scores else 0,
            'alerts': alerts
        }

        # Redisì— ë¦¬í¬íŠ¸ ì €ì¥
        await self.redis_client.setex(
            'quality_report',
            3600,  # 1ì‹œê°„ TTL
            json.dumps(report, ensure_ascii=False)
        )

        logger.info(f"í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: í‰ê·  ì ìˆ˜ {report['average_score']:.1f}")
        return report

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°"""

    def __init__(self, config: MonitoringConfig, metrics_collector: PrometheusMetricsCollector):
        self.config = config
        self.metrics_collector = metrics_collector
        self.engine = create_engine(config.postgres_url)

    async def get_system_performance(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')

            # ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰
            network = psutil.net_io_counters()

            # ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥
            db_performance = await self._get_database_performance()

            performance_data = {
                'timestamp': datetime.now().isoformat(),
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'memory_used_gb': memory.used / (1024**3),
                'memory_total_gb': memory.total / (1024**3),
                'disk_percent': disk.percent,
                'disk_used_gb': disk.used / (1024**3),
                'disk_total_gb': disk.total / (1024**3),
                'network_bytes_sent': network.bytes_sent,
                'network_bytes_recv': network.bytes_recv,
                'database_performance': db_performance
            }

            # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.metrics_collector.update_system_metrics()

            return performance_data

        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì„±ëŠ¥ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.metrics_collector.record_error("system_performance", "monitoring")
            return {}

    async def _get_database_performance(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì •ë³´"""
        try:
            # í…Œì´ë¸” í¬ê¸°
            size_query = """
            SELECT
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
            FROM pg_tables
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """

            size_df = pd.read_sql(size_query, self.engine)

            # ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘ í†µê³„
            stats_query = """
            SELECT
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as unique_symbols,
                MAX(collected_at) as latest_data,
                MIN(collected_at) as earliest_data
            FROM ohlcv_data
            """

            stats_df = pd.read_sql(stats_query, self.engine)

            return {
                'table_sizes': size_df.to_dict('records'),
                'data_statistics': stats_df.to_dict('records')[0] if not stats_df.empty else {}
            }

        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""

    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.alert_history = []

    def check_alerts(self, quality_report: Dict[str, Any], performance_data: Dict[str, Any]) -> List[str]:
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        alerts = []

        # ë°ì´í„° í’ˆì§ˆ ì•Œë¦¼
        if quality_report:
            avg_score = quality_report.get('average_score', 0)
            if avg_score < self.config.alert_thresholds['data_quality_min']:
                alerts.append(f"ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ë‚®ìŒ: {avg_score:.1f}")

            for alert in quality_report.get('alerts', []):
                alerts.append(alert)

        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ì•Œë¦¼
        if performance_data:
            memory_percent = performance_data.get('memory_percent', 0)
            if memory_percent > self.config.alert_thresholds['memory_usage_max']:
                alerts.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {memory_percent:.1f}%")

            cpu_percent = performance_data.get('cpu_percent', 0)
            if cpu_percent > self.config.alert_thresholds['cpu_usage_max']:
                alerts.append(f"CPU ì‚¬ìš©ëŸ‰ ë†’ìŒ: {cpu_percent:.1f}%")

        # ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        if alerts:
            self.alert_history.append({
                'timestamp': datetime.now().isoformat(),
                'alerts': alerts
            })

        # ìµœê·¼ 100ê°œ ì•Œë¦¼ë§Œ ìœ ì§€
        if len(self.alert_history) > 100:
            self.alert_history = self.alert_history[-100:]

        return alerts

def create_streamlit_dashboard():
    """Streamlit ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    if not STREAMLIT_AVAILABLE:
        logger.warning("Streamlitì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ë¶€ ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        return

    st.set_page_config(
        page_title="íŠ¸ë ˆì´ë”© ë°ì´í„° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
        page_icon="ğŸ“Š",
        layout="wide"
    )

    st.title("ğŸš€ íŠ¸ë ˆì´ë”© ë°ì´í„° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ì„¤ì •")
    refresh_interval = st.sidebar.slider("ìƒˆë¡œê³ ì¹¨ ê°„ê²© (ì´ˆ)", 10, 300, 60)

    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì‹œìŠ¤í…œ ê°€ë™ë¥ ", "99.8%", "0.1%")

    with col2:
        st.metric("ë°ì´í„° í’ˆì§ˆ", "92.5%", "1.2%")

    with col3:
        st.metric("CPU ì‚¬ìš©ëŸ‰", "45.2%", "2.1%")

    with col4:
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", "67.8%", "-1.5%")

    # ì°¨íŠ¸ ì˜ì—­
    st.subheader("ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")

    # ê°€ìƒ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)
    dates = pd.date_range(start='2025-01-01', periods=100, freq='H')
    cpu_data = np.random.normal(45, 10, 100)
    memory_data = np.random.normal(68, 5, 100)
    quality_data = np.random.normal(92, 3, 100)

    # ì„±ëŠ¥ ì°¨íŠ¸
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('CPU ì‚¬ìš©ëŸ‰', 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰', 'ë°ì´í„° í’ˆì§ˆ', 'ì‹œìŠ¤í…œ ê°€ë™ë¥ '),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )

    fig.add_trace(
        go.Scatter(x=dates, y=cpu_data, name='CPU', line=dict(color='red')),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(x=dates, y=memory_data, name='Memory', line=dict(color='blue')),
        row=1, col=2
    )

    fig.add_trace(
        go.Scatter(x=dates, y=quality_data, name='Quality', line=dict(color='green')),
        row=2, col=1
    )

    fig.add_trace(
        go.Scatter(x=dates, y=[99.8] * 100, name='Uptime', line=dict(color='orange')),
        row=2, col=2
    )

    fig.update_layout(height=600, showlegend=True)
    st.plotly_chart(fig, use_container_width=True)

    # ì•Œë¦¼ ì„¹ì…˜
    st.subheader("ğŸ”” ìµœê·¼ ì•Œë¦¼")

    # ê°€ìƒ ì•Œë¦¼ ë°ì´í„°
    alerts = [
        {"time": "2025-01-27 14:30:00", "level": "Warning", "message": "ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ 85%ë¡œ í•˜ë½"},
        {"time": "2025-01-27 14:15:00", "level": "Info", "message": "ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ"},
        {"time": "2025-01-27 14:00:00", "level": "Success", "message": "ë°±ì—… ì‘ì—… ì„±ê³µ"}
    ]

    for alert in alerts:
        if alert["level"] == "Warning":
            st.warning(f"{alert['time']} - {alert['message']}")
        elif alert["level"] == "Info":
            st.info(f"{alert['time']} - {alert['message']}")
        else:
            st.success(f"{alert['time']} - {alert['message']}")

def create_dash_dashboard():
    """Dash ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    if not DASH_AVAILABLE:
        logger.error("Dashê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    app = dash.Dash(__name__)

    app.layout = html.Div([
        html.H1("íŠ¸ë ˆì´ë”© ë°ì´í„° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"),

        # ë©”íŠ¸ë¦­ ì¹´ë“œ
        html.Div([
            html.Div([
                html.H3("ì‹œìŠ¤í…œ ê°€ë™ë¥ "),
                html.H2("99.8%", id="uptime-metric")
            ], className="metric-card"),

            html.Div([
                html.H3("ë°ì´í„° í’ˆì§ˆ"),
                html.H2("92.5%", id="quality-metric")
            ], className="metric-card"),

            html.Div([
                html.H3("CPU ì‚¬ìš©ëŸ‰"),
                html.H2("45.2%", id="cpu-metric")
            ], className="metric-card"),

            html.Div([
                html.H3("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"),
                html.H2("67.8%", id="memory-metric")
            ], className="metric-card")
        ], className="metrics-container"),

        # ì°¨íŠ¸
        dcc.Graph(id="performance-chart"),

        # ìë™ ìƒˆë¡œê³ ì¹¨
        dcc.Interval(
            id='interval-component',
            interval=60*1000,  # 60ì´ˆë§ˆë‹¤
            n_intervals=0
        )
    ])

    @app.callback(
        Output('performance-chart', 'figure'),
        Input('interval-component', 'n_intervals')
    )
    def update_chart(n):
        # ê°€ìƒ ë°ì´í„° ìƒì„±
        dates = pd.date_range(start='2025-01-01', periods=100, freq='H')
        cpu_data = np.random.normal(45, 10, 100)
        memory_data = np.random.normal(68, 5, 100)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=dates, y=cpu_data, name='CPU', line=dict(color='red')))
        fig.add_trace(go.Scatter(x=dates, y=memory_data, name='Memory', line=dict(color='blue')))

        fig.update_layout(
            title="ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì‚¬ìš©ëŸ‰ (%)"
        )

        return fig

    return app

async def run_monitoring_system():
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰"""
    logger.info("ğŸ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œì‘")

    # ì„¤ì •
    config = MonitoringConfig()

    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    metrics_collector = PrometheusMetricsCollector(config)

    # ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    quality_monitor = DataQualityMonitor(config, metrics_collector)
    performance_monitor = PerformanceMonitor(config, metrics_collector)
    alert_manager = AlertManager(config)

    try:
        while True:
            logger.info("ëª¨ë‹ˆí„°ë§ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

            # ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
            quality_report = await quality_monitor.generate_quality_report()

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            performance_data = await performance_monitor.get_system_performance()

            # ì•Œë¦¼ í™•ì¸
            alerts = alert_manager.check_alerts(quality_report, performance_data)

            if alerts:
                logger.warning(f"ì•Œë¦¼ ë°œìƒ: {alerts}")

            # ëŒ€ê¸°
            await asyncio.sleep(config.metrics_interval_seconds)

    except KeyboardInterrupt:
        logger.info("ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ")
    except Exception as e:
        logger.error(f"ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” íŠ¸ë ˆì´ë”© ë°ì´í„° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)

    # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰
    asyncio.run(run_monitoring_system())

if __name__ == "__main__":
    main()

