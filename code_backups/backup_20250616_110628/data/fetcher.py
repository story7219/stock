# fetcher.py
# yfinanceë¥¼ ì´ìš©í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ í•¨ìˆ˜ ëª¨ìŒ (ì¼ëª©ê· í˜•í‘œ 2ì—­í˜¸ì „ í¬í•¨)

import yfinance as yf
import pandas as pd
from datetime import datetime
from trading.kis_api import KIS_API # KIS_API í´ë˜ìŠ¤ë¥¼ ì§ì ‘ import
from utils.logger import log_event # ëˆ„ë½ëœ log_event import ì¶”ê°€
import config # IS_MOCK_TRADING ê°’ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ import
import requests
from collections import Counter
from kis_api_client import KISAPIClient
from typing import List, Dict, Any, Literal

# 1ë‹¨ê³„: 350ì¼ì¹˜ OHLCV ë°ì´í„° ìˆ˜ì§‘

def fetch_ohlcv_350(ticker):
    """
    yfinanceë¡œ 350ì¼ì¹˜ OHLCV ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    """
    df = yf.download(ticker, period='350d', interval='1d')
    return df

def fetch_daily_data(ticker: str, period: str = "2mo") -> pd.DataFrame:
    """
    ë‹¨ê¸° ìŠ¤ìºë„ˆë¥¼ ìœ„í•´ yfinanceì—ì„œ ì¼ë´‰ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    Args:
        ticker (str): ì¢…ëª© í‹°ì»¤ (ì˜ˆ: '005930.KS')
        period (str): ë°ì´í„° ê¸°ê°„ (ê¸°ë³¸ê°’: "2mo" - 2ê°œì›”)
    Returns:
        pd.DataFrame: OHLCV ë°ì´í„°í”„ë ˆì„
    """
    try:
        stock = yf.Ticker(ticker)
        df = stock.history(period=period, interval="1d")
        if df.empty:
            return None
        return df
    except Exception as e:
        print(f"[{ticker}] ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return None

# ì‹¤ì‹œê°„(ë˜ëŠ” ìµœê·¼) ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ìë™ë§¤ë§¤ ì‹¤ì „ìš©)
def fetch_realtime_ohlcv(ticker, period="5d", interval="1m"):
    """
    yfinanceë¡œ ì‹¤ì‹œê°„(ë˜ëŠ” ìµœê·¼) OHLCV ë°ì´í„° ìˆ˜ì§‘
    """
    df = yf.download(ticker, period=period, interval=interval)
    return df

# í•œêµ­íˆ¬ìì¦ê¶Œ APIìš© ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ì˜ˆì‹œ)
def fetch_realtime_ohlcv_kis(ticker, api_key):
    """
    í•œêµ­íˆ¬ìì¦ê¶Œ APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì‹œ
    """
    # ì‹¤ì œ êµ¬í˜„ í•„ìš” (API ë¬¸ì„œ ì°¸ê³ )
    pass

# 2~6ë‹¨ê³„: ì „ëµ í†µí•© ë¶„ì„ í•¨ìˆ˜

def analyze_complete_strategy(ticker, verbose=True):
    """
    ì…ë ¥: ì¢…ëª©ì½”ë“œ
    ì¶œë ¥: ê° ë‹¨ê³„ë³„ ê²°ê³¼ì™€ ìµœì¢… ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
    """
    try:
        df = fetch_ohlcv_350(ticker)
        if df.empty or len(df) < 300:
            if verbose:
                print(f"[ë°ì´í„° ë¶€ì¡±] {ticker}")
            return None
        # 2ë‹¨ê³„: 300ì¼ ìµœì €ê°€ ë° ë‚ ì§œ
        df_300 = df[-300:]
        absolute_low = df_300['Low'].min()
        low_date = df_300['Low'].idxmin()
        if verbose:
            print(f"[ì ˆëŒ€ìµœì €ê°€] {absolute_low}")
            print(f"[ìµœì €ê°€ ë‚ ì§œ] {low_date.date()}")
        # 3ë‹¨ê³„: íš¡ë³´ íŒë‹¨
        df_after_low = df.loc[low_date:]
        high_since_low = df_after_low['High'].max()
        current_close = df['Close'][-1]
        ìƒìŠ¹ë¥  = high_since_low / absolute_low
        í˜„ì¬ìœ„ì¹˜ = current_close / absolute_low
        is_sideways = (ìƒìŠ¹ë¥  < 1.2) and (0.9 <= í˜„ì¬ìœ„ì¹˜ <= 1.15)
        if verbose:
            print(f"[ìµœì €ê°€ ì´í›„ ìµœê³ ê°€] {high_since_low}")
            print(f"[ìƒìŠ¹ë¥ ] {ìƒìŠ¹ë¥ :.2f}")
            print(f"[í˜„ì¬ìœ„ì¹˜] {í˜„ì¬ìœ„ì¹˜:.2f}")
            print(f"[íš¡ë³´ì—¬ë¶€] {'íš¡ë³´ì¤‘' if is_sideways else 'íš¡ë³´ì•„ë‹˜'}")
        # 4ë‹¨ê³„: MA30, MA60, ê³¨ë“ í¬ë¡œìŠ¤
        df['MA30'] = df['Close'].rolling(window=30).mean()
        df['MA60'] = df['Close'].rolling(window=60).mean()
        ma_cross = False
        if len(df) >= 61:
            ma30_yesterday = df['MA30'].iloc[-2]
            ma60_yesterday = df['MA60'].iloc[-2]
            ma30_today = df['MA30'].iloc[-1]
            ma60_today = df['MA60'].iloc[-1]
            if pd.notna(ma30_yesterday) and pd.notna(ma60_yesterday) and pd.notna(ma30_today) and pd.notna(ma60_today):
                ma_cross = (ma30_yesterday < ma60_yesterday) and (ma30_today > ma60_today)
        if verbose:
            print(f"[MA30] {df['MA30'].iloc[-1]:.2f}")
            print(f"[MA60] {df['MA60'].iloc[-1]:.2f}")
            print(f"[ê³¨ë“ í¬ë¡œìŠ¤] {'ë°œìƒ' if ma_cross else 'ì—†ìŒ'}")
        # 5ë‹¨ê³„: ì¼ëª©ê· í˜•í‘œ ê³„ì‚°
        df['ì „í™˜ì„ '] = (df['High'].rolling(9).max() + df['Low'].rolling(9).min()) / 2
        df['ê¸°ì¤€ì„ '] = (df['High'].rolling(26).max() + df['Low'].rolling(26).min()) / 2
        ichimoku_1 = df['ì „í™˜ì„ '].iloc[-1] > df['ê¸°ì¤€ì„ '].iloc[-1]
        ichimoku_2 = df['Close'].iloc[-1] > df['Close'].shift(25).iloc[-1]
        if verbose:
            print(f"[ì „í™˜ì„ ] {df['ì „í™˜ì„ '].iloc[-1]:.2f}")
            print(f"[ê¸°ì¤€ì„ ] {df['ê¸°ì¤€ì„ '].iloc[-1]:.2f}")
            print(f"[1ì—­í˜¸ì „] {'O' if ichimoku_1 else 'X'}")
            print(f"[2ì—­í˜¸ì „] {'O' if ichimoku_2 else 'X'}")
        # 6ë‹¨ê³„: ìµœì¢… ì¡°ê±´
        all_ok = is_sideways and ma_cross and ichimoku_2
        if verbose:
            print(f"[ìµœì¢… ì¡°ê±´] {'ë§Œì¡±' if all_ok else 'ë¶ˆë§Œì¡±'}")
        return {
            'ticker': ticker,
            'absolute_low': absolute_low,
            'low_date': str(low_date.date()),
            'is_sideways': is_sideways,
            'ma_cross': ma_cross,
            'ichimoku_2': ichimoku_2,
            'all_ok': all_ok
        }
    except Exception as e:
        if verbose:
            print(f"[ì—ëŸ¬] {ticker}: {e}")
        return None

# 8ë‹¨ê³„: ì½”ìŠ¤í”¼200 ì „ì²´ ì ìš© ì˜ˆì‹œ
def fetch_kospi200_tickers(use_web_scraping=True):
    """
    ì½”ìŠ¤í”¼200 ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì›¹ì—ì„œ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ìµœì‹  ìƒíƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    yfinanceì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì¢…ëª©ì½”ë“œ ë’¤ì— '.KS'ë¥¼ ë¶™ì—¬ì¤ë‹ˆë‹¤.
    ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ì— ëŒ€ë¹„í•˜ì—¬ ì—¬ëŸ¬ URLì„ ì‹œë„í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ë‚´ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if not use_web_scraping:
        return _get_fallback_kospi200_tickers()

    # ì‹œë„í•  URL ë¦¬ìŠ¤íŠ¸ (ì²« ë²ˆì§¸: ë„¤ì´ë²„ ê¸ˆìœµ, ë‘ ë²ˆì§¸: ì—°í•©ì¸í¬ë§¥ìŠ¤)
    urls = [
        'https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=1',
        'https://www.infomax.co.kr/web/kospi200/component'
    ]
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
    
    for i, url in enumerate(urls):
        try:
            tables = pd.read_html(requests.get(url, headers=headers).text)
            
            if "naver.com" in url:
                # ë„¤ì´ë²„ ê¸ˆìœµ: ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì³ ìˆìœ¼ë¯€ë¡œ 4í˜ì´ì§€ê¹Œì§€ ì½ì–´ì˜´
                df_list = []
                for page in range(1, 5): # 1~4 í˜ì´ì§€
                    page_url = f'https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page={page}'
                    df_list.append(pd.read_html(requests.get(page_url, headers=headers).text)[1])
                df = pd.concat(df_list)
                df = df[df['ì¢…ëª©ëª…'].notna()]
                # ë„¤ì´ë²„ëŠ” ì¢…ëª©ì½”ë“œê°€ ì—†ìœ¼ë¯€ë¡œ, ì¢…ëª©ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ yfinance í‹°ì»¤ë¥¼ ì°¾ì•„ì•¼ í•¨ (ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ê³  ë‹¤ë¥¸ URL ìš°ì„ )
                # ê°„ì†Œí™”ë¥¼ ìœ„í•´ ë„¤ì´ë²„ëŠ” ê±´ë„ˆë›°ê³  ì—°í•©ì¸í¬ë§¥ìŠ¤ ìš°ì„  ì‹œë„
                continue # ë„¤ì´ë²„ ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ ë‹¤ìŒ URLë¡œ ë„˜ì–´ê°

            elif "infomax.co.kr" in url:
                 # ì—°í•©ì¸í¬ë§¥ìŠ¤ëŠ” ë‘ ë²ˆì§¸ í…Œì´ë¸”ì— ì •ë³´ê°€ ìˆìŒ
                df = tables[1]
                df['ë‹¨ì¶•ì½”ë“œ'] = df['ë‹¨ì¶•ì½”ë“œ'].astype(str).str.zfill(6)
                tickers = [f"{code}.KS" for code in df['ë‹¨ì¶•ì½”ë“œ'] if len(code) == 6 and code.isdigit()]

            else: # ì¼ë°˜ì ì¸ ê²½ìš° (ì˜ˆ: KRX)
                df = tables[0]
                # 'ì¢…ëª©ì½”ë“œ' ì—´ ì´ë¦„ì„ ì‹¤ì œ í…Œì´ë¸”ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŒ
                if 'ì¢…ëª©ì½”ë“œ' not in df.columns:
                    # 'í‹°ì»¤' ë“± ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ë˜ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„
                    code_col = [col for col in df.columns if 'ì½”ë“œ' in col or 'í‹°ì»¤' in col][0]
                else:
                    code_col = 'ì¢…ëª©ì½”ë“œ'
                
                df[code_col] = df[code_col].astype(str).str.zfill(6)
                tickers = [f"{code}.KS" for code in df[code_col] if len(code) == 6 and code.isdigit()]

            if tickers:
                log_event("INFO", f"ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ KOSPI200 ìµœì‹  ì¢…ëª© {len(tickers)}ê°œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (URL: {url})")
                # KIS APIì™€ í˜¸í™˜ì„ ìœ„í•´ .KS ì ‘ë¯¸ì‚¬ ì œê±°
                return [ticker.replace('.KS', '') for ticker in tickers]

        except Exception as e:
            log_event("WARNING", f"URL {url} ì—ì„œ KOSPI200 ì¢…ëª© ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            continue # ë‹¤ìŒ URL ì‹œë„

    # ëª¨ë“  ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ
    log_event("ERROR", "ëª¨ë“  ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œë„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‚´ì¥ëœ ëŒ€ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    return _get_fallback_kospi200_tickers()

def _get_fallback_kospi200_tickers():
    """ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ë‚´ì¥ KOSPI200 ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # 2024ë…„ 5ì›” ê¸°ì¤€ KOSPI 200 ì¼ë¶€ ì¢…ëª© (ì „ì²´ í¬í•¨ ì‹œ ë„ˆë¬´ ê¸¸ì–´ì§)
    # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì „ì²´ 200ê°œ ì¢…ëª©ì„ ë„£ì–´ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    log_event("WARNING", "ë‚´ì¥ëœ KOSPI200 ëŒ€ì²´ ì˜ˆì‹œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ìµœì‹  ì •ë³´ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    tickers = [
        '005930.KS', '000660.KS', '035420.KS', '035720.KS', '051910.KS', '005380.KS', '005490.KS', '068270.KS', '105560.KS', '003670.KS',
        '012330.KS', '000270.KS', '066570.KS', '096770.KS', '034730.KS', '028260.KS', '015760.KS', '032830.KS', '006400.KS', '017670.KS'
    ]
    # KIS APIì™€ í˜¸í™˜ì„ ìœ„í•´ .KS ì ‘ë¯¸ì‚¬ ì œê±°
    return [ticker.replace('.KS', '') for ticker in tickers]

def fetch_market_ranking(kis_api: KIS_API, ranking_type: str, top_n: int = 20) -> list:
    """
    KIS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ìœ í˜•ì˜ ì‹œì¥ ë­í‚¹ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        kis_api (KIS_API): ì´ˆê¸°í™”ëœ KIS_API ì¸ìŠ¤í„´ìŠ¤.
        ranking_type (str): 'volume'(ê±°ë˜ëŸ‰), 'gainer'(ìƒìŠ¹ë¥ ) ë“± ìˆœìœ„ ìœ í˜•.
        top_n (int): ê°€ì ¸ì˜¬ ìƒìœ„ ì¢…ëª©ì˜ ìˆ˜.
        
    Returns:
        list: ìƒìœ„ ì¢…ëª©ì˜ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['005930', '000660', ...]). ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸.
    """
    ranking_data = kis_api.fetch_ranking_data(ranking_type)
    
    if not ranking_data:
        return []
    
    # KIS APIëŠ” ì¢…ëª©ì½”ë“œì— 'KS' ì ‘ë¯¸ì‚¬ë¥¼ ë¶™ì´ì§€ ì•Šìœ¼ë¯€ë¡œ, ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # API ì‘ë‹µì—ì„œ ì¢…ëª© ì½”ë“œ(h_kor_iscd)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    tickers = [item.get('h_kor_iscd', '').strip() for item in ranking_data]
    
    # Noneì´ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤.
    tickers = [ticker for ticker in tickers if ticker]
    
    log_event("INFO", f"[{ranking_type}] ë­í‚¹ ìƒìœ„ {len(tickers)}ê°œ ì¢…ëª© ì¡°íšŒ ì„±ê³µ.")
    return tickers[:top_n]

def fetch_short_term_candidates_hybrid(kis_api: KIS_API, top_n: int = 50) -> list:
    """
    'ë§ˆì¼“ í”„ë¦¬ì¦˜' ì „ëµìœ¼ë¡œ ë‹¨ê¸° íˆ¬ì í›„ë³´êµ°ì„ ì„ ì •í•©ë‹ˆë‹¤.
    1. ì£¼ë„ ì—…ì¢… í¬ì°©: ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª©ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ ì£¼ë„ ì—…ì¢…ì„ ê²°ì •.
    2. ë‹¤ì¤‘ ë­í‚¹ ì¡°íšŒ: ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ ë“± ì£¼ìš” ë­í‚¹ ì •ë³´ë¥¼ ëª¨ë‘ ì¡°íšŒ.
    3. êµì°¨ í•„í„°ë§: ë‹¤ì¤‘ ë­í‚¹ ì¢…ëª© ì¤‘ 'ì£¼ë„ ì—…ì¢…'ì— ì†í•˜ëŠ” ê²ƒë§Œ 1ì°¨ í•„í„°ë§.
    4. ìµœì¢… ì••ì¶•: í•„í„°ë§ëœ ì¢…ëª© ì¤‘ ê°€ì¥ ë§ì´ ì¤‘ë³µëœ ìˆœì„œë¡œ ìµœì¢… í›„ë³´ ì„ ì •.
    """
    if config.IS_MOCK_TRADING:
        log_event("WARNING", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] ëª¨ì˜íˆ¬ì í™˜ê²½ì—ì„œëŠ” ìˆœìœ„ ì¡°íšŒë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return _get_fallback_kospi200_tickers()

    # 1. ì£¼ë„ ì—…ì¢… í¬ì°©
    log_event("INFO", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] 1. ì£¼ë„ ì—…ì¢… í¬ì°© ì‹œì‘...")
    gainer_rankers = fetch_market_ranking(kis_api, 'gainer', top_n=top_n)
    if not gainer_rankers:
        log_event("ERROR", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] ì£¼ë„ ì—…ì¢… í¬ì°© ì‹¤íŒ¨(ìƒìŠ¹ë¥  ë­í‚¹ ì¡°íšŒ ë¶ˆê°€). ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return []

    sector_scores = Counter()
    for ticker in gainer_rankers:
        industry = kis_api.get_stock_industry(ticker)
        if industry and 'ì¦ê¶Œ' not in industry:
            sector_scores[industry] += 1
    
    if not sector_scores:
        log_event("WARNING", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] ìœ íš¨í•œ ì£¼ë„ ì—…ì¢…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []
        
    leading_sector = sector_scores.most_common(1)[0][0]
    log_event("SUCCESS", f"[ë§ˆì¼“ í”„ë¦¬ì¦˜] ì˜¤ëŠ˜ì˜ ì£¼ë„ ì—…ì¢…: '{leading_sector}'")

    # 2. ë‹¤ì¤‘ ë­í‚¹ ì¡°íšŒ
    log_event("INFO", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] 2. ë‹¤ì¤‘ ë­í‚¹(ê±°ë˜ëŸ‰,ëŒ€ê¸ˆ,ì™¸êµ­ì¸,ê¸°ê´€) ì¡°íšŒ...")
    ranking_types = ['volume', 'value', 'foreign_buy', 'ê¸°ê´€_buy']
    all_rankers = []
    for r_type in ranking_types:
        rankers = fetch_market_ranking(kis_api, r_type, top_n=top_n)
        if rankers:
            all_rankers.extend(rankers)

    if not all_rankers:
        log_event("ERROR", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] ë‹¤ì¤‘ ë­í‚¹ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return []

    # 3. êµì°¨ í•„í„°ë§: ë‹¤ì¤‘ ë­í‚¹ ì¢…ëª©ë“¤ì„ ì£¼ë„ ì—…ì¢…ìœ¼ë¡œ í•„í„°ë§
    log_event("INFO", f"[ë§ˆì¼“ í”„ë¦¬ì¦˜] 3. ë‹¤ì¤‘ ë­í‚¹ ì¢…ëª©ë“¤ì„ '{leading_sector}' ì—…ì¢…ìœ¼ë¡œ í•„í„°ë§...")
    filtered_by_sector = []
    # ì¤‘ë³µ ì¡°íšŒë¥¼ í”¼í•˜ê¸° ìœ„í•´ setìœ¼ë¡œ ë³€í™˜
    unique_rankers = set(all_rankers) 
    for ticker in unique_rankers:
        industry = kis_api.get_stock_industry(ticker)
        if industry == leading_sector:
            # ì£¼ë„ ì—…ì¢…ì— ì†í•˜ëŠ” ì¢…ëª©ë“¤ì„ ì›ë˜ì˜ all_rankers ë¦¬ìŠ¤íŠ¸ì—ì„œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ ì¶”ê°€
            # (ì¤‘ë³µ íšŸìˆ˜ ìœ ì§€ë¥¼ ìœ„í•´)
            filtered_by_sector.extend([t for t in all_rankers if t == ticker])
            
    if not filtered_by_sector:
        log_event("WARNING", f"[ë§ˆì¼“ í”„ë¦¬ì¦˜] ì£¼ë„ ì—…ì¢…('{leading_sector}')ì— ì†í•˜ëŠ” ë­í‚¹ ìƒìœ„ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # 4. ìµœì¢… ì••ì¶•
    log_event("INFO", "[ë§ˆì¼“ í”„ë¦¬ì¦˜] 4. ìµœì¢… í›„ë³´êµ° ì••ì¶•...")
    ticker_counts = Counter(filtered_by_sector)
    sorted_candidates = sorted(ticker_counts.items(), key=lambda item: (-item[1], item[0]))
    final_candidates = [ticker for ticker, count in sorted_candidates]
    
    log_event("SUCCESS", f"[ë§ˆì¼“ í”„ë¦¬ì¦˜] ìµœì¢… í›„ë³´êµ° {len(final_candidates)}ê°œ ì„ ì • ì™„ë£Œ: {final_candidates}")
    return final_candidates

def _fetch_candidates_by_multi_rank(kis_api: KIS_API, top_n: int = 30) -> list:
    """
    (ì˜ˆë¹„ ê³„íš) ë‹¤ì¤‘ ë­í‚¹ì„ ì¢…í•©í•˜ì—¬ í›„ë³´êµ°ì„ ì„ ì •í•©ë‹ˆë‹¤.
    """
    log_event("INFO", "[ëŒ€ì²´ ë¡œì§] ë‹¤ì¤‘ ë­í‚¹(ê±°ë˜ëŸ‰,ëŒ€ê¸ˆ,ì™¸êµ­ì¸,ê¸°ê´€) ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    ranking_types = ['volume', 'value', 'foreign_buy', 'ê¸°ê´€_buy']
    all_rankers = []
    
    for r_type in ranking_types:
        rankers = fetch_market_ranking(kis_api, r_type, top_n=top_n)
        if rankers:
            all_rankers.extend(rankers)

    if not all_rankers:
        log_event("ERROR", "[ëŒ€ì²´ ë¡œì§] ëª¨ë“  ë­í‚¹ ì¡°íšŒ ì‹¤íŒ¨. ì½”ìŠ¤í”¼200ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return fetch_kospi200_tickers()

    from collections import Counter
    ticker_counts = Counter(all_rankers)
    sorted_candidates = sorted(ticker_counts.items(), key=lambda item: (-item[1], item[0]))
    final_candidates = [ticker for ticker, count in sorted_candidates]
    log_event("INFO", f"[ëŒ€ì²´ ë¡œì§] í›„ë³´êµ° {len(final_candidates)}ê°œ ì„ ì • ì™„ë£Œ.")
    return final_candidates

class MarketFetcher:
    """
    í•œêµ­íˆ¬ìì¦ê¶Œ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œì¥ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í´ë˜ìŠ¤
    """
    def __init__(self, kis_api: KIS_API):
        self.api = kis_api

    def _send_ranking_request(self, tr_id: str, path: str, params: Dict) -> List[Dict]:
        """ë­í‚¹ ì¡°íšŒ ìš”ì²­ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ê³µí†µ í•¨ìˆ˜"""
        try:
            url = f"{self.api.base_url}/{path}"
            headers = self.api._get_headers(tr_id)
            res = requests.get(url, headers=headers, params=params)
            res.raise_for_status()
            data = res.json()
            if data.get('rt_cd') == '0':
                return data.get('output', [])
            log_event("WARNING", f"âš ï¸ [Fetcher] ë­í‚¹ ì¡°íšŒ ì‹¤íŒ¨: {data.get('msg1')}")
            return []
        except Exception as e:
            log_event("ERROR", f"ğŸ”¥ [Fetcher] ë­í‚¹ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def get_price_ranking(self, rank_type: Literal['rise', 'fall'] = 'rise', limit: int = 20) -> List[Dict]:
        """ìƒìŠ¹ë¥ /í•˜ë½ë¥  ìˆœìœ„ ì¡°íšŒ"""
        params = {
            "fid_cond_mrkt_div_code": "J", "fid_input_iscd": "0000",
            "fid_div_cls_code": "0" if rank_type == "rise" else "1",
            "fid_input_price_1": "1000" # 1000ì› ì´ìƒ
        }
        return self._send_ranking_request("FHPST01700000", self.api.PATH_RANKING_FLUCTUATION, params)

    def get_investor_ranking(self, investor_type: Literal['foreign', 'institution'] = 'foreign', limit: int = 20) -> List[Dict]:
        """ì™¸êµ­ì¸/ê¸°ê´€ ìˆœë§¤ìˆ˜ ìˆœìœ„ ì¡°íšŒ"""
        params = {
            "fid_cond_mrkt_div_code": "J", "fid_input_iscd": "0001" if investor_type == "foreign" else "0002",
        }
        return self._send_ranking_request("FHKST01010900", self.api.PATH_RANKING_INVESTOR, params)

    def get_volume_ranking(self, limit: int = 20) -> List[Dict]:
        """ê±°ë˜ëŸ‰ ìˆœìœ„ ì¡°íšŒ"""
        params = {"fid_cond_mrkt_div_code": "J", "fid_input_iscd": "0000"}
        return self._send_ranking_request("FHPST01710000", self.api.PATH_RANKING_VOLUME, params)

    def find_market_prism_candidates(self, top_n: int = 10) -> List[str]:
        """
        'ë§ˆì¼“ í”„ë¦¬ì¦˜' ì „ëµìœ¼ë¡œ ìœ ë§ í›„ë³´ ì¢…ëª© í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ìƒìŠ¹ë¥ , ê±°ë˜ëŸ‰, ì™¸êµ­ì¸/ê¸°ê´€ ìˆ˜ê¸‰ì„ ì¢…í•©í•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³  ìƒìœ„ ì¢…ëª©ì„ ì„ ì •í•©ë‹ˆë‹¤.
        """
        log_event("INFO", "ğŸ” [MarketPrism] ìœ ë§ í›„ë³´ ì¢…í•© ë¶„ì„ ì‹œì‘...")
        scores = {}
        
        rankings = {
            'rise': self.get_price_ranking('rise', 50),
            'volume': self.get_volume_ranking(50),
            'foreign': self.get_investor_ranking('foreign', 50),
            'institution': self.get_investor_ranking('institution', 50)
        }
        
        weights = {'rise': 2.0, 'volume': 1.0, 'foreign': 1.5, 'institution': 1.5}

        for r_type, items in rankings.items():
            for i, item in enumerate(items):
                ticker = item.get('mksc_shrn_iscd') or item.get('h_kor_iscd')
                if not ticker: continue
                
                score = (50 - i) * weights[r_type]
                scores[ticker] = scores.get(ticker, 0) + score
        
        if not scores:
            log_event("WARNING", "âš ï¸ [MarketPrism] ë¶„ì„í•  í›„ë³´ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        final_tickers = [ticker for ticker, score in sorted_candidates[:top_n]]
        
        log_event("SUCCESS", f"ğŸ¯ [MarketPrism] ìµœì¢… í›„ë³´ {len(final_tickers)}ê°œ ì„ ì •: {final_tickers}")
        return final_tickers

def fetch_daily_data_for_chart(ticker: str, period: str = "3mo") -> pd.DataFrame | None:
    """
    ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•´ yfinanceì—ì„œ ì¼ë´‰ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        yf_ticker = f"{ticker}.KS"
        stock = yf.Ticker(yf_ticker)
        df = stock.history(period=period, interval="1d")
        if df.empty:
            return None
        return df
    except Exception as e:
        log_event("ERROR", f"[{ticker}] ì°¨íŠ¸ìš© ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return None

def fetch_kospi_tickers() -> list:
    """ì½”ìŠ¤í”¼ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìƒ˜í”Œ)"""
    # ì‹¤ì œë¡œëŠ” APIë‚˜ íŒŒì¼ì—ì„œ ì½ì–´ì˜¬ ìˆ˜ ìˆìŒ
    return [
        "005930",  # ì‚¼ì„±ì „ì
        "000660",  # SKí•˜ì´ë‹‰ìŠ¤
        "207940",  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
        "005490",  # POSCOí™€ë”©ìŠ¤
        "035420",  # NAVER
        "006400",  # ì‚¼ì„±SDI
        "051910",  # LGí™”í•™
        "028260",  # ì‚¼ì„±ë¬¼ì‚°
        "105560",  # KBê¸ˆìœµ
        "068270",  # ì…€íŠ¸ë¦¬ì˜¨
        "012330",  # í˜„ëŒ€ëª¨ë¹„ìŠ¤
        "003670",  # í¬ìŠ¤ì½”í“¨ì²˜ì— 
        "096770",  # SKì´ë…¸ë² ì´ì…˜
        "000270",  # ê¸°ì•„
        "323410",  # ì¹´ì¹´ì˜¤ë±…í¬
    ]

if __name__ == "__main__":
    # ì‚¼ì„±ì „ì í…ŒìŠ¤íŠ¸
    print("\n[ì‚¼ì„±ì „ì ì „ëµ ë¶„ì„ ê²°ê³¼]")
    analyze_complete_strategy('005930.KS', verbose=True)
    # ì „ì²´ ì¢…ëª© ë¶„ì„
    print("\n[ì½”ìŠ¤í”¼200 ì „ëµ í•„í„°ë§ ê²°ê³¼]")
    tickers = fetch_kospi200_tickers()
    results = []
    for ticker in tickers:
        res = analyze_complete_strategy(ticker, verbose=False)
        if res and res['all_ok']:
            results.append(res)
    df_result = pd.DataFrame(results)
    print(df_result) 