```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPU ë”¥ëŸ¬ë‹ ì‹¤ì „ í…ŒìŠ¤íŠ¸ (Python 3.11+)
"""
import torch
import torch.nn as nn
import torch.optim as optim
import time
import numpy as np

def test_gpu_deep_learning():
    """GPU ë”¥ëŸ¬ë‹ ì‹¤ì „ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ GPU ë”¥ëŸ¬ë‹ ì‹¤ì „ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    
    # 1. GPU ì„¤ì • í™•ì¸
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        try:
            print(f"CUDA ë²„ì „: {torch.version.cuda}")
        except AttributeError:
            print("CUDA ë²„ì „ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ì‹¤ì „ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ì˜
    class DeepNeuralNetwork(nn.Module):
        def __init__(self, input_size: int = 100, hidden_size: int = 256):
            super().__init__()
            self.layers = nn.Sequential(
                nn.Linear(input_size, hidden_size),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(hidden_size, hidden_size // 2),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(hidden_size // 2, hidden_size // 4),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(hidden_size // 4, 1)
            )
        
        def forward(self, x: torch.Tensor) -> torch.Tensor:
            return self.layers(x)
    
    # 3. ëª¨ë¸ ìƒì„± ë° GPUë¡œ ì´ë™
    model = DeepNeuralNetwork().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    print(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {next(model.parameters()).device}")
    
    # 4. ì‹¤ì „ ë°ì´í„° ìƒì„± (ëŒ€ìš©ëŸ‰)
    batch_size = 1000
    input_size = 100
    
    # CPUì—ì„œ ë°ì´í„° ìƒì„± í›„ GPUë¡œ ì´ë™
    X = torch.randn(batch_size, input_size).to(device)
    y = torch.randn(batch_size, 1).to(device)
    
    print(f"ë°ì´í„° ìƒì„± ì™„ë£Œ - X: {X.shape}, y: {y.shape}")
    print(f"X ë””ë°”ì´ìŠ¤: {X.device}, y ë””ë°”ì´ìŠ¤: {y.device}")
    
    # 5. ì‹¤ì „ í•™ìŠµ (GPU ê°€ì†)
    print("\nğŸ”¥ GPU ë”¥ëŸ¬ë‹ í•™ìŠµ ì‹œì‘!")
    start_time = time.time()
    
    model.train()
    for epoch in range(100):
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        
        if epoch % 20 == 0:
            print(f"Epoch {epoch:3d}, ì†ì‹¤ê°’: {loss.item():.6f}")
    
    training_time = time.time() - start_time
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ì‹œê°„: {training_time:.2f}ì´ˆ")
```